{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87e69787",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Training Models in Vertex AI: Intro\"\n",
    "teaching: 30\n",
    "exercises: 2\n",
    "---\n",
    "\n",
    ":::::::::::::::::::::::::::::::::::::: questions \n",
    "\n",
    "- What are the differences between training locally in a Vertex AI notebook and using Vertex AI-managed training jobs?  \n",
    "- How do custom training jobs in Vertex AI streamline the training process for various frameworks?  \n",
    "- How does Vertex AI handle scaling across CPUs, GPUs, and TPUs?  \n",
    "\n",
    "::::::::::::::::::::::::::::::::::::::::::::::::\n",
    "\n",
    "::::::::::::::::::::::::::::::::::::: objectives\n",
    "\n",
    "- Understand the difference between local training in a Vertex AI Workbench notebook and submitting managed training jobs.  \n",
    "- Learn to configure and use Vertex AI custom training jobs for different frameworks (e.g., XGBoost, PyTorch, SKLearn).  \n",
    "- Understand scaling options in Vertex AI, including when to use CPUs, GPUs, or TPUs.  \n",
    "- Compare performance, cost, and setup between custom scripts and pre-built containers in Vertex AI.  \n",
    "- Conduct training with data stored in GCS and monitor training job status using the Google Cloud Console.  \n",
    "\n",
    "::::::::::::::::::::::::::::::::::::::::::::::::\n",
    "\n",
    "## Initial setup \n",
    "\n",
    "#### 1. Open pre-filled notebook\n",
    "Navigate to `/Intro_GCP_for_ML/notebooks/06-Training-models-in-VertexAI.ipynb` to begin this notebook.\n",
    "\n",
    "#### 2. CD to instance home directory\n",
    "To ensure we're all in the saming starting spot, change directory to your Jupyter home directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b02050",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/jupyter/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3983ed",
   "metadata": {},
   "source": [
    "#### 3. Set environment variables \n",
    "This code initializes the Vertex AI environment by importing the Python SDK, setting the project, region, and defining a GCS bucket for input/output data.\n",
    "\n",
    "- `PROJECT_ID`: Identifies your GCP project.  \n",
    "- `REGION`: Determines where training jobs run (choose a region close to your data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de642a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "client = storage.Client()\n",
    "PROJECT_ID = client.project\n",
    "REGION = \"us-central1\"\n",
    "BUCKET_NAME = \"sinkorswim-johndoe-titanic\" # ADJUST to your bucket's name\n",
    "\n",
    "print(f\"project = {PROJECT_ID}\\nregion = {REGION}\\nbucket = {BUCKET_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83d452e",
   "metadata": {},
   "source": [
    "## Testing train.py locally in the notebook\n",
    "\n",
    "::::::::::::::::::::::::::::::::::::::: challenge\n",
    "\n",
    "### Understanding the XGBoost Training Script (GCP version)\n",
    "\n",
    "Take a moment to review the `train_xgboost.py` script we're using on GCP found in `Intro_GCP-for_ML/scripts/train_xgboost.py`. This script handles preprocessing, training, and saving an XGBoost model, while supporting local paths and GCS (`gs://`) paths, and it adapts to Vertex AI conventions (e.g., `AIP_MODEL_DIR`).\n",
    "\n",
    "Try answering the following questions:\n",
    "\n",
    "1. **Data preprocessing**: What transformations are applied to the dataset before training?\n",
    "2. **Training function**: What does the `train_model()` function do? Why print the training time?\n",
    "3. **Command-line arguments**: What is the purpose of `argparse` in this script? How would you change the number of training rounds?\n",
    "4. **Handling local vs. GCP runs**: How does the script let you run the same code locally, in Workbench, or as a Vertex AI job? Which environment variable controls where the model artifact is written?\n",
    "5. **Training and saving the model**: What format is the dataset converted to before training, and why? How does the script save to a local path vs. a `gs://` destination?\n",
    "\n",
    "After reviewing, discuss any questions or observations with your group.\n",
    "\n",
    ":::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
    "\n",
    "\n",
    "::::::::::::::::::::::::::::::::::::::: solution\n",
    "\n",
    "### Solution\n",
    "\n",
    "1. **Data preprocessing**: The script fills missing values (`Age` with median, `Embarked` with mode), maps categorical fields to numeric (`Sex` → {male:1, female:0}, `Embarked` → {S:0, C:1, Q:2}), and drops non-predictive columns (`Name`, `Ticket`, `Cabin`).\n",
    "2. **Training function**: `train_model()` constructs and fits an XGBoost model with the provided parameters and prints wall-clock training time. Timing helps compare runs and make sensible scaling choices.\n",
    "3. **Command-line arguments**: `argparse` lets you set hyperparameters and file paths without editing code (e.g., `--max_depth`, `--eta`, `--num_round`, `--train`). To change rounds:  `python train_xgboost.py --num_round 200`\n",
    "4. **Handling local vs. GCP runs**:  \n",
    "   - **Input**: You pass `--train` as either a local path (`train.csv`) or a GCS URI (`gs://bucket/path.csv`). The script automatically detects `gs://` and reads the file directly from Cloud Storage using the Python client.  \n",
    "   - **Output**: If the environment variable `AIP_MODEL_DIR` is set (as it is in Vertex AI CustomJobs), the trained model is written there—often a `gs://` path. Otherwise, the model is saved in the current working directory, which works seamlessly in both local and Workbench environments.\n",
    "5. **Training and saving the model**:  \n",
    "   The training data is converted into an **XGBoost `DMatrix`**, an optimized format that speeds up training and reduces memory use. The trained model is serialized with `joblib`. When saving locally, the file is written directly to disk. If saving to a Cloud Storage path (`gs://...`), the model is first saved to a temporary file and then uploaded to the specified bucket.\n",
    "\n",
    ":::::::::::::::::::::::::::::::::::::::\n",
    "\n",
    "\n",
    "Before scaling training jobs onto managed resources, it's essential to test your training script locally. This prevents wasting GPU/TPU time on bugs or misconfigured code.  \n",
    "\n",
    "### Guidelines for testing ML pipelines before scaling\n",
    "\n",
    "- **Run tests locally first** with small datasets.  \n",
    "- **Use a subset of your dataset** (1–5%) for fast checks.  \n",
    "- **Start with minimal compute** before moving to larger accelerators.  \n",
    "- **Log key metrics** such as loss curves and runtimes.  \n",
    "- **Verify correctness first** before scaling up.  \n",
    "\n",
    "\n",
    "### What tests should we do before scaling?  \n",
    "\n",
    "Before scaling to multiple or more powerful instances (e.g., GPUs or TPUs), it's important to run a few sanity checks. Skipping these can lead to: silent data bugs, runtime blowups at scale, inefficient experiments, or broken model artifacts.  \n",
    "\n",
    "Here is a non-exhaustive list of suggested tests to perform before scaling up your compute needs.\n",
    "\n",
    "- **Data loads correctly** – dataset loads without errors, expected columns exist, missing values handled.  \n",
    "- **Overfitting check** – train on a tiny dataset (e.g., 100 rows). If it doesn't overfit, something is off.  \n",
    "- **Loss behavior** – verify training loss decreases and doesn't diverge.  \n",
    "- **Runtime estimate** – get a rough sense of training time on small data.  \n",
    "- **Memory estimate** – check approximate memory use.  \n",
    "- **Save & reload** – ensure model saves, reloads, and infers without errors.  \n",
    "\n",
    "\n",
    "## Download data into notebook environment\n",
    "Sometimes it's helpful to keep a copy of data in your notebook VM for quick iteration, even though **GCS is the preferred storage location**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039e1ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "client = storage.Client()\n",
    "bucket = client.bucket(BUCKET_NAME)\n",
    "\n",
    "blob = bucket.blob(\"titanic_train.csv\")\n",
    "blob.download_to_filename(\"titanic_train.csv\")\n",
    "\n",
    "print(\"Downloaded titanic_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd5d8ea",
   "metadata": {},
   "source": [
    "## Local test run of train.py\n",
    "\n",
    "**Outside of this workshop, you should run these kinds of tests on your local laptop or lab PC when possible.** We're using the Workbench VM here only for convenience in this workshop setting, but this does incur a small fee for our running VM. \n",
    "\n",
    "- For large datasets, use a small representative sample of the total dataset when testing locally (i.e., just to verify that code is working and model overfits nearly perfectly after training enough epochs)\n",
    "- For larger models, use smaller model equivalents (e.g., 100M vs 7B params) when testing locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a322029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time as t\n",
    "\n",
    "start = t.time()\n",
    "\n",
    "# Example: run your custom training script with args\n",
    "!python Intro_GCP_for_ML/scripts/train_xgboost.py --max_depth 3 --eta 0.1 --subsample 0.8 --colsample_bytree 0.8 --num_round 100 --train titanic_train.csv\n",
    "\n",
    "print(f\"Total local runtime: {t.time() - start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb8c77d",
   "metadata": {},
   "source": [
    "Training on this small dataset should take <1 minute. Log runtime as a baseline.  You should see the following output file:\n",
    "\n",
    "- `xgboost-model`  # Python-serialized XGBoost model (Booster) via joblib; load with joblib.load for reuse.\n",
    "\n",
    "## Training via Vertex AI custom training job\n",
    "Unlike \"local\" training using our notebook's VM, this next approach launches a **managed training job** that runs on scalable compute. Vertex AI handles provisioning, scaling, logging, and saving outputs to GCS.  \n",
    "\n",
    "### Which machine type to start with?\n",
    "Start with a small CPU machine like `n1-standard-4`. Only scale up to GPUs/TPUs once you've verified your script. See [Instances for ML on GCP](https://qualiamachine.github.io/Intro_GCP_for_ML/instances-for-ML.html) for guidance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709d6656",
   "metadata": {},
   "outputs": [],
   "source": [
    "MACHINE = 'n1-standard-4'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac85ff7",
   "metadata": {},
   "source": [
    "### Creating a custom training job with the SDK\n",
    "\n",
    "We'll first initialize the Vertex AI platform with our environment variables. We'll also set a `RUN_ID` and `ARTIFACT_DIR` to help store outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f2ba52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "import datetime as dt\n",
    "RUN_ID = dt.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "print(f\"project = {PROJECT_ID}\\nregion = {REGION}\\nbucket = {BUCKET_NAME}\")\n",
    "ARTIFACT_DIR = f\"gs://{BUCKET_NAME}/artifacts/xgb/{RUN_ID}/\"  # everything will live beside this\n",
    "\n",
    "# Staging bucket is only for the SDK's temp code tarball (aiplatform-*.tar.gz)\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=f\"gs://{BUCKET_NAME}/.vertex_staging\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2957ed1f",
   "metadata": {},
   "source": [
    "This next section defines a custom training job in Vertex AI, specifying how and where the training code will run.  It points to your training script (`train_xgboost.py`), uses Google's prebuilt XGBoost training container image, and installs any extra dependencies your script needs (in this case, `google-cloud-storage` for accessing GCS).  The `display_name` sets a readable name for tracking the job in the Vertex AI console.\n",
    "\n",
    "#### Prebuilt containers for training\n",
    "Vertex AI provides prebuilt Docker container images for model training. These containers are organized by machine learning frameworks and framework versions and include common dependencies that you might want to use in your training code. To learn about which PyTorch versions have prebuilt training containers and how to train models with a prebuilt training container, see [Prebuilt containers for custom training](https://docs.cloud.google.com/vertex-ai/docs/predictions/pre-built-containers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12ddc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = aiplatform.CustomTrainingJob(\n",
    "    display_name=f\"endemann_xgb_{RUN_ID}\",\n",
    "    script_path=\"Intro_GCP_for_ML/scripts/train_xgboost.py\",\n",
    "    container_uri=\"us-docker.pkg.dev/vertex-ai/training/xgboost-cpu.2-1:latest\",\n",
    "    requirements=[\"google-cloud-storage\"],  # Our train_xgboost.py script uses storage.Client(), which isn't included in the xgboost image. We add it here.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926905b3",
   "metadata": {},
   "source": [
    "Finally, this next block launches the custom training job on Vertex AI using the configuration defined earlier. **We won't be charged for our selected `MACHINE` until we run the below code using `job.run()`. This marks the point when our script actually begins executing remotely on the Vertex training infrastructure. Once job.run() is called, Vertex handles packaging your training script, transferring it to the managed training environment, provisioning the requested compute instance, and monitoring the run. The job's status and logs can be viewed directly in the Vertex AI Console under Training → Custom jobs.\n",
    "\n",
    "If you need to cancel or modify a job mid-run, you can do so from the console or via the SDK by calling job.cancel(). When the job completes, Vertex automatically tears down the compute resources so you only pay for the active training time.\n",
    "\n",
    "- The `args` list passes command-line parameters directly into your training script, including hyperparameters and the path to the training data in GCS.  \n",
    "- `base_output_dir` specifies where all outputs (model, metrics, logs) will be written in Cloud Storage\n",
    "- `machine_type` controls the compute resources used for training.\n",
    "- When `sync=True`, the notebook waits until the job finishes before continuing, making it easier to inspect results immediately after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc76be2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "job.run(\n",
    "    args=[\n",
    "        f\"--train=gs://{BUCKET_NAME}/titanic_train.csv\",\n",
    "        \"--max_depth=3\",\n",
    "        \"--eta=0.1\",\n",
    "        \"--subsample=0.8\",\n",
    "        \"--colsample_bytree=0.8\",\n",
    "        \"--num_round=100\",\n",
    "    ],\n",
    "    replica_count=1,\n",
    "    machine_type=MACHINE, # MACHINE variable defined above; adjust to something more powerful when needed\n",
    "    base_output_dir=ARTIFACT_DIR,  # sets AIP_MODEL_DIR for your script\n",
    "    sync=True,\n",
    ")\n",
    "\n",
    "print(\"Model + logs folder:\", ARTIFACT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f1f2a9",
   "metadata": {},
   "source": [
    "This launches a managed training job with Vertex AI. It should take 2-5 minutes for the training job to complete. \n",
    "\n",
    "### Understanding the training output message\n",
    "\n",
    "After your job finishes, you may see a message like: `Training did not produce a Managed Model returning None.` This is expected when running a `CustomTrainingJob` without specifying deployment parameters.  Vertex AI supports two modes:\n",
    "\n",
    "- **CustomTrainingJob (research/development)** – You control training and save models/logs to Cloud Storage via `AIP_MODEL_DIR`. This is ideal for experimentation and cost control.\n",
    "- **TrainingPipeline (for deployment)** – You include `model_serving_container_image_uri` and `model_display_name`, and Vertex automatically registers a *Managed Model* in the Model Registry for deployment to an endpoint.\n",
    "\n",
    "In our setup, we're intentionally using the simpler **CustomTrainingJob** path. Your trained model is safely stored under your specified artifact directory (e.g., `gs://{BUCKET_NAME}/artifacts/xgb/{RUN_ID}/`), and you can later register or deploy it manually when ready.\n",
    "\n",
    "\n",
    "## Monitoring training jobs in the Console\n",
    "1. Go to the Google Cloud Console.  \n",
    "2. Navigate to **Vertex AI > Training > Custom Jobs**.  \n",
    "3. Click on your job name to see status, logs, and output model artifacts.  \n",
    "4. Cancel jobs from the console if needed (be careful not to stop jobs you don't own in shared projects).\n",
    "\n",
    "#### Visit \"training pipelines\" to verify it's running.\n",
    "\n",
    "https://console.cloud.google.com/vertex-ai/training/training-pipelines?hl=en&project=doit-rci-mlm25-4626\n",
    "\n",
    "## Training artifacts\n",
    "\n",
    "After the training run completes, we can manually view our bucket using the Google Cloud Console or run the below code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883580ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size_bytes = 0\n",
    "# bucket = client.bucket(BUCKET_NAME)\n",
    "\n",
    "for blob in client.list_blobs(BUCKET_NAME):\n",
    "    total_size_bytes += blob.size\n",
    "    print(blob.name)\n",
    "\n",
    "total_size_mb = total_size_bytes / (1024**2)\n",
    "print(f\"Total size of bucket '{BUCKET_NAME}': {total_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fc701e",
   "metadata": {},
   "source": [
    "#### Training Artifacts  →  `ARTIFACT_DIR`\n",
    "This is your *intended output location*, set via `base_output_dir`.  \n",
    "It contains everything your training script explicitly writes. In our case, this includes:\n",
    "\n",
    "- **`{BUCKET_NAME}/artifacts/xgb/{RUN_ID}/xgboost-model`** — Serialized XGBoost model (Booster) saved via `joblib`; reload later with `joblib.load()` for reuse or deployment.  \n",
    "\n",
    "\n",
    "#### System-Generated Files\n",
    "Additional system-generated files (e.g., Vertex's `.tar.gz` code package or `executor_output.json`) will appear under `.vertex_staging/` and can be safely ignored or auto-deleted via lifecycle rules.\n",
    "\n",
    "### When training takes too long  \n",
    "\n",
    "Two main options in Vertex AI:  \n",
    "\n",
    "**Option 1: Upgrade to more powerful machine types**  \n",
    "- The simplest way to reduce training time is to use a larger machine or add GPUs (e.g., T4, V100, A100).  \n",
    "- This works best for small or medium datasets (<10 GB) and avoids the coordination overhead of distributed training.  \n",
    "- GPUs and TPUs can accelerate deep learning workloads significantly.  \n",
    "\n",
    "**Option 2: Use distributed training with multiple replicas**  \n",
    "- Vertex AI supports distributed training for many frameworks.  \n",
    "- The dataset is split across replicas, each training a portion of the data with synchronized gradient updates.  \n",
    "- This approach is most useful for large datasets and long-running jobs.  \n",
    "\n",
    "**When distributed training makes sense**  \n",
    "- Dataset size exceeds 10–50 GB.  \n",
    "- Training on a single machine takes more than 10 hours.  \n",
    "- The model is a deep learning workload that scales naturally across GPUs or TPUs.  \n",
    "\n",
    "We will explore both options more in depth in the next episode when we train a neural network.\n",
    "\n",
    "::::::::::::::::::::::::::::::::::::: keypoints\n",
    "\n",
    "- **Environment initialization**: Use `aiplatform.init()` to set defaults for project, region, and bucket.  \n",
    "- **Local vs managed training**: Test locally before scaling into managed jobs.  \n",
    "- **Custom jobs**: Vertex AI lets you run scripts as managed training jobs using pre-built or custom containers.  \n",
    "- **Scaling**: Start small, then scale up to GPUs or distributed jobs as dataset/model size grows.  \n",
    "- **Monitoring**: Track job logs and artifacts in the Vertex AI Console.  \n",
    "\n",
    "::::::::::::::::::::::::::::::::::::::::::::::::"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
