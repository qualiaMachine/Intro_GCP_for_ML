{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f3ac06e",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Training Models in Vertex AI: PyTorch Example\"\n",
    "teaching: 20\n",
    "exercises: 10\n",
    "---\n",
    "\n",
    ":::::::::::::::::::::::::::::::::::::: questions\n",
    "\n",
    "- When should you consider a GPU (or TPU) instance for PyTorch training in Vertex AI, and what are the trade‑offs for small vs. large workloads?\n",
    "- How do you launch a script‑based training job and write **all** artifacts (model, metrics, logs) next to each other in GCS without deploying a managed model?\n",
    "\n",
    "::::::::::::::::::::::::::::::::::::::::::::::::\n",
    "\n",
    "::::::::::::::::::::::::::::::::::::: objectives\n",
    "\n",
    "- Prepare the Titanic dataset and save train/val arrays to compressed `.npz` files in GCS.\n",
    "- Submit a **CustomTrainingJob** that runs a PyTorch script and explicitly writes outputs to a chosen `gs://…/artifacts/.../` folder.\n",
    "- Co‑locate artifacts: `model.pt` (or `.joblib`), `metrics.json`, `eval_history.csv`, and `training.log` for reproducibility.\n",
    "- Choose CPU vs. GPU instances sensibly; understand when distributed training is (not) worth it.\n",
    "\n",
    "::::::::::::::::::::::::::::::::::::::::::::::::\n",
    "\n",
    "## Initial setup (controller notebook)\n",
    "\n",
    "## Initial setup (controller notebook)\n",
    "\n",
    "Open a fresh Jupyter notebook in Vertex AI Workbench. Select the **PyTorch** environment (kernel)\n",
    "\n",
    "Note: local PyTorch is only needed for local tests. Your **Vertex AI job** uses the container specified by `container_uri` (e.g., `pytorch-cpu.2-1` or `pytorch-gpu.2-1`), so it brings its own framework at run time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10367ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform, storage\n",
    "client = storage.Client()\n",
    "PROJECT_ID = client.project\n",
    "REGION = \"us-central1\"\n",
    "BUCKET_NAME = \"sinkorswim-johndoe-titanic\" # ADJUST to your bucket's name\n",
    "\n",
    "print(f\"project = {PROJECT_ID}\\nregion = {REGION}\\nbucket = {BUCKET_NAME}\")\n",
    "\n",
    "# Only used for the SDK's small packaging tarball.\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=f\"gs://{BUCKET_NAME}/.vertex_staging\") # store tar balls in staging folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532e2546",
   "metadata": {},
   "source": [
    "## Prepare data as `.npz`\n",
    "\n",
    "Why `.npz`?\n",
    "\n",
    "- Smaller, faster I/O than CSV for arrays.\n",
    "- Natural fit for `torch.utils.data.Dataset` / `DataLoader`.\n",
    "- One file can hold multiple arrays (`X_train`, `y_train`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4274f16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Load Titanic CSV (from local or GCS you've already downloaded to the notebook)\n",
    "bucket = client.bucket(BUCKET_NAME)\n",
    "blob = bucket.blob(\"titanic_train.csv\")\n",
    "df = pd.read_csv(io.BytesIO(blob.download_as_bytes()))\n",
    "\n",
    "# Minimal preprocessing to numeric arrays\n",
    "sex_enc = LabelEncoder().fit(df[\"Sex\"])            # Fit label encoder on 'Sex' column (male/female)\n",
    "df[\"Sex\"] = sex_enc.transform(df[\"Sex\"])           # Convert 'Sex' to numeric values (e.g., male=1, female=0)\n",
    "df[\"Embarked\"] = df[\"Embarked\"].fillna(\"S\")       # Replace missing embarkation ports with most common ('S')\n",
    "emb_enc = LabelEncoder().fit(df[\"Embarked\"])       # Fit label encoder on 'Embarked' column (S/C/Q)\n",
    "df[\"Embarked\"] = emb_enc.transform(df[\"Embarked\"]) # Convert embarkation categories to numeric codes\n",
    "df[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].median())   # Fill missing ages with median (robust to outliers)\n",
    "df[\"Fare\"] = df[\"Fare\"].fillna(df[\"Fare\"].median())# Fill missing fares with median to avoid NaNs\n",
    "\n",
    "X = df[[\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"Embarked\"]].values  # Select numeric feature columns as input\n",
    "y = df[\"Survived\"].values                                                # Target variable (1=survived, 0=did not survive)\n",
    "\n",
    "scaler = StandardScaler()                                                # Initialize standard scaler for standardization (best practice for neural net training)\n",
    "X = scaler.fit_transform(X)                                              # Scale features to mean=0, std=1 for stable training\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(                       # Split dataset into training and validation sets\n",
    "    X, y, test_size=0.2, random_state=42)                                # 80% training, 20% validation (fixed random seed)\n",
    "\n",
    "np.savez(\"/home/jupyter/train_data.npz\", X_train=X_train, y_train=y_train)             # Save training arrays to compressed .npz file\n",
    "np.savez(\"/home/jupyter/val_data.npz\",   X_val=X_val,   y_val=y_val)                   # Save validation arrays to compressed .npz file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e0de5f",
   "metadata": {},
   "source": [
    "We can then upload the files to our GCS bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c994dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to GCS\n",
    "bucket.blob(\"data/train_data.npz\").upload_from_filename(\"/home/jupyter/train_data.npz\")\n",
    "bucket.blob(\"data/val_data.npz\").upload_from_filename(\"/home/jupyter/val_data.npz\")\n",
    "print(\"Uploaded: gs://%s/data/train_data.npz and val_data.npz\" % BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b457aaff",
   "metadata": {},
   "source": [
    "## Minimal PyTorch training script (`train_nn.py`)\n",
    "\n",
    "Find this file in our repo: `Intro_GCP_for_ML/scripts/train_nn.py`. It does three things:\n",
    "1) loads `.npz` from local or GCS\n",
    "2) trains a tiny multilayer perceptron (MLP)\n",
    "3) **writes all outputs side‑by‑side** (model + metrics + eval history + training.log) to the same `--model_out` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fee863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCP_helpers/train_nn.py\n",
    "import argparse, io, json, os, sys\n",
    "import numpy as np\n",
    "import torch, torch.nn as nn\n",
    "from time import time\n",
    "\n",
    "#  small helpers for GCS/local I/O \n",
    "def _parent_dir(p):\n",
    "    return p.rsplit(\"/\", 1)[0] if p.startswith(\"gs://\") else (os.path.dirname(p) or \".\")\n",
    "\n",
    "def _write_bytes(path: str, data: bytes):\n",
    "    if path.startswith(\"gs://\"):\n",
    "        try:\n",
    "            import fsspec\n",
    "            with fsspec.open(path, \"wb\") as f:\n",
    "                f.write(data)\n",
    "        except Exception:\n",
    "            from google.cloud import storage\n",
    "            b, k = path[5:].split(\"/\", 1)\n",
    "            storage.Client().bucket(b).blob(k).upload_from_string(data)\n",
    "    else:\n",
    "        os.makedirs(_parent_dir(path), exist_ok=True)\n",
    "        with open(path, \"wb\") as f:\n",
    "            f.write(data)\n",
    "\n",
    "def _write_text(path: str, text: str):\n",
    "    _write_bytes(path, text.encode(\"utf-8\"))\n",
    "\n",
    "#  tiny MLP \n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, d_in):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(d_in, 32), nn.ReLU(),\n",
    "            nn.Linear(32, 16), nn.ReLU(),\n",
    "            nn.Linear(16, 1), nn.Sigmoid(),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class _Tee:\n",
    "    def __init__(self, *s): self.s = s\n",
    "    def write(self, d):\n",
    "        for x in self.s: x.write(d); x.flush()\n",
    "    def flush(self):\n",
    "        for x in self.s: x.flush()\n",
    "\n",
    "def main():\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"--train\", required=True)\n",
    "    ap.add_argument(\"--val\",   required=True)\n",
    "    ap.add_argument(\"--epochs\", type=int, default=100)\n",
    "    ap.add_argument(\"--learning_rate\", type=float, default=1e-3)\n",
    "    ap.add_argument(\"--model_out\", required=True, help=\"gs://…/artifacts/.../model.pt\")\n",
    "    args = ap.parse_args()\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # All artifacts will sit next to model_out\n",
    "    model_path = args.model_out\n",
    "    art_dir = _parent_dir(model_path)\n",
    "\n",
    "    # capture stdout/stderr\n",
    "    buf = io.StringIO()\n",
    "    orig_out, orig_err = sys.stdout, sys.stderr\n",
    "    sys.stdout = _Tee(sys.stdout, buf)\n",
    "    sys.stderr = _Tee(sys.stderr, buf)\n",
    "    log_path = f\"{art_dir}/training.log\"\n",
    "\n",
    "    try:\n",
    "        # Load npz (supports gs:// via fsspec)\n",
    "        def _npz_load(p):\n",
    "            if p.startswith(\"gs://\"):\n",
    "                import fsspec\n",
    "                with fsspec.open(p, \"rb\") as f:\n",
    "                    by = f.read()\n",
    "                return np.load(io.BytesIO(by))\n",
    "            else:\n",
    "                return np.load(p)\n",
    "        train = _npz_load(args.train)\n",
    "        val   = _npz_load(args.val)\n",
    "        Xtr, ytr = train[\"X_train\"].astype(\"float32\"), train[\"y_train\"].astype(\"float32\")\n",
    "        Xva, yva = val[\"X_val\"].astype(\"float32\"),   val[\"y_val\"].astype(\"float32\")\n",
    "\n",
    "        Xtr_t = torch.from_numpy(Xtr).to(device)\n",
    "        ytr_t = torch.from_numpy(ytr).view(-1,1).to(device)\n",
    "        Xva_t = torch.from_numpy(Xva).to(device)\n",
    "        yva_t = torch.from_numpy(yva).view(-1,1).to(device)\n",
    "\n",
    "        model = MLP(Xtr.shape[1]).to(device)\n",
    "        opt = torch.optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "        loss_fn = nn.BCELoss()\n",
    "\n",
    "        hist = []\n",
    "        t0 = time()\n",
    "        for ep in range(1, args.epochs+1):\n",
    "            model.train()\n",
    "            opt.zero_grad()\n",
    "            pred = model(Xtr_t)\n",
    "            loss = loss_fn(pred, ytr_t)\n",
    "            loss.backward(); opt.step()\n",
    "\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_loss = loss_fn(model(Xva_t), yva_t).item()\n",
    "            hist.append(val_loss)\n",
    "            if ep % 10 == 0 or ep == 1:\n",
    "                print(f\"epoch={ep} val_loss={val_loss:.4f}\")\n",
    "        print(f\"Training time: {time()-t0:.2f}s on {device}\")\n",
    "\n",
    "        # save model\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(f\"[INFO] Saved model: {model_path}\")\n",
    "\n",
    "        # metrics.json and eval_history.csv\n",
    "        import json\n",
    "        metrics = {\n",
    "            \"final_val_loss\": float(hist[-1]) if hist else None,\n",
    "            \"epochs\": int(args.epochs),\n",
    "            \"learning_rate\": float(args.learning_rate),\n",
    "            \"train_rows\": int(Xtr.shape[0]),\n",
    "            \"val_rows\": int(Xva.shape[0]),\n",
    "            \"features\": list(range(Xtr.shape[1])),\n",
    "            \"model_uri\": model_path,\n",
    "            \"device\": str(device),\n",
    "        }\n",
    "        from io import StringIO\n",
    "        _write_text(f\"{art_dir}/metrics.json\", json.dumps(metrics, indent=2))\n",
    "        csv = \"iter,val_loss\\n\" + \"\\n\".join(f\"{i+1},{v}\" for i, v in enumerate(hist))\n",
    "        _write_text(f\"{art_dir}/eval_history.csv\", csv)\n",
    "    finally:\n",
    "        # persist log and restore streams\n",
    "        try:\n",
    "            _write_text(log_path, buf.getvalue())\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] could not write log: {e}\")\n",
    "        sys.stdout, sys.stderr = orig_out, orig_err\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb85345",
   "metadata": {},
   "source": [
    "## Launch the training job (no base_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3279cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_ID = dt.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "ARTIFACT_DIR = f\"gs://{BUCKET_NAME}/artifacts/pytorch/{RUN_ID}\"\n",
    "MODEL_URI = f\"{ARTIFACT_DIR}/model.pt\"   # model + metrics + logs will live here together\n",
    "\n",
    "job = aiplatform.CustomTrainingJob(\n",
    "    display_name=f\"pytorch_nn_{RUN_ID}\",\n",
    "    script_path=\"GCP_helpers/train_nn.py\",\n",
    "    container_uri=\"us-docker.pkg.dev/vertex-ai/training/pytorch-cpu.2-1:latest\",  # or pytorch-gpu.2-1\n",
    "    requirements=[\"torch\", \"numpy\", \"fsspec\", \"gcsfs\"],\n",
    ")\n",
    "\n",
    "job.run(\n",
    "    args=[\n",
    "        f\"--train=gs://{BUCKET_NAME}/data/train_data.npz\",\n",
    "        f\"--val=gs://{BUCKET_NAME}/data/val_data.npz\",\n",
    "        f\"--epochs=200\",\n",
    "        f\"--learning_rate=0.001\",\n",
    "        f\"--model_out={MODEL_URI}\",   # drives where *all* artifacts go\n",
    "    ],\n",
    "    replica_count=1,\n",
    "    machine_type=\"n1-standard-4\",  # CPU fine for small datasets\n",
    "    sync=True,\n",
    ")\n",
    "\n",
    "print(\"Artifacts folder:\", ARTIFACT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda6dfe3",
   "metadata": {},
   "source": [
    "**What you’ll see in `gs://…/artifacts/pytorch/<RUN_ID>/`:**\n",
    "- `model.pt` — PyTorch weights (`state_dict`).\n",
    "- `metrics.json` — final val loss, hyperparameters, dataset sizes, device, model URI.\n",
    "- `eval_history.csv` — per‑epoch validation loss (for plots/regression checks).\n",
    "- `training.log` — complete stdout/stderr for reproducibility and debugging.\n",
    "\n",
    "## Optional: GPU training\n",
    "\n",
    "For larger models or heavier data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36a2de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = aiplatform.CustomTrainingJob(\n",
    "    display_name=f\"pytorch_nn_gpu_{RUN_ID}\",\n",
    "    script_path=\"GCP_helpers/train_nn.py\",\n",
    "    container_uri=\"us-docker.pkg.dev/vertex-ai/training/pytorch-gpu.2-1:latest\",\n",
    "    requirements=[\"torch\", \"numpy\", \"fsspec\", \"gcsfs\"],\n",
    ")\n",
    "\n",
    "job.run(\n",
    "    args=[\n",
    "        f\"--train=gs://{BUCKET_NAME}/data/train_data.npz\",\n",
    "        f\"--val=gs://{BUCKET_NAME}/data/val_data.npz\",\n",
    "        f\"--epochs=200\",\n",
    "        f\"--learning_rate=0.001\",\n",
    "        f\"--model_out={MODEL_URI}\",\n",
    "    ],\n",
    "    replica_count=1,\n",
    "    machine_type=\"n1-standard-8\",\n",
    "    accelerator_type=\"NVIDIA_TESLA_T4\",\n",
    "    accelerator_count=1,\n",
    "    sync=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b492d61",
   "metadata": {},
   "source": [
    "GPU tips:\n",
    "- On small problems, GPU startup/transfer overhead can erase speedups—benchmark before you scale.\n",
    "- Stick to a single replica unless your batch sizes and dataset really warrant data parallelism.\n",
    "\n",
    "## Distributed training (when to consider)\n",
    "\n",
    "- **Data parallelism** (DDP) helps when a single GPU is saturated by batch size/throughput. For most workshop‑scale models, a single machine/GPU is simpler and cheaper.\n",
    "- **Model parallelism** is for very large networks that don’t fit on one device—overkill for this lesson.\n",
    "\n",
    "## Monitoring jobs & finding outputs\n",
    "\n",
    "- Console → Vertex AI → Training → Custom Jobs → your run → “Output directory” shows the container logs and the environment’s `AIP_MODEL_DIR`.\n",
    "- Your script writes **model + metrics + eval history + training.log** next to `--model_out`, e.g., `gs://<bucket>/artifacts/pytorch/<RUN_ID>/`.\n",
    "\n",
    "::::::::::::::::::::::::::::::::::::: keypoints\n",
    "\n",
    "- Use **CustomTrainingJob** with a prebuilt PyTorch container; let your script control outputs via `--model_out`.\n",
    "- Keep artifacts **together** (model, metrics, history, log) in one folder for reproducibility.\n",
    "- `.npz` speeds up loading and plays nicely with PyTorch.\n",
    "- Start on CPU for small datasets; use GPU only when profiling shows a clear win.\n",
    "- Skip `base_output_dir` unless you specifically want Vertex’s default run directory; staging bucket is just for the SDK packaging tarball.\n",
    "\n",
    "::::::::::::::::::::::::::::::::::::::::::::::::"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
