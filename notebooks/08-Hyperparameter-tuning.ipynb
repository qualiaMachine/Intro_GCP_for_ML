{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "696a9be0",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Hyperparameter Tuning in Vertex AI: Neural Network Example\"\n",
    "teaching: 60\n",
    "exercises: 0\n",
    "---\n",
    "\n",
    ":::::::::::::::::::::::::::::::::::::: questions \n",
    "\n",
    "- How can we efficiently manage hyperparameter tuning in Vertex AI?  \n",
    "- How can we parallelize tuning jobs to optimize time without increasing costs?  \n",
    "\n",
    "::::::::::::::::::::::::::::::::::::::::::::::::\n",
    "\n",
    "::::::::::::::::::::::::::::::::::::: objectives\n",
    "\n",
    "- Set up and run a hyperparameter tuning job in Vertex AI.  \n",
    "- Define search spaces for `ContinuousParameter` and `CategoricalParameter`.  \n",
    "- Log and capture objective metrics for evaluating tuning success.  \n",
    "- Optimize tuning setup to balance cost and efficiency, including parallelization.  \n",
    "\n",
    "::::::::::::::::::::::::::::::::::::::::::::::::\n",
    "\n",
    "To conduct efficient hyperparameter tuning with neural networks (or any model) in Vertex AI, we’ll use Vertex AI’s **Hyperparameter Tuning Jobs**. The key is defining a clear search space, ensuring metrics are properly logged, and keeping costs manageable by controlling the number of trials and level of parallelization.\n",
    "\n",
    "### Key steps for hyperparameter tuning\n",
    "\n",
    "The overall process involves these steps:\n",
    "\n",
    "1. Prepare training script and ensure metrics are logged.  \n",
    "2. Define hyperparameter search space.  \n",
    "3. Configure a hyperparameter tuning job in Vertex AI.  \n",
    "4. Set data paths and launch the tuning job.  \n",
    "5. Monitor progress in the Vertex AI Console.  \n",
    "6. Extract best model and evaluate.  \n",
    "\n",
    "#### 0. Directory setup\n",
    "Change directory to your Jupyter home folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0052a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/jupyter/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7dc049",
   "metadata": {},
   "source": [
    "#### 1. Prepare training script with metric logging\n",
    "Your training script (`train_nn.py`) should periodically print validation accuracy in a format that Vertex AI can capture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f18a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (epoch + 1) % 100 == 0 or epoch == epochs - 1:\n",
    "    print(f\"validation_accuracy: {val_accuracy:.4f}\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48b512a",
   "metadata": {},
   "source": [
    "Vertex AI automatically captures metrics logged in this format (`key: value`).  \n",
    "\n",
    "#### 2. Define hyperparameter search space\n",
    "\n",
    "In Vertex AI, you specify hyperparameter ranges when configuring the tuning job. You can define both discrete and continuous ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce15baea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "# Import the right classes directly\n",
    "from google.cloud.aiplatform import hyperparameter_tuning as hpt\n",
    "\n",
    "parameter_spec = {\n",
    "    \"epochs\": hpt.IntegerParameterSpec(min=100, max=1000, scale=\"linear\"),\n",
    "    \"learning_rate\": hpt.DoubleParameterSpec(min=0.001, max=0.1, scale=\"log\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8069fc",
   "metadata": {},
   "source": [
    "- **IntegerParameterSpec**: Defines integer ranges.  \n",
    "- **DoubleParameterSpec**: Defines continuous ranges, with optional scaling.  \n",
    "\n",
    "#### 3. Configure hyperparameter tuning job\n",
    "\n",
    "**Start with a max of 1 trials!** Scale up after confirming it's setup correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f4ac73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform, storage\n",
    "from google.cloud.aiplatform import hyperparameter_tuning as hpt\n",
    "import datetime as dt\n",
    "\n",
    "# --- project/region/bucket init ---\n",
    "client = storage.Client()\n",
    "PROJECT_ID = client.project\n",
    "REGION = \"us-central1\"\n",
    "LAST_NAME = \"DOE\"\n",
    "BUCKET_NAME = \"sinkorswim-johndoe-titanic\"  # ADJUST\n",
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    staging_bucket=f\"gs://{BUCKET_NAME}/.vertex_staging\",\n",
    ")\n",
    "\n",
    "# --- run IDs and output dir ---\n",
    "RUN_ID = dt.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "BASE_DIR = f\"gs://{BUCKET_NAME}/artifacts/pytorch_hpt/{RUN_ID}\"\n",
    "\n",
    "# --- training container (use TRAINING image) ---\n",
    "IMAGE = 'us-docker.pkg.dev/vertex-ai/training/pytorch-xla.2-4.py310:latest' # cpu-only version\n",
    "\n",
    "# --- machine/accelerator for each trial (CPU example) ---\n",
    "MACHINE = \"n1-standard-4\"\n",
    "ACCELERATOR_TYPE = None\n",
    "ACCELERATOR_COUNT = 0\n",
    "\n",
    "# --- search space (arg names must match train_nn.py argparse flags) ---\n",
    "parameter_spec = {\n",
    "    \"epochs\": hpt.IntegerParameterSpec(min=100, max=300, scale=\"linear\"),\n",
    "    \"learning_rate\": hpt.DoubleParameterSpec(min=1e-4, max=1e-1, scale=\"log\"),\n",
    "}\n",
    "\n",
    "metric_spec = {\"final_val_loss\": \"minimize\"}  # must match metrics.json key written by your script\n",
    "\n",
    "# --- build the trial job as a CustomJob; set compute + base_output_dir HERE ---\n",
    "custom_job = aiplatform.CustomJob.from_local_script(\n",
    "    display_name=f\"{LAST_NAME}_pytorch_hpt-trial_{RUN_ID}\",\n",
    "    script_path=\"Intro_GCP_for_ML/scripts/train_nn.py\",\n",
    "    container_uri=IMAGE,\n",
    "    args=[\n",
    "        f\"--train=gs://{BUCKET_NAME}/data/train_data.npz\",\n",
    "        f\"--val=gs://{BUCKET_NAME}/data/val_data.npz\",\n",
    "        \"--epochs=200\",\n",
    "        \"--learning_rate=0.001\",\n",
    "    ],\n",
    "    base_output_dir=BASE_DIR,\n",
    "    machine_type=MACHINE,\n",
    "    accelerator_type=\"ACCELERATOR_TYPE_UNSPECIFIED\",  # explicitly no GPU\n",
    "    accelerator_count=0,                              # also required\n",
    ")\n",
    "\n",
    "# --- create and run the HPT job (no base_output_dir or machine args here) ---\n",
    "DISPLAY_NAME = f\"{LAST_NAME}_pytorch_hpt_{RUN_ID}\" # since we're in a shared account envirnoment, we'll add our name to the training job to more easily track these jobs down in the Console\n",
    "tuning_job = aiplatform.HyperparameterTuningJob(\n",
    "    display_name=DISPLAY_NAME,\n",
    "    custom_job=custom_job,                 # must be a CustomJob (not CustomTrainingJob)\n",
    "    metric_spec=metric_spec,\n",
    "    parameter_spec=parameter_spec,\n",
    "    max_trial_count=10,\n",
    "    parallel_trial_count=2,\n",
    ")\n",
    "\n",
    "tuning_job.run(sync=True)  # just launch; compute/output were set on the CustomJob above\n",
    "\n",
    "print(\"HPT artifacts base:\", BASE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e311845",
   "metadata": {},
   "source": [
    "- **max_trial_count**: Total number of configurations tested.  \n",
    "- **parallel_trial_count**: Number of trials run at once (recommend ≤4 to let adaptive search improve).  \n",
    "\n",
    "#### 5. Monitor tuning job in Vertex AI Console\n",
    "1. Navigate to **Vertex AI > Training > Hyperparameter tuning jobs**.  \n",
    "2. View trial progress, logs, and metrics.  \n",
    "3. Cancel jobs from the console if needed.  \n",
    "\n",
    "#### 6. Extract and evaluate the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753f440a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial = hpt_job.trials[0]  # Best trial listed first after completion\n",
    "print(\"Best hyperparameters:\", best_trial.parameters)\n",
    "print(\"Best objective value:\", best_trial.final_measurement.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5be36b8",
   "metadata": {},
   "source": [
    "You can then load the best model artifact from the associated GCS path and evaluate on test data.\n",
    "\n",
    "::::::::::::::::::::::::::::::::::::: discussion\n",
    "\n",
    "### What is the effect of parallelism in tuning?  \n",
    "\n",
    "- How might running 10 trials in parallel differ from running 2 at a time in terms of cost, time, and quality of results?  \n",
    "- When would you want to prioritize speed over adaptive search benefits?  \n",
    "\n",
    "::::::::::::::::::::::::::::::::::::::::::::::::\n",
    "\n",
    "::::::::::::::::::::::::::::::::::::: keypoints\n",
    "\n",
    "- Vertex AI Hyperparameter Tuning Jobs let you efficiently explore parameter spaces using adaptive strategies.  \n",
    "- Always test with `max_trial_count=1` first to confirm your setup works.  \n",
    "- Limit `parallel_trial_count` to a small number (2–4) to benefit from adaptive search.  \n",
    "- Use GCS for input/output and monitor jobs through the Vertex AI Console.  \n",
    "\n",
    "::::::::::::::::::::::::::::::::::::::::::::::::"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
