<!DOCTYPE html>
<!-- START: inst/pkgdown/templates/layout.html --><!-- Generated by pkgdown: do not edit by hand --><html lang="en" data-bs-theme="auto"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><title>Intro to Google Cloud Platform (GCP) for Machine Learning: Compute for ML</title><meta name="viewport" content="width=device-width, initial-scale=1"><script src="assets/themetoggle.js"></script><link rel="stylesheet" type="text/css" href="assets/styles.css"><script src="assets/scripts.js" type="text/javascript"></script><!-- mathjax --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/PreviewHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
      TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      },
      tex2jax: {
        inlineMath: [['\\(', '\\)']],
        displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
        processEscapes: true
      }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><!-- Responsive Favicon for The Carpentries --><link rel="apple-touch-icon" sizes="180x180" href="favicons/incubator/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="favicons/incubator/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="favicons/incubator/favicon-16x16.png"><link rel="manifest" href="favicons/incubator/site.webmanifest"><link rel="mask-icon" href="favicons/incubator/safari-pinned-tab.svg" color="#5bbad5"><meta name="msapplication-TileColor" content="#da532c"><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"><meta name="theme-color" media="(prefers-color-scheme: dark)" content="black"></head><body>
    <header id="top" class="navbar navbar-expand-md top-nav incubator"><svg xmlns="http://www.w3.org/2000/svg" class="d-none"><symbol id="check2" viewbox="0 0 16 16"><path d="M13.854 3.646a.5.5 0 0 1 0 .708l-7 7a.5.5 0 0 1-.708 0l-3.5-3.5a.5.5 0 1 1 .708-.708L6.5 10.293l6.646-6.647a.5.5 0 0 1 .708 0z"></path></symbol><symbol id="circle-half" viewbox="0 0 16 16"><path d="M8 15A7 7 0 1 0 8 1v14zm0 1A8 8 0 1 1 8 0a8 8 0 0 1 0 16z"></path></symbol><symbol id="moon-stars-fill" viewbox="0 0 16 16"><path d="M6 .278a.768.768 0 0 1 .08.858 7.208 7.208 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277.527 0 1.04-.055 1.533-.16a.787.787 0 0 1 .81.316.733.733 0 0 1-.031.893A8.349 8.349 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.752.752 0 0 1 6 .278z"></path><path d="M10.794 3.148a.217.217 0 0 1 .412 0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217 0 0 1 0 .412l-1.162.387a1.734 1.734 0 0 0-1.097 1.097l-.387 1.162a.217.217 0 0 1-.412 0l-.387-1.162A1.734 1.734 0 0 0 9.31 6.593l-1.162-.387a.217.217 0 0 1 0-.412l1.162-.387a1.734 1.734 0 0 0 1.097-1.097l.387-1.162zM13.863.099a.145.145 0 0 1 .274 0l.258.774c.115.346.386.617.732.732l.774.258a.145.145 0 0 1 0 .274l-.774.258a1.156 1.156 0 0 0-.732.732l-.258.774a.145.145 0 0 1-.274 0l-.258-.774a1.156 1.156 0 0 0-.732-.732l-.774-.258a.145.145 0 0 1 0-.274l.774-.258c.346-.115.617-.386.732-.732L13.863.1z"></path></symbol><symbol id="sun-fill" viewbox="0 0 16 16"><path d="M8 12a4 4 0 1 0 0-8 4 4 0 0 0 0 8zM8 0a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 0zm0 13a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 13zm8-5a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2a.5.5 0 0 1 .5.5zM3 8a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2A.5.5 0 0 1 3 8zm10.657-5.657a.5.5 0 0 1 0 .707l-1.414 1.415a.5.5 0 1 1-.707-.708l1.414-1.414a.5.5 0 0 1 .707 0zm-9.193 9.193a.5.5 0 0 1 0 .707L3.05 13.657a.5.5 0 0 1-.707-.707l1.414-1.414a.5.5 0 0 1 .707 0zm9.193 2.121a.5.5 0 0 1-.707 0l-1.414-1.414a.5.5 0 0 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .707zM4.464 4.465a.5.5 0 0 1-.707 0L2.343 3.05a.5.5 0 1 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .708z"></path></symbol></svg><a class="visually-hidden-focusable skip-link" href="#main-content">Skip to main content</a>
  <div class="container-fluid top-nav-container">
    <div class="col-md-8">
      <div class="large-logo">
        <img id="incubator-logo" alt="Lesson Description" src="assets/images/incubator-logo.svg"><span class="badge text-bg-danger">
          <abbr title="This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught.">
            <a href="https://docs.carpentries.org/resources/curriculum/lesson-life-cycle.html" class="external-link alert-link">
              <i aria-hidden="true" class="icon" data-feather="alert-octagon" style="border-radius: 5px"></i>
              Pre-Alpha
            </a>
            <span class="visually-hidden">This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught.</span>
          </abbr>
        </span>

      </div>
    </div>
    <div class="selector-container">
      <div id="theme-selector">
        <li class="nav-item dropdown" id="theme-button-list">
          <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
            <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="bd-theme-text"><li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                Light
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                Dark
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                Auto
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
          </ul></li>
      </div>

      <div class="dropdown" id="instructor-dropdown">
        <button class="btn btn-secondary dropdown-toggle bordered-button" type="button" id="dropdownMenu1" data-bs-toggle="dropdown" aria-expanded="false">
          <i aria-hidden="true" class="icon" data-feather="eye"></i> Learner View <i data-feather="chevron-down"></i>
        </button>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1"><li><button class="dropdown-item" type="button" onclick="window.location.href='instructor/instances-for-ML.html';">Instructor View</button></li>
        </ul></div>
    </div>
  </div>
  <hr></header><nav class="navbar navbar-expand-xl bottom-nav incubator" aria-label="Main Navigation"><div class="container-fluid nav-container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle Navigation">
      <span class="navbar-toggler-icon"></span>
      <span class="menu-title">Menu</span>
    </button>
    <div class="nav-logo">
      <img class="small-logo" alt="Lesson Description" src="assets/images/incubator-logo-sm.svg"></div>
    <div class="lesson-title-md">
      Intro to Google Cloud Platform (GCP) for Machine Learning
    </div>
    <div class="search-icon-sm">
      <!-- TODO: do not show until we have search
        <i role="img" aria-label="Search the All In One page" data-feather="search"></i>
      -->
    </div>
    <div class="desktop-nav">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0"><li class="nav-item">
          <span class="lesson-title">
            Intro to Google Cloud Platform (GCP) for Machine Learning
          </span>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="key-points.html">Key Points</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="reference.html#glossary">Glossary</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="profiles.html">Learner Profiles</a>
        </li>
        <li class="nav-item dropdown">
          <button class="nav-link dropdown-toggle" id="navbarDropdown" data-bs-toggle="dropdown" aria-expanded="false">
            More <i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdown"><li><a class="dropdown-item" href="glossary.html">Glossary</a></li><li><a class="dropdown-item" href="instances-for-ML.html">Compute for ML</a></li>
          </ul></li>
      </ul></div>
    <!--
    <form class="d-flex col-md-2 search-form">
      <fieldset disabled>
      <input class="form-control me-2 searchbox" type="search" placeholder="" aria-label="">
        <button class="btn btn-outline-success tablet-search-button"  type="submit">
          <i class="search-icon" data-feather="search" role="img" aria-label="Search the All In One page"></i>
        </button>
      </fieldset>
    </form>
    -->
    <a id="search-button" class="btn btn-primary" href="aio.html" role="button" aria-label="Search the All In One page">Search the All In One page</a>
  </div><!--/div.container-fluid -->
</nav><div class="col-md-12 mobile-title">
  Intro to Google Cloud Platform (GCP) for Machine Learning
</div>

<aside class="col-md-12 lesson-progress"><div style="width: NA%" class="percentage">
    NA%
  </div>
  <div class="progress incubator">
    <div class="progress-bar incubator" role="progressbar" style="width: NA%" aria-valuenow="NA" aria-label="Lesson Progress" aria-valuemin="0" aria-valuemax="100">
    </div>
  </div>
</aside><div class="container">
      <div class="row">
        <!-- START: inst/pkgdown/templates/navbar.html -->
<div id="sidebar-col" class="col-lg-4">
  <div id="sidebar" class="sidebar">
      <nav aria-labelledby="flush-headingEleven"><button role="button" aria-label="close menu" alt="close menu" aria-expanded="true" aria-controls="sidebar" class="collapse-toggle" data-collapse="Collapse " data-episodes="Episodes ">
          <i class="search-icon" data-feather="x" role="img"></i>
        </button>
        <div class="sidebar-inner">
          <div class="row mobile-row" id="theme-row-mobile">
            <div class="col" id="theme-selector">
              <li class="nav-item dropdown" id="theme-button-list">
                <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
                  <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><span class="d-lg-none ms-1" id="bd-theme-text">Toggle Theme</span>
                </button>
                <ul class="dropdown-menu dropdown-menu-right" aria-labelledby="bd-theme-text"><li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                      Light
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                      Dark
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                      <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                      Auto
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                </ul></li>
            </div>
          </div>
          <div class="row mobile-row">
            <div class="col">
              <div class="sidenav-view-selector">
                <div class="accordion accordion-flush" id="accordionFlush9">
                  <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingNine">
                      <button class="accordion-button collapsed" id="instructor" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseNine" aria-expanded="false" aria-controls="flush-collapseNine">
                        <i id="eye" aria-hidden="true" class="icon" data-feather="eye"></i> Learner View
                      </button>
                    </h2>
                    <div id="flush-collapseNine" class="accordion-collapse collapse" aria-labelledby="flush-headingNine" data-bs-parent="#accordionFlush2">
                      <div class="accordion-body">
                        <a href="instructor/instances-for-ML.html">Instructor View</a>
                      </div>
                    </div>
                  </div><!--/div.accordion-item-->
                </div><!--/div.accordion-flush-->
              </div><!--div.sidenav-view-selector -->
            </div><!--/div.col -->

            <hr></div><!--/div.mobile-row -->

          <div class="accordion accordion-flush" id="accordionFlush11">
            <div class="accordion-item">

              <button id="chapters" class="accordion-button show" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseEleven" aria-expanded="false" aria-controls="flush-collapseEleven">
                <h2 class="accordion-header chapters" id="flush-headingEleven">
                  EPISODES
                </h2>
              </button>
              <div id="flush-collapseEleven" class="accordion-collapse show collapse" aria-labelledby="flush-headingEleven" data-bs-parent="#accordionFlush11">

                <div class="accordion-body">
                  <div class="accordion accordion-flush" id="accordionFlush1">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading1">
        <a href="index.html">Summary and Setup</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush2">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading2">
        <a href="01-Introduction.html">1. Overview of Google Cloud for Machine Learning</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush3">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading3">
        <a href="02-Data-storage.html">2. Data Storage: Setting up GCS</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush4">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading4">
        <a href="03-Notebooks-as-controllers.html">3. Notebooks as Controllers</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush5">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading5">
        <a href="04-Accessing-and-managing-data.html">4. Accessing and Managing Data in GCS with Vertex AI Notebooks</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush6">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading6">
        <a href="05-Interacting-with-code-repo.html">5. Using a GitHub Personal Access Token (PAT) to Push/Pull from a Vertex AI Notebook</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush7">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading7">
        <a href="06-Training-models-in-VertexAI.html">6. Training Models in Vertex AI: Intro</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush8">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading8">
        <a href="07-Training-models-in-VertexAI-GPUs.html">7. Training Models in Vertex AI: PyTorch Example</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush9">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading9">
        <a href="08-Hyperparameter-tuning.html">8. Hyperparameter Tuning in Vertex AI: Neural Network Example</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush10">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading10">
        <a href="09-Resource-management-cleanup.html">9. Resource Management &amp; Monitoring on Vertex AI (GCP)</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

                </div>
              </div>
            </div>

            <hr class="half-width"><div class="accordion accordion-flush lesson-resources" id="accordionFlush12">
              <div class="accordion-item">
                <h2 class="accordion-header" id="flush-headingTwelve">
                  <button class="accordion-button collapsed" id="lesson-resources" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwelve" aria-expanded="false" aria-controls="flush-collapseTwelve">
                    RESOURCES
                  </button>
                </h2>
                <div id="flush-collapseTwelve" class="accordion-collapse collapse" aria-labelledby="flush-headingTwelve" data-bs-parent="#accordionFlush12">
                  <div class="accordion-body">
                    <ul><li>
                        <a href="key-points.html">Key Points</a>
                      </li>
                      <li>
                        <a href="reference.html#glossary">Glossary</a>
                      </li>
                      <li>
                        <a href="profiles.html">Learner Profiles</a>
                      </li>
                      <li><a href="glossary.html">Glossary</a></li><li><a href="instances-for-ML.html">Compute for ML</a></li>
                    </ul></div>
                </div>
              </div>
            </div>
            <hr class="half-width lesson-resources"><a href="aio.html">See all in one page</a>


            <hr class="d-none d-sm-block d-md-none"><div class="d-grid gap-1">

            </div>
          </div><!-- /div.accordion -->
        </div><!-- /div.sidebar-inner -->
      </nav></div><!-- /div.sidebar -->
  </div><!-- /div.sidebar-col -->
<!-- END:   inst/pkgdown/templates/navbar.html-->

        <!-- START: inst/pkgdown/templates/content-instructor.html -->
  <div class="col-xl-8 col-lg-12 primary-content">
    <nav class="lesson-content mx-md-4" aria-label="Previous and Next Chapter"><!-- content for small screens --><div class="d-block d-sm-block d-md-none">
        <a class="chapter-link" href="index.html"><i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>Previous</a>
        <a class="chapter-link float-end" href="index.html">Next<i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i></a>
      </div>
      <!-- content for large screens -->
      <div class="d-none d-sm-none d-md-block">
        <a class="chapter-link" href="index.html" rel="prev">
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>
          Home
        </a>
        <a class="chapter-link float-end" href="index.html" rel="next">
          Home
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i>
        </a>
      </div>
      <hr></nav><main id="main-content" class="main-content"><div class="container lesson-content">
        <h1>Compute for ML</h1>
        <p>Last updated on 2025-10-29 |

        <a href="https://github.com/qualiaMachine/Intro_GCP_VertexAI/edit/main/learners/instances-for-ML.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>



        <div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>

        

<p>This page provides guidance for selecting compute configurations in
Google Cloud Platform (GCP) for machine learning workloads. While
instance size is an important factor, effective performance depends on
how you pair a machine type with optional GPU accelerators.</p>
<p>All pricing estimates are based on public rates for
<code>us-central1</code> as of October 2025. Actual cost depends on
sustained-use discounts, attached GPU quotas, and whether your project
has promotional or educational credits.</p>
<div class="section level3">
<h3 id="reference-docs">Reference Docs<a class="anchor" aria-label="anchor" href="#reference-docs"></a></h3>
<ul><li><a href="https://cloud.google.com/compute/vm-instance-pricing" class="external-link">Compute
Engine VM Instance Pricing (applies to notebook backends)</a></li>
<li><a href="https://cloud.google.com/compute/gpus-pricing" class="external-link">Compute
Engine GPU Pricing</a></li>
<li><a href="https://cloud.google.com/compute/all-pricing" class="external-link">All Compute
Pricing Overview</a></li>
</ul></div>
<div class="section level3">
<h3 id="key-terms">Key Terms<a class="anchor" aria-label="anchor" href="#key-terms"></a></h3>
<ul><li>
<strong>vCPU</strong>: A <em>virtual CPU</em> represents one logical
core allocated from a physical CPU. Two vCPUs typically correspond to
one physical core on GCP hardware. More vCPUs allow for greater
parallelism — useful when loading data, performing CPU-heavy
preprocessing, or running multi-threaded operations. In GCP machine
types, memory (RAM) generally scales with vCPUs — doubling vCPUs usually
doubles available memory.<br></li>
<li>
<strong>Memory (GiB)</strong>: System RAM available to the VM.
Higher RAM supports larger batch sizes, data caching, and in-memory
preprocessing, reducing disk I/O overhead.<br></li>
<li>
<strong>GPU (Graphics Processing Unit)</strong>: Specialized
hardware for parallel tensor operations used in deep learning model
training and inference.<br></li>
<li>
<strong>Machine type</strong>: Defines CPU and RAM resources;
determines how many vCPUs and how much memory your instance has.<br></li>
<li>
<strong>Machine family</strong>: A group of machine types optimized
for a specific balance of performance, memory, and cost (e.g.,
<code>n2-standard-8</code>).<br></li>
<li>
<strong>Accelerator</strong>: Optional hardware (such as GPUs or
TPUs) that can be attached to certain VM families to speed up training
and inference.</li>
<li>
<strong>Accelerator count</strong>: Defines how many GPUs are
attached to a single VM. Most training jobs begin with
<code>accelerator_count=1</code>. Increasing the count (for example, to
2, 4, or 8) enables multi-GPU training, but it also requires
proportional increases in CPU, memory, and disk I/O to feed data
efficiently to all GPUs. Performance scaling is rarely linear — expect
diminishing returns beyond 2–4 GPUs unless your model and batch sizes
are very large.<br></li>
<li>
<strong>Region</strong>: The physical location of your compute
resources (e.g., <code>us-central1</code>). Pricing and GPU availability
can vary by region.</li>
</ul></div>
<div class="section level3">
<h3 id="key-concepts">Key Concepts<a class="anchor" aria-label="anchor" href="#key-concepts"></a></h3>
<ul><li>
<strong>Machine type vs. GPU</strong>: The <code>machine_type</code>
defines CPU and RAM resources — it is not a GPU by itself. You can
attach a GPU by adding <code>accelerator_type</code> and
<code>accelerator_count</code> (for example, <code>NVIDIA_L4</code> or
<code>NVIDIA_TESLA_T4</code>). Only specialized machine families like
<code>A2</code> include GPUs automatically.<br></li>
<li>
<strong>Full names and syntax</strong>: Machine types follow the
pattern <code>&lt;family&gt;-&lt;series&gt;-&lt;vCPU count&gt;</code>.
For example:
<ul><li>
<code>n2-standard-8</code>: 8 vCPUs, 32 GB RAM<br></li>
<li>
<code>c2-standard-8</code>: 8 vCPUs, 32 GB RAM (CPU-optimized)<br></li>
<li>
<code>a2-highgpu-1g</code>: 12 vCPUs, 85 GB RAM, and 1 attached A100
GPU<br></li>
</ul></li>
<li>
<strong>RAM requirements</strong>: Minimum RAM should be at least
1.5× dataset size unless your workflow uses batching.<br></li>
<li>
<strong>Free tier</strong>: Some smaller instance types (for
example, <code>e2-micro</code>) may qualify for the <a href="https://cloud.google.com/free" class="external-link">GCP Free Tier</a>. Check usage
limits before running persistent notebooks.</li>
</ul></div>
<div class="section level3">
<h3 id="machine-families-overview">Machine Families Overview<a class="anchor" aria-label="anchor" href="#machine-families-overview"></a></h3>
<p>Different machine families are optimized for different
workloads.<br>
Costs below are approximate per-hour rates for instances with 8 vCPUs in
the <code>us-central1</code> region.</p>
<table class="table"><colgroup><col width="8%"><col width="15%"><col width="21%"><col width="16%"><col width="30%"><col width="6%"></colgroup><thead><tr class="header"><th>Family</th>
<th>Optimized For</th>
<th>Example Machine Type</th>
<th>Approx. Cost/hr</th>
<th>Typical Model or Dataset Scale</th>
<th>Notes</th>
</tr></thead><tbody><tr class="odd"><td><code>E2</code></td>
<td>General purpose</td>
<td><code>e2-standard-8</code></td>
<td>~$0.25</td>
<td>Small jobs or lightweight scripts</td>
<td>Cheapest option; slower CPUs</td>
</tr><tr class="even"><td><code>N1</code></td>
<td>Balanced compute (older gen)</td>
<td><code>n1-standard-8</code></td>
<td>~$0.35</td>
<td>Small to mid-sized ML (&lt;100M params)</td>
<td>Broad GPU compatibility</td>
</tr><tr class="odd"><td><code>N2</code></td>
<td>Balanced compute (newer gen)</td>
<td><code>n2-standard-8</code></td>
<td>~$0.38</td>
<td>Mid-sized ML and RAG pipelines (100M–500M params)</td>
<td>Common choice for notebooks</td>
</tr><tr class="even"><td><code>C2</code></td>
<td>Compute optimized</td>
<td><code>c2-standard-8</code></td>
<td>~$0.45</td>
<td>CPU-heavy preprocessing or feature extraction</td>
<td>High single-thread performance</td>
</tr><tr class="odd"><td><code>C3</code></td>
<td>Next-gen compute optimized</td>
<td><code>c3-standard-8</code></td>
<td>~$0.50</td>
<td>High-performance CPU-only workloads</td>
<td>Faster I/O and networking</td>
</tr><tr class="even"><td><code>A2</code></td>
<td>GPU (A100)</td>
<td><code>a2-highgpu-1g</code></td>
<td>~$2.93 (with 1×A100)</td>
<td>Large DL models (0.5B–10B params)</td>
<td>Fixed GPU counts, quota required</td>
</tr><tr class="odd"><td><code>A3</code></td>
<td>GPU (H100)</td>
<td><code>a3-highgpu-8g</code></td>
<td>~$32.00 (with 8×H100)</td>
<td>Transformer-scale models (10B–70B params)</td>
<td>High throughput, limited quota</td>
</tr><tr class="even"><td><code>A4</code></td>
<td>GPU (B200)</td>
<td><code>a4-highgpu-4g</code></td>
<td>~$36.00 (with 4×B200)</td>
<td>Foundation models (70B+ params)</td>
<td>Highest-end, limited availability</td>
</tr><tr class="odd"><td>
<code>T2A</code> / <code>T2D</code>
</td>
<td>Arm or AMD CPUs</td>
<td><code>t2a-standard-8</code></td>
<td>~$0.20</td>
<td>Low-cost inference or lightweight workloads</td>
<td>No GPU support</td>
</tr></tbody></table><p><strong>Cost notes:</strong><br>
- Prices vary by region and storage/network configuration.<br>
- <code>N2</code> instances are a typical choice for cost-effective ML
workloads.<br>
- <code>A2–A4</code> families include GPUs by default; all others
require attaching GPUs manually.</p>
</div>
<div class="section level3">
<h3 id="attaching-gpus-vs--using-gpu-families">Attaching GPUs vs. Using GPU Families<a class="anchor" aria-label="anchor" href="#attaching-gpus-vs--using-gpu-families"></a></h3>
<p>Attaching a GPU to a standard CPU family (<code>n1</code>,
<code>n2</code>, or <code>c2</code>) is the most flexible and
cost-efficient setup for research and medium-scale workloads.<br>
Dedicated GPU families like <code>A2</code>, <code>A3</code>, and
<code>A4</code> are designed for very large or multi-GPU training but
come with higher fixed costs and quota requirements.</p>
<table class="table"><colgroup><col width="32%"><col width="32%"><col width="17%"><col width="17%"></colgroup><thead><tr class="header"><th>Approach</th>
<th>Best For</th>
<th>Pros</th>
<th>Cons</th>
</tr></thead><tbody><tr class="odd"><td>Attach GPU to Standard VM (<code>n1</code>/<code>n2</code> +
<code>NVIDIA_L4</code>/<code>T4</code>)</td>
<td>Fine-tuning, RAG pipelines, and large-scale inference with models up
to ~500M–1B params</td>
<td>Cheaper, flexible CPU/GPU balance, reusable for notebooks and
jobs</td>
<td>Not ideal for multi-GPU scaling</td>
</tr><tr class="even"><td>Use GPU Machine Family
(<code>A2</code>/<code>A3</code>/<code>A4</code>)</td>
<td>Multi-GPU training or high-throughput inference with models &gt;1B
params</td>
<td>High throughput, optimized GPU interconnects</td>
<td>Expensive, quota-restricted, fixed GPU count</td>
</tr></tbody></table><p>For large-scale RAG deployments using very large models (e.g., 7B–70B
parameters), <code>A2</code> or <code>A3</code> instances may be
required to hold the model in GPU memory during inference.<br>
However, when using model sharding or quantized models under 20–40 GB
total, attached L4 GPUs on <code>n2</code> machines remain
cost-effective.</p>
</div>
<div class="section level3">
<h3 id="typical-gpu-options-for-attached-configurations">Typical GPU Options for Attached Configurations<a class="anchor" aria-label="anchor" href="#typical-gpu-options-for-attached-configurations"></a></h3>
<table class="table"><colgroup><col width="9%"><col width="11%"><col width="15%"><col width="15%"><col width="13%"><col width="22%"><col width="11%"></colgroup><thead><tr class="header"><th>GPU Type</th>
<th>CUDA Version</th>
<th>Approx. Price/hr</th>
<th>Model Size Range</th>
<th>Dataset Scale</th>
<th>System RAM (Recommended)</th>
<th>Typical Use</th>
</tr></thead><tbody><tr class="odd"><td><code>NVIDIA_TESLA_T4</code></td>
<td>CUDA 11.x–12.x</td>
<td>~$0.35</td>
<td>≤100 M params</td>
<td>≤10 GB</td>
<td>≥16 GB</td>
<td>Entry GPU for CNNs, small transformers</td>
</tr><tr class="even"><td><code>NVIDIA_L4</code></td>
<td>CUDA 12.x</td>
<td>~$0.60</td>
<td>≤500 M–1 B params</td>
<td>≤50 GB</td>
<td>≥32 GB</td>
<td>Moderate training, RAG inference, fine-tuning</td>
</tr><tr class="odd"><td><code>NVIDIA_TESLA_V100</code></td>
<td>CUDA 11.x</td>
<td>~$2.48</td>
<td>0.5 B–2 B params</td>
<td>≤100 GB</td>
<td>≥64 GB</td>
<td>High-performance deep learning</td>
</tr><tr class="even"><td><code>NVIDIA_A100_40GB</code></td>
<td>CUDA 11.x–12.x</td>
<td>~$2.93</td>
<td>2 B–10 B params</td>
<td>≤200 GB</td>
<td>≥128 GB</td>
<td>Research-scale model training</td>
</tr><tr class="odd"><td><code>NVIDIA_H100</code></td>
<td>CUDA 12.x</td>
<td>~$4.00</td>
<td>10 B–70 B params</td>
<td>≤500 GB</td>
<td>≥256 GB</td>
<td>Transformer and LLM training/inference</td>
</tr><tr class="even"><td><code>NVIDIA_B200</code></td>
<td>CUDA 12.x</td>
<td>~$5.00+</td>
<td>&gt;70 B params</td>
<td>≥1 TB</td>
<td>≥512 GB</td>
<td>Foundation-model or multi-node workloads</td>
</tr></tbody></table></div>
<div class="section level3">
<h3 id="example-workload-choices">Example Workload Choices<a class="anchor" aria-label="anchor" href="#example-workload-choices"></a></h3>
<ul><li>
<strong>RAG with LLMs:</strong> Retrieval-augmented generation
pipelines rely mainly on CPU and memory for vector retrieval and
embedding operations, with moderate GPU usage during inference.
Recommended: <code>n2-standard-8</code> + <code>NVIDIA_L4</code> for
typical RAG; move to <code>a2-highgpu-1g</code> or
<code>a3-highgpu</code> if the model exceeds 1B parameters or GPU memory
limits.<br></li>
<li>
<strong>Training a 100M-parameter neural network:</strong> This
model size fits comfortably on a single mid-tier GPU and benefits from
faster GPU memory bandwidth. Recommended: <code>n1-standard-8</code> +
<code>NVIDIA_TESLA_T4</code> for affordability, or
<code>NVIDIA_L4</code> if training time matters more than cost.<br></li>
<li>
<strong>Multi-GPU or LLM fine-tuning (billions of
parameters):</strong> Large models (1B–70B parameters) often require
multiple A100, H100, or B200 GPUs in parallel. Recommended:
<code>a2-highgpu-2g</code> (2×A100) or larger depending on model size
and parallelism. Cost note: Fine-tuning billion-parameter models can
easily exceed $200–$500 per hour of GPU time. Even short fine-tunes may
consume hundreds of dollars in credits. Plan carefully, monitor
utilization, and test your pipeline with smaller models first.</li>
</ul></div>
<div class="section level3">
<h3 id="example-configurations">Example Configurations<a class="anchor" aria-label="anchor" href="#example-configurations"></a></h3>
<table class="table"><colgroup><col width="12%"><col width="27%"><col width="5%"><col width="13%"><col width="16%"><col width="13%"><col width="11%"></colgroup><thead><tr class="header"><th>Dataset Size</th>
<th>Recommended Notebook Instance</th>
<th>vCPU</th>
<th>Memory (GiB)</th>
<th>GPU / Accelerator</th>
<th>Price/hr (USD)</th>
<th>Typical Use</th>
</tr></thead><tbody><tr class="odd"><td>&lt; 1 GB</td>
<td>
<code>e2-micro</code> (Free Tier)</td>
<td>2</td>
<td>1</td>
<td>None</td>
<td>Free Tier</td>
<td>Lightweight code tests</td>
</tr><tr class="even"><td>&lt; 1 GB</td>
<td><code>n2-standard-4</code></td>
<td>4</td>
<td>16</td>
<td>None</td>
<td>~$0.17</td>
<td>Preprocessing, regression, small models</td>
</tr><tr class="odd"><td>&lt; 1 GB</td>
<td>
<code>n1-standard-8</code> + <code>NVIDIA_TESLA_T4</code>
</td>
<td>8</td>
<td>30</td>
<td>1× T4</td>
<td>~$0.55</td>
<td>Entry GPU runs, small CNNs</td>
</tr><tr class="even"><td>10 GB</td>
<td><code>c2-standard-8</code></td>
<td>8</td>
<td>32</td>
<td>None</td>
<td>~$0.34</td>
<td>CPU-heavy ML tasks</td>
</tr><tr class="odd"><td>10 GB</td>
<td>
<code>n2-standard-8</code> + <code>NVIDIA_L4</code>
</td>
<td>8</td>
<td>32</td>
<td>1× L4</td>
<td>~$0.75</td>
<td>Moderate deep learning workloads</td>
</tr><tr class="even"><td>50 GB</td>
<td>
<code>a2-highgpu-2g</code> (2× A100)</td>
<td>24</td>
<td>170</td>
<td>2× A100</td>
<td>~$5.90</td>
<td>Multi-GPU training, large-model inference</td>
</tr><tr class="odd"><td>100 GB</td>
<td>
<code>a3-highgpu-8g</code> (8× H100)</td>
<td>128</td>
<td>512</td>
<td>8× H100</td>
<td>~$32.00</td>
<td>Transformer or LLM fine-tuning</td>
</tr><tr class="even"><td>1 TB+</td>
<td>
<code>a4-highgpu-4g</code> (4× B200)</td>
<td>96</td>
<td>768</td>
<td>4× B200</td>
<td>~$36.00</td>
<td>Foundation-model scale training</td>
</tr></tbody></table></div>
<div class="section level3">
<h3 id="general-notes">General Notes<a class="anchor" aria-label="anchor" href="#general-notes"></a></h3>
<ul><li>For small datasets, CPUs are often faster to start and cheaper to
run.<br></li>
<li>When moving from CPU to GPU training, keep the same script and
simply change:
<ul><li><p><code>container_uri</code> to a GPU-enabled image (for example,
<code>pytorch-gpu.*</code>)</p></li>
<li>
<p>Add both <code>accelerator_type</code> and
<code>accelerator_count</code> in your <code>CustomTrainingJob</code>.
For example:</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a>job.run(</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a>    machine_type<span class="op">=</span><span class="st">"n2-standard-8"</span>,</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a>    accelerator_type<span class="op">=</span><span class="st">"NVIDIA_L4"</span>,</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a>    accelerator_count<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a>    base_output_dir<span class="op">=</span>ARTIFACTS,</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a>)</span></code></pre>
</div>
</li>
<li><p>Increasing <code>accelerator_count</code> (e.g., 2–4) enables
parallel training but requires larger datasets and batch sizes to avoid
idle GPUs.</p></li>
</ul></li>
</ul></div>
<div class="section level3">
<h3 id="summary">Summary<a class="anchor" aria-label="anchor" href="#summary"></a></h3>
<ol style="list-style-type: decimal"><li>Choose the <code>machine_type</code> for CPU and memory
resources.<br></li>
<li>Attach a GPU with <code>accelerator_type</code> and
<code>accelerator_count</code> if needed.<br></li>
<li>Only <code>A2</code>, <code>A3</code>, and <code>A4</code> families
include GPUs automatically.<br></li>
<li>For most research training jobs, <code>n1-standard-8</code> +
<code>NVIDIA_TESLA_T4</code> or <code>NVIDIA_L4</code> is a practical
and affordable starting point.<br></li>
<li>Fine-tuning or large-scale inference with billion-parameter models
can be extremely expensive; validate your workflow with smaller models
first.</li>
</ol><!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 --></div>



      </div> <!-- / div.lesson-content -->
    </main><!-- / main#main-content.main-content --><nav class="bottom-pagination mx-md-4" aria-label="Previous and Next Chapter"><div class="d-block d-sm-block d-md-none">
        <a class="chapter-link" href="index.html"><i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>Previous</a>
        <a class="chapter-link float-end" href="index.html">Next<i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i></a>
      </div>
      <!-- content for large screens -->
      <div class="d-none d-sm-none d-md-block">
        <a class="chapter-link" href="index.html" rel="prev">
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>
          Home
        </a>
        <a class="chapter-link float-end" href="index.html" rel="next">
          Home
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i>
        </a>
      </div>
    </nav></div> <!-- / div.primary-content.col-xs-12 -->
<!-- END:   inst/pkgdown/templates/content-instructor.html-->

      </div><!--/div.row-->
      		<footer class="row footer mx-md-3"><hr><div class="col-md-6">
        <p>This lesson is subject to the <a href="CODE_OF_CONDUCT.html">Code of Conduct</a></p>
        <p>

        <a href="https://github.com/qualiaMachine/Intro_GCP_VertexAI/edit/main/learners/instances-for-ML.md" class="external-link">Edit on GitHub</a>

	
        | <a href="https://github.com/qualiaMachine/Intro_GCP_VertexAI/blob/main/CONTRIBUTING.md" class="external-link">Contributing</a>
        | <a href="https://github.com/qualiaMachine/Intro_GCP_VertexAI/" class="external-link">Source</a></p>
				<p><a href="https://github.com/qualiaMachine/Intro_GCP_VertexAI/blob/main/CITATION.cff" class="external-link">Cite</a> | <a href="mailto:endemann@wisc.edu">Contact</a> | <a href="https://carpentries.org/about/" class="external-link">About</a></p>
			</div>
			<div class="col-md-6">

        <p>Materials licensed under <a href="LICENSE.html">CC-BY 4.0</a> by the authors</p>

        <p>Template licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" class="external-link">CC-BY 4.0</a> by <a href="https://carpentries.org/" class="external-link">The Carpentries</a></p>
        <p>Built with <a href="https://github.com/carpentries/sandpaper/tree/0.17.1" class="external-link">sandpaper (0.17.1)</a>, <a href="https://github.com/carpentries/pegboard/tree/0.7.9" class="external-link">pegboard (0.7.9)</a>, and <a href="https://github.com/carpentries/varnish/tree/1.0.7" class="external-link">varnish (1.0.7)</a></p>
			</div>
		</footer></div> <!-- / div.container -->
	<div id="to-top">
		<a href="#top">
      <i class="search-icon" data-feather="arrow-up" role="img" aria-label="Back To Top"></i><br><!-- <span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top --><span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top
		</a>
	</div>
  <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "LearningResource",
  "@id": "https://qualiaMachine.github.io/Intro_GCP_VertexAI/instances-for-ML.html",
  "inLanguage": "en",
  "dct:conformsTo": "https://bioschemas.org/profiles/LearningResource/1.0-RELEASE",
  "description": "A Carpentries Lesson teaching foundational data and coding skills to researchers worldwide",
  "keywords": "cloud, GCP, lesson, The Carpentries, ML, AI, GPU",
  "name": "Compute for ML",
  "creativeWorkStatus": "active",
  "url": "https://qualiaMachine.github.io/Intro_GCP_VertexAI/instances-for-ML.html",
  "identifier": "https://qualiaMachine.github.io/Intro_GCP_VertexAI/instances-for-ML.html",
  "dateCreated": "2025-08-26",
  "dateModified": "2025-10-29",
  "datePublished": "2025-10-30"
}

  </script><script>
		feather.replace();
	</script></body></html><!-- END:   inst/pkgdown/templates/layout.html-->

