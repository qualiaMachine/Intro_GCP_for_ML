<!DOCTYPE html>
<!-- START: inst/pkgdown/templates/layout.html --><!-- Generated by pkgdown: do not edit by hand --><html lang="en" data-bs-theme="auto"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><title>Intro to Google Cloud Platform (GCP) for Machine Learning: Retrieval-Augmented Generation (RAG) with Vertex AI</title><meta name="viewport" content="width=device-width, initial-scale=1"><script src="../assets/themetoggle.js"></script><link rel="stylesheet" type="text/css" href="../assets/styles.css"><script src="../assets/scripts.js" type="text/javascript"></script><!-- mathjax --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/PreviewHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
      TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      },
      tex2jax: {
        inlineMath: [['\\(', '\\)']],
        displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
        processEscapes: true
      }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><!-- Responsive Favicon for The Carpentries --><link rel="apple-touch-icon" sizes="180x180" href="../favicons/incubator/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="../favicons/incubator/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="../favicons/incubator/favicon-16x16.png"><link rel="manifest" href="../favicons/incubator/site.webmanifest"><link rel="mask-icon" href="../favicons/incubator/safari-pinned-tab.svg" color="#5bbad5"><meta name="msapplication-TileColor" content="#da532c"><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"><meta name="theme-color" media="(prefers-color-scheme: dark)" content="black"></head><body>
    <header id="top" class="navbar navbar-expand-md top-nav incubator"><svg xmlns="http://www.w3.org/2000/svg" class="d-none"><symbol id="check2" viewbox="0 0 16 16"><path d="M13.854 3.646a.5.5 0 0 1 0 .708l-7 7a.5.5 0 0 1-.708 0l-3.5-3.5a.5.5 0 1 1 .708-.708L6.5 10.293l6.646-6.647a.5.5 0 0 1 .708 0z"></path></symbol><symbol id="circle-half" viewbox="0 0 16 16"><path d="M8 15A7 7 0 1 0 8 1v14zm0 1A8 8 0 1 1 8 0a8 8 0 0 1 0 16z"></path></symbol><symbol id="moon-stars-fill" viewbox="0 0 16 16"><path d="M6 .278a.768.768 0 0 1 .08.858 7.208 7.208 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277.527 0 1.04-.055 1.533-.16a.787.787 0 0 1 .81.316.733.733 0 0 1-.031.893A8.349 8.349 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.752.752 0 0 1 6 .278z"></path><path d="M10.794 3.148a.217.217 0 0 1 .412 0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217 0 0 1 0 .412l-1.162.387a1.734 1.734 0 0 0-1.097 1.097l-.387 1.162a.217.217 0 0 1-.412 0l-.387-1.162A1.734 1.734 0 0 0 9.31 6.593l-1.162-.387a.217.217 0 0 1 0-.412l1.162-.387a1.734 1.734 0 0 0 1.097-1.097l.387-1.162zM13.863.099a.145.145 0 0 1 .274 0l.258.774c.115.346.386.617.732.732l.774.258a.145.145 0 0 1 0 .274l-.774.258a1.156 1.156 0 0 0-.732.732l-.258.774a.145.145 0 0 1-.274 0l-.258-.774a1.156 1.156 0 0 0-.732-.732l-.774-.258a.145.145 0 0 1 0-.274l.774-.258c.346-.115.617-.386.732-.732L13.863.1z"></path></symbol><symbol id="sun-fill" viewbox="0 0 16 16"><path d="M8 12a4 4 0 1 0 0-8 4 4 0 0 0 0 8zM8 0a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 0zm0 13a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 13zm8-5a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2a.5.5 0 0 1 .5.5zM3 8a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2A.5.5 0 0 1 3 8zm10.657-5.657a.5.5 0 0 1 0 .707l-1.414 1.415a.5.5 0 1 1-.707-.708l1.414-1.414a.5.5 0 0 1 .707 0zm-9.193 9.193a.5.5 0 0 1 0 .707L3.05 13.657a.5.5 0 0 1-.707-.707l1.414-1.414a.5.5 0 0 1 .707 0zm9.193 2.121a.5.5 0 0 1-.707 0l-1.414-1.414a.5.5 0 0 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .707zM4.464 4.465a.5.5 0 0 1-.707 0L2.343 3.05a.5.5 0 1 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .708z"></path></symbol></svg><a class="visually-hidden-focusable skip-link" href="#main-content">Skip to main content</a>
  <div class="container-fluid top-nav-container">
    <div class="col-md-8">
      <div class="large-logo">
        <img id="incubator-logo" alt="Lesson Description" src="../assets/images/incubator-logo.svg"><span class="badge text-bg-danger">
          <abbr title="This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught.">
            <a href="https://docs.carpentries.org/resources/curriculum/lesson-life-cycle.html" class="external-link alert-link">
              <i aria-hidden="true" class="icon" data-feather="alert-octagon" style="border-radius: 5px"></i>
              Pre-Alpha
            </a>
            <span class="visually-hidden">This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught.</span>
          </abbr>
        </span>

      </div>
    </div>
    <div class="selector-container">
      <div id="theme-selector">
        <li class="nav-item dropdown" id="theme-button-list">
          <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
            <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="bd-theme-text"><li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                Light
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                Dark
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                Auto
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
          </ul></li>
      </div>

      <div class="dropdown" id="instructor-dropdown">
        <button class="btn btn-secondary dropdown-toggle bordered-button" type="button" id="dropdownMenu1" data-bs-toggle="dropdown" aria-expanded="false">
          <i aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View <i data-feather="chevron-down"></i>
        </button>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1"><li><button class="dropdown-item" type="button" onclick="window.location.href='../10-Retrieval-augmented-generation.html';">Learner View</button></li>
        </ul></div>
    </div>
  </div>
  <hr></header><nav class="navbar navbar-expand-xl bottom-nav incubator" aria-label="Main Navigation"><div class="container-fluid nav-container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle Navigation">
      <span class="navbar-toggler-icon"></span>
      <span class="menu-title">Menu</span>
    </button>
    <div class="nav-logo">
      <img class="small-logo" alt="Lesson Description" src="../assets/images/incubator-logo-sm.svg"></div>
    <div class="lesson-title-md">
      Intro to Google Cloud Platform (GCP) for Machine Learning
    </div>
    <div class="search-icon-sm">
      <!-- TODO: do not show until we have search
        <i role="img" aria-label="Search the All In One page" data-feather="search"></i>
      -->
    </div>
    <div class="desktop-nav">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0"><li class="nav-item">
          <span class="lesson-title">
            Intro to Google Cloud Platform (GCP) for Machine Learning
          </span>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/key-points.html">Key Points</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/instructor-notes.html">Instructor Notes</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/images.html">Extract All Images</a>
        </li>
        <li class="nav-item dropdown">
          <button class="nav-link dropdown-toggle" id="navbarDropdown" data-bs-toggle="dropdown" aria-expanded="false">
            More <i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdown"><hr><li><a class="dropdown-item" href="glossary.html">Glossary</a></li><li><a class="dropdown-item" href="instances-for-ML.html">Compute for ML</a></li>
          </ul></li>
      </ul></div>
    <!--
    <form class="d-flex col-md-2 search-form">
      <fieldset disabled>
      <input class="form-control me-2 searchbox" type="search" placeholder="" aria-label="">
        <button class="btn btn-outline-success tablet-search-button"  type="submit">
          <i class="search-icon" data-feather="search" role="img" aria-label="Search the All In One page"></i>
        </button>
      </fieldset>
    </form>
    -->
    <a id="search-button" class="btn btn-primary" href="../instructor/aio.html" role="button" aria-label="Search the All In One page">Search the All In One page</a>
  </div><!--/div.container-fluid -->
</nav><div class="col-md-12 mobile-title">
  Intro to Google Cloud Platform (GCP) for Machine Learning
</div>

<aside class="col-md-12 lesson-progress"><div style="width: 91%" class="percentage">
    91%
  </div>
  <div class="progress incubator">
    <div class="progress-bar incubator" role="progressbar" style="width: 91%" aria-valuenow="91" aria-label="Lesson Progress" aria-valuemin="0" aria-valuemax="100">
    </div>
  </div>
</aside><div class="container">
      <div class="row">
        <!-- START: inst/pkgdown/templates/navbar.html -->
<div id="sidebar-col" class="col-lg-4">
  <div id="sidebar" class="sidebar">
      <nav aria-labelledby="flush-headingEleven"><button role="button" aria-label="close menu" alt="close menu" aria-expanded="true" aria-controls="sidebar" class="collapse-toggle" data-collapse="Collapse " data-episodes="Episodes ">
          <i class="search-icon" data-feather="x" role="img"></i>
        </button>
        <div class="sidebar-inner">
          <div class="row mobile-row" id="theme-row-mobile">
            <div class="col" id="theme-selector">
              <li class="nav-item dropdown" id="theme-button-list">
                <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
                  <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><span class="d-lg-none ms-1" id="bd-theme-text">Toggle Theme</span>
                </button>
                <ul class="dropdown-menu dropdown-menu-right" aria-labelledby="bd-theme-text"><li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                      Light
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                      Dark
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                      <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                      Auto
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                </ul></li>
            </div>
          </div>
          <div class="row mobile-row">
            <div class="col">
              <div class="sidenav-view-selector">
                <div class="accordion accordion-flush" id="accordionFlush9">
                  <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingNine">
                      <button class="accordion-button collapsed" id="instructor" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseNine" aria-expanded="false" aria-controls="flush-collapseNine">
                        <i id="eye" aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View
                      </button>
                    </h2>
                    <div id="flush-collapseNine" class="accordion-collapse collapse" aria-labelledby="flush-headingNine" data-bs-parent="#accordionFlush2">
                      <div class="accordion-body">
                        <a href="../10-Retrieval-augmented-generation.html">Learner View</a>
                      </div>
                    </div>
                  </div><!--/div.accordion-item-->
                </div><!--/div.accordion-flush-->
              </div><!--div.sidenav-view-selector -->
            </div><!--/div.col -->

            <hr></div><!--/div.mobile-row -->

          <div class="accordion accordion-flush" id="accordionFlush11">
            <div class="accordion-item">

              <button id="chapters" class="accordion-button show" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseEleven" aria-expanded="false" aria-controls="flush-collapseEleven">
                <h2 class="accordion-header chapters" id="flush-headingEleven">
                  EPISODES
                </h2>
              </button>
              <div id="flush-collapseEleven" class="accordion-collapse show collapse" aria-labelledby="flush-headingEleven" data-bs-parent="#accordionFlush11">

                <div class="accordion-body">
                  <div class="accordion accordion-flush" id="accordionFlush1">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading1">
        <a href="index.html">Summary and Schedule</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush2">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading2">
        <a href="01-Introduction.html">1. Overview of Google Cloud for Machine Learning</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush3">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading3">
        <a href="02-Data-storage.html">2. Data Storage: Setting up GCS</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush4">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading4">
        <a href="03-Notebooks-as-controllers.html">3. Notebooks as Controllers</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush5">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading5">
        <a href="04-Accessing-and-managing-data.html">4. Accessing and Managing Data in GCS with Vertex AI Notebooks</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush6">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading6">
        <a href="05-Interacting-with-code-repo.html">5. Using a GitHub Personal Access Token (PAT) to Push/Pull from a Vertex AI Notebook</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush7">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading7">
        <a href="06-Training-models-in-VertexAI.html">6. Training Models in Vertex AI: Intro</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush8">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading8">
        <a href="07-Training-models-in-VertexAI-GPUs.html">7. Training Models in Vertex AI: PyTorch Example</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush9">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading9">
        <a href="08-Hyperparameter-tuning.html">8. Hyperparameter Tuning in Vertex AI: Neural Network Example</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush10">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading10">
        <a href="09-Resource-management-cleanup.html">9. Resource Management &amp; Monitoring on Vertex AI (GCP)</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlushcurrent">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-headingcurrent">
      <button class="accordion-button" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapsecurrent" aria-expanded="true" aria-controls="flush-collapsecurrent">
        <span class="visually-hidden">Current Chapter</span>
        <span class="current-chapter">
        10. Retrieval-Augmented Generation (RAG) with Vertex AI
        </span>
      </button>
    </div><!--/div.accordion-header-->

    <div id="flush-collapsecurrent" class="accordion-collapse collapse show" aria-labelledby="flush-headingcurrent" data-bs-parent="#accordionFlushcurrent">
      <div class="accordion-body">
        <ul><li><a href="#overview-what-were-building">Overview: What we’re building</a></li>
<li><a href="#step-1-setup-environment">Step 1: Setup environment</a></li>
<li><a href="#step-2-extract-and-chunk-pdfs">Step 2: Extract and chunk PDFs</a></li>
<li><a href="#step-3-embed-text-using-vertex-ai">Step 3: Embed text using Vertex AI</a></li>
<li><a href="#step-5-generate-answers-using-gemini">Step 5: Generate answers using Gemini</a></li>
<li><a href="#step-6-cost-summary">Step 6: Cost summary</a></li>
<li><a href="#optional-hugging-face-local-substitution">(Optional) Hugging Face local substitution</a></li>
<li><a href="#key-takeaways">Key takeaways</a></li>
        </ul></div><!--/div.accordion-body-->
    </div><!--/div.accordion-collapse-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

                </div>
              </div>
            </div>

            <hr class="half-width"><div class="accordion accordion-flush lesson-resources" id="accordionFlush12">
              <div class="accordion-item">
                <h2 class="accordion-header" id="flush-headingTwelve">
                  <button class="accordion-button collapsed" id="lesson-resources" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwelve" aria-expanded="false" aria-controls="flush-collapseTwelve">
                    RESOURCES
                  </button>
                </h2>
                <div id="flush-collapseTwelve" class="accordion-collapse collapse" aria-labelledby="flush-headingTwelve" data-bs-parent="#accordionFlush12">
                  <div class="accordion-body">
                    <ul><li>
                        <a href="../instructor/key-points.html">Key Points</a>
                      </li>
                      <li>
                        <a href="../instructor/instructor-notes.html">Instructor Notes</a>
                      </li>
                      <li>
                        <a href="../instructor/images.html">Extract All Images</a>
                      </li>
                      <hr><li><a class="dropdown-item" href="glossary.html">Glossary</a></li><li><a class="dropdown-item" href="instances-for-ML.html">Compute for ML</a></li>
                    </ul></div>
                </div>
              </div>
            </div>
            <hr class="half-width lesson-resources"><a href="../instructor/aio.html">See all in one page</a>


            <hr class="d-none d-sm-block d-md-none"><div class="d-grid gap-1">

            </div>
          </div><!-- /div.accordion -->
        </div><!-- /div.sidebar-inner -->
      </nav></div><!-- /div.sidebar -->
  </div><!-- /div.sidebar-col -->
<!-- END:   inst/pkgdown/templates/navbar.html-->

        <!-- START: inst/pkgdown/templates/content-instructor.html -->
  <div class="col-xl-8 col-lg-12 primary-content">
    <nav class="lesson-content mx-md-4" aria-label="Previous and Next Chapter"><!-- content for small screens --><div class="d-block d-sm-block d-md-none">
        <a class="chapter-link" href="../instructor/09-Resource-management-cleanup.html"><i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>Previous</a>
        <a class="chapter-link float-end" href="../instructor/index.html">Next<i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i></a>
      </div>
      <!-- content for large screens -->
      <div class="d-none d-sm-none d-md-block">
        <a class="chapter-link" href="../instructor/09-Resource-management-cleanup.html" rel="prev">
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>
          Previous: Resource Management
        </a>
        <a class="chapter-link float-end" href="../instructor/index.html" rel="next">
          Home
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i>
        </a>
      </div>
      <hr></nav><main id="main-content" class="main-content"><div class="container lesson-content">
        <h1>Retrieval-Augmented Generation (RAG) with Vertex AI</h1>
        <p>Last updated on 2025-10-30 |

        <a href="https://github.com/qualiaMachine/Intro_GCP_VertexAI/edit/main/episodes/10-Retrieval-augmented-generation.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>



        <p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 30 minutes</p>

        <div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>

        

<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul><li>How do we go from “a pile of PDFs” to “ask a question and get a
cited answer” using Google Cloud tools?</li>
<li>What are the key parts of a RAG system (chunking, embedding,
retrieval, generation), and how do they map onto Vertex AI
services?</li>
<li>How much does each part of this pipeline cost (VM time, embeddings,
LLM calls), and where can we keep it cheap?</li>
<li>Can we use open models / Hugging Face instead of Google models, and
what does that change?</li>
</ul></div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul><li>Unpack the core RAG pipeline: ingest → chunk → embed → retrieve →
answer.</li>
<li>Run a minimal, fully programmatic RAG loop on a Vertex AI Workbench
VM using Google’s own foundation models (for embeddings +
generation).</li>
<li>Understand how to substitute open-source / Hugging Face models if
you want to avoid managed API costs.</li>
<li>Answer questions using content from provided papers and return
citations instead of vibes.</li>
</ul></div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="overview-what-were-building">Overview: What we’re building<a class="anchor" aria-label="anchor" href="#overview-what-were-building"></a></h2>
<hr class="half-width"><p><strong>Retrieval-Augmented Generation (RAG)</strong> is a
pattern:</p>
<ol style="list-style-type: decimal"><li>You ask a question.<br></li>
<li>The system <strong>retrieves</strong> relevant passages from your
PDFs or data.<br></li>
<li>An LLM <strong>answers</strong> using those passages only, with
citations.</li>
</ol><p>This approach powers sustainability-related projects like
<strong>WattBot</strong>, which extracts AI water and energy metrics
from research papers.</p>
<p><strong>Cost mindset:</strong><br>
- <strong>VM cost:</strong> pay for Workbench instance uptime. Stop when
not in use.<br>
- <strong>Embedding cost:</strong> pay per character embedded — only
once per doc.<br>
- <strong>Generation cost:</strong> pay per token for input + output.
Shorter prompts = cheaper.</p>
<p><strong>Hugging Face alternatives:</strong><br>
You can replace Google-managed APIs with open models such as:<br>
- <strong>Embeddings:</strong>
<code>sentence-transformers/all-MiniLM-L6-v2</code>,
<code>BAAI/bge-large-en-v1.5</code><br>
- <strong>Generators:</strong> <code>google/gemma-2b-it</code>,
<code>mistralai/Mistral-7B-Instruct</code>, or
<code>tiiuae/falcon-7b-instruct</code><br>
However, this requires a GPU or large CPU VM (e.g.,
<code>n1-standard-8</code> + <code>T4</code>) and manual model
management. Rather than use a very expensive machine and GPU in
Workbench, you can launch custom jobs that perform the embedding and
generation steps. Start with a PyTorch image and add HuggingFace as a
requirement.</p>
</section><section><h2 class="section-heading" id="step-1-setup-environment">Step 1: Setup environment<a class="anchor" aria-label="anchor" href="#step-1-setup-environment"></a></h2>
<hr class="half-width"><div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="op">!</span>pip install <span class="op">--</span>quiet <span class="op">--</span>upgrade pypdf</span></code></pre>
</div>
<p><strong>Cost note:</strong> Installing packages is free; you’re only
billed for VM runtime.</p>
<div class="section level3">
<h3 id="initialize-project">Initialize project<a class="anchor" aria-label="anchor" href="#initialize-project"></a></h3>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="im">from</span> google.cloud <span class="im">import</span> aiplatform</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="im">from</span> vertexai <span class="im">import</span> init <span class="im">as</span> vertexai_init</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>PROJECT_ID <span class="op">=</span> os.environ.get(<span class="st">"GOOGLE_CLOUD_PROJECT"</span>, <span class="st">"&lt;YOUR_PROJECT_ID&gt;"</span>)</span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a>REGION <span class="op">=</span> <span class="st">"us-central1"</span></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>aiplatform.init(project<span class="op">=</span>PROJECT_ID, location<span class="op">=</span>REGION)</span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a>vertexai_init(project<span class="op">=</span>PROJECT_ID, location<span class="op">=</span>REGION)</span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Initialized:"</span>, PROJECT_ID, REGION)</span></code></pre>
</div>
</div>
</section><section><h2 class="section-heading" id="step-2-extract-and-chunk-pdfs">Step 2: Extract and chunk PDFs<a class="anchor" aria-label="anchor" href="#step-2-extract-and-chunk-pdfs"></a></h2>
<hr class="half-width"><div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="im">import</span> zipfile, pathlib, re, pandas <span class="im">as</span> pd</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a><span class="im">from</span> pypdf <span class="im">import</span> PdfReader</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>ZIP_PATH <span class="op">=</span> pathlib.Path(<span class="st">"/home/jupyter/Intro_GCP_for_ML/data/pdfs_bundle.zip"</span>)</span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a>DOC_DIR <span class="op">=</span> pathlib.Path(<span class="st">"/home/jupyter/docs"</span>)</span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a>DOC_DIR.mkdir(exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a><span class="co"># unzip</span></span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a><span class="cf">with</span> zipfile.ZipFile(ZIP_PATH, <span class="st">"r"</span>) <span class="im">as</span> zf:</span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a>    zf.extractall(DOC_DIR)</span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a><span class="kw">def</span> chunk_text(text, max_chars<span class="op">=</span><span class="dv">1200</span>, overlap<span class="op">=</span><span class="dv">150</span>):</span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(text), max_chars <span class="op">-</span> overlap):</span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a>        <span class="cf">yield</span> text[i:i<span class="op">+</span>max_chars]</span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a></span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a>rows <span class="op">=</span> []</span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a><span class="cf">for</span> pdf <span class="kw">in</span> DOC_DIR.glob(<span class="st">"*.pdf"</span>):</span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a>    txt <span class="op">=</span> <span class="st">""</span></span>
<span id="cb3-19"><a href="#cb3-19" tabindex="-1"></a>    <span class="cf">for</span> page <span class="kw">in</span> PdfReader(<span class="bu">str</span>(pdf)).pages:</span>
<span id="cb3-20"><a href="#cb3-20" tabindex="-1"></a>        txt <span class="op">+=</span> page.extract_text() <span class="kw">or</span> <span class="st">""</span></span>
<span id="cb3-21"><a href="#cb3-21" tabindex="-1"></a>    <span class="cf">for</span> i, chunk <span class="kw">in</span> <span class="bu">enumerate</span>(chunk_text(re.sub(<span class="vs">r"\s+"</span>, <span class="st">" "</span>, txt))):</span>
<span id="cb3-22"><a href="#cb3-22" tabindex="-1"></a>        rows.append({<span class="st">"doc"</span>: pdf.name, <span class="st">"chunk_id"</span>: i, <span class="st">"text"</span>: chunk})</span>
<span id="cb3-23"><a href="#cb3-23" tabindex="-1"></a></span>
<span id="cb3-24"><a href="#cb3-24" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb3-25"><a href="#cb3-25" tabindex="-1"></a>corpus_df <span class="op">=</span> pd.DataFrame(rows)</span>
<span id="cb3-26"><a href="#cb3-26" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">len</span>(corpus_df), <span class="st">"chunks created"</span>)</span></code></pre>
</div>
<p><strong>Cost note:</strong> Only VM runtime applies. Chunk size
affects future embedding cost.</p>
</section><section><h2 class="section-heading" id="step-3-embed-text-using-vertex-ai">Step 3: Embed text using Vertex AI<a class="anchor" aria-label="anchor" href="#step-3-embed-text-using-vertex-ai"></a></h2>
<hr class="half-width"><div class="section level3">
<h3 id="choosing-an-embedding-and-generator-model">Choosing an embedding and generator model<a class="anchor" aria-label="anchor" href="#choosing-an-embedding-and-generator-model"></a></h3>
<p>Vertex AI currently offers multiple managed embedding models under
the <strong>Text Embeddings API</strong> family.<br>
For this exercise, we’re using
<strong><code>text-embedding-004</code></strong>, which is Google’s
latest general-purpose model optimized for <strong>semantic
similarity</strong>, <strong>retrieval</strong>, and
<strong>clustering</strong> tasks.</p>
<p><strong>Why this model?</strong> - Produces 768-dimensional dense
vectors suitable for cosine or dot-product similarity.<br>
- Handles long passages (up to ~8,000 tokens) and multilingual
content.<br>
- Tuned for retrieval tasks like RAG, document search, and
clustering.<br>
- Cost-efficient for classroom-scale workloads (fractions of a cent per
document).</p>
<p>If you’d like to explore other options: - Open the <a href="https://console.cloud.google.com/vertex-ai/model-garden?project=doit-rci-mlm25-4626&amp;pageState=(%22galleryStateKey%22:(%22f%22:(%22g%22:%5B%22goals%22%5D,%22o%22:%5B%22Text%20embeddings%22%5D),%22s%22:%22%22))" class="external-link"><strong>Vertex
AI Model Garden → Text Embeddings</strong></a> in your GCP
console.<br>
- You’ll find specialized alternatives such as: -
<strong><code>text-embedding-005</code> (experimental)</strong> – larger
model, higher precision on longer documents.<br>
- <strong><code>multimodal-embedding-001</code></strong> – supports
image + text embeddings for richer use cases.<br>
- <strong>Third-party embeddings (via Model Garden)</strong> – e.g.,
<code>bge-large-en</code>, <code>cohere-embed-v3</code>,
<code>all-MiniLM</code>.</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="co">#############################################</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a><span class="co"># 1. Imports and client setup</span></span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a><span class="co">#############################################</span></span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a><span class="im">from</span> google <span class="im">import</span> genai</span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a><span class="im">from</span> google.genai.types <span class="im">import</span> HttpOptions, EmbedContentConfig, GenerateContentConfig</span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> NearestNeighbors</span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a><span class="co"># We'll assume you already have:</span></span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a><span class="co">#   corpus_df  -&gt; pandas DataFrame with columns: 'text', 'doc', 'chunk_id'</span></span>
<span id="cb4-12"><a href="#cb4-12" tabindex="-1"></a><span class="co"># If not, you'll need to define/load that before running this cell.</span></span>
<span id="cb4-13"><a href="#cb4-13" tabindex="-1"></a></span>
<span id="cb4-14"><a href="#cb4-14" tabindex="-1"></a></span>
<span id="cb4-15"><a href="#cb4-15" tabindex="-1"></a><span class="co">#############################################</span></span>
<span id="cb4-16"><a href="#cb4-16" tabindex="-1"></a><span class="co"># 2. Initialize the Gen AI client</span></span>
<span id="cb4-17"><a href="#cb4-17" tabindex="-1"></a><span class="co">#############################################</span></span>
<span id="cb4-18"><a href="#cb4-18" tabindex="-1"></a></span>
<span id="cb4-19"><a href="#cb4-19" tabindex="-1"></a><span class="co"># vertexai=True = bill/govern in your GCP project instead of the public endpoint</span></span>
<span id="cb4-20"><a href="#cb4-20" tabindex="-1"></a>client <span class="op">=</span> genai.Client(</span>
<span id="cb4-21"><a href="#cb4-21" tabindex="-1"></a>    http_options<span class="op">=</span>HttpOptions(api_version<span class="op">=</span><span class="st">"v1"</span>),</span>
<span id="cb4-22"><a href="#cb4-22" tabindex="-1"></a>    vertexai<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb4-23"><a href="#cb4-23" tabindex="-1"></a>    project<span class="op">=</span><span class="st">"doit-rci-mlm25-4626"</span>,</span>
<span id="cb4-24"><a href="#cb4-24" tabindex="-1"></a>    location<span class="op">=</span><span class="st">"us-central1"</span>,</span>
<span id="cb4-25"><a href="#cb4-25" tabindex="-1"></a>)</span>
<span id="cb4-26"><a href="#cb4-26" tabindex="-1"></a></span>
<span id="cb4-27"><a href="#cb4-27" tabindex="-1"></a><span class="co"># Generation model for answering questions</span></span>
<span id="cb4-28"><a href="#cb4-28" tabindex="-1"></a>GENERATION_MODEL_ID <span class="op">=</span> <span class="st">"gemini-2.5-pro"</span>        <span class="co"># or "gemini-2.5-flash" for cheaper/faster</span></span>
<span id="cb4-29"><a href="#cb4-29" tabindex="-1"></a></span>
<span id="cb4-30"><a href="#cb4-30" tabindex="-1"></a><span class="co"># Embedding model for retrieval</span></span>
<span id="cb4-31"><a href="#cb4-31" tabindex="-1"></a>EMBED_MODEL_ID <span class="op">=</span> <span class="st">"gemini-embedding-001"</span></span>
<span id="cb4-32"><a href="#cb4-32" tabindex="-1"></a></span>
<span id="cb4-33"><a href="#cb4-33" tabindex="-1"></a><span class="co"># Pick an embedding dimensionality and stick to it across corpus + queries.</span></span>
<span id="cb4-34"><a href="#cb4-34" tabindex="-1"></a>EMBED_DIM <span class="op">=</span> <span class="dv">1536</span>  <span class="co"># valid typical choices: 768, 1536, 3072</span></span>
<span id="cb4-35"><a href="#cb4-35" tabindex="-1"></a></span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="co">#############################################</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a><span class="co"># 3. Helper: get embeddings for a list of texts</span></span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a><span class="co">#############################################</span></span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a><span class="kw">def</span> embed_texts(text_list, batch_size<span class="op">=</span><span class="dv">32</span>, dims<span class="op">=</span>EMBED_DIM):</span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a><span class="co">    Convert a list of text strings into embedding vectors using gemini-embedding-001.</span></span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a><span class="co">    Returns a NumPy array of shape (len(text_list), dims).</span></span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a>    vectors <span class="op">=</span> []</span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a></span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a>    <span class="co"># batch to avoid huge single requests</span></span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a>    <span class="cf">for</span> start <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(text_list), batch_size):</span>
<span id="cb5-14"><a href="#cb5-14" tabindex="-1"></a>        batch <span class="op">=</span> text_list[start:start<span class="op">+</span>batch_size]</span>
<span id="cb5-15"><a href="#cb5-15" tabindex="-1"></a></span>
<span id="cb5-16"><a href="#cb5-16" tabindex="-1"></a>        resp <span class="op">=</span> client.models.embed_content(</span>
<span id="cb5-17"><a href="#cb5-17" tabindex="-1"></a>            model<span class="op">=</span>EMBED_MODEL_ID,</span>
<span id="cb5-18"><a href="#cb5-18" tabindex="-1"></a>            contents<span class="op">=</span>batch,</span>
<span id="cb5-19"><a href="#cb5-19" tabindex="-1"></a>            config<span class="op">=</span>EmbedContentConfig(</span>
<span id="cb5-20"><a href="#cb5-20" tabindex="-1"></a>                task_type<span class="op">=</span><span class="st">"RETRIEVAL_DOCUMENT"</span>,   <span class="co"># optimize embeddings for retrieval/use as chunks</span></span>
<span id="cb5-21"><a href="#cb5-21" tabindex="-1"></a>                output_dimensionality<span class="op">=</span>dims,       <span class="co"># must match EMBED_DIM everywhere</span></span>
<span id="cb5-22"><a href="#cb5-22" tabindex="-1"></a>            ),</span>
<span id="cb5-23"><a href="#cb5-23" tabindex="-1"></a>        )</span>
<span id="cb5-24"><a href="#cb5-24" tabindex="-1"></a></span>
<span id="cb5-25"><a href="#cb5-25" tabindex="-1"></a>        <span class="co"># resp.embeddings is aligned with 'batch'</span></span>
<span id="cb5-26"><a href="#cb5-26" tabindex="-1"></a>        <span class="cf">for</span> emb <span class="kw">in</span> resp.embeddings:</span>
<span id="cb5-27"><a href="#cb5-27" tabindex="-1"></a>            vectors.append(emb.values)</span>
<span id="cb5-28"><a href="#cb5-28" tabindex="-1"></a></span>
<span id="cb5-29"><a href="#cb5-29" tabindex="-1"></a>    <span class="cf">return</span> np.array(vectors, dtype<span class="op">=</span><span class="st">"float32"</span>)</span>
<span id="cb5-30"><a href="#cb5-30" tabindex="-1"></a></span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="co">#############################################</span></span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a><span class="co"># 4. Embed the corpus and build the NN index</span></span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a><span class="co">#############################################</span></span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a><span class="co"># Create embeddings for every text chunk in the corpus</span></span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a>emb_matrix <span class="op">=</span> embed_texts(corpus_df[<span class="st">"text"</span>].tolist(), dims<span class="op">=</span>EMBED_DIM)</span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"emb_matrix shape:"</span>, emb_matrix.shape)   <span class="co"># (num_chunks, EMBED_DIM)</span></span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a><span class="co"># Fit NearestNeighbors on those embeddings once</span></span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a>nn <span class="op">=</span> NearestNeighbors(</span>
<span id="cb6-11"><a href="#cb6-11" tabindex="-1"></a>    metric<span class="op">=</span><span class="st">"cosine"</span>,   <span class="co"># cosine distance is standard for semantic similarity</span></span>
<span id="cb6-12"><a href="#cb6-12" tabindex="-1"></a>    n_neighbors<span class="op">=</span><span class="dv">5</span>,     <span class="co"># default neighborhood size; can override at query time</span></span>
<span id="cb6-13"><a href="#cb6-13" tabindex="-1"></a>)</span>
<span id="cb6-14"><a href="#cb6-14" tabindex="-1"></a>nn.fit(emb_matrix)</span>
<span id="cb6-15"><a href="#cb6-15" tabindex="-1"></a></span>
<span id="cb6-16"><a href="#cb6-16" tabindex="-1"></a></span>
<span id="cb6-17"><a href="#cb6-17" tabindex="-1"></a><span class="co">#############################################</span></span>
<span id="cb6-18"><a href="#cb6-18" tabindex="-1"></a><span class="co"># 5. Retrieval: given a query string, get top-k relevant chunks</span></span>
<span id="cb6-19"><a href="#cb6-19" tabindex="-1"></a><span class="co">#############################################</span></span>
<span id="cb6-20"><a href="#cb6-20" tabindex="-1"></a></span>
<span id="cb6-21"><a href="#cb6-21" tabindex="-1"></a><span class="kw">def</span> retrieve(query, k<span class="op">=</span><span class="dv">5</span>):</span>
<span id="cb6-22"><a href="#cb6-22" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-23"><a href="#cb6-23" tabindex="-1"></a><span class="co">    Embed the user query with the SAME embedding model/dim,</span></span>
<span id="cb6-24"><a href="#cb6-24" tabindex="-1"></a><span class="co">    then find the top-k most similar corpus chunks.</span></span>
<span id="cb6-25"><a href="#cb6-25" tabindex="-1"></a><span class="co">    Returns a DataFrame of the top matches with a 'similarity' column.</span></span>
<span id="cb6-26"><a href="#cb6-26" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-27"><a href="#cb6-27" tabindex="-1"></a></span>
<span id="cb6-28"><a href="#cb6-28" tabindex="-1"></a>    <span class="co"># Embed the query to the same dimension space as emb_matrix</span></span>
<span id="cb6-29"><a href="#cb6-29" tabindex="-1"></a>    query_vec <span class="op">=</span> embed_texts([query], dims<span class="op">=</span>EMBED_DIM)[<span class="dv">0</span>]   <span class="co"># shape (EMBED_DIM,)</span></span>
<span id="cb6-30"><a href="#cb6-30" tabindex="-1"></a></span>
<span id="cb6-31"><a href="#cb6-31" tabindex="-1"></a>    <span class="co"># Find nearest neighbors using cosine distance</span></span>
<span id="cb6-32"><a href="#cb6-32" tabindex="-1"></a>    distances, indices <span class="op">=</span> nn.kneighbors([query_vec], n_neighbors<span class="op">=</span>k, return_distance<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-33"><a href="#cb6-33" tabindex="-1"></a></span>
<span id="cb6-34"><a href="#cb6-34" tabindex="-1"></a>    <span class="co"># Grab those rows from the original corpus</span></span>
<span id="cb6-35"><a href="#cb6-35" tabindex="-1"></a>    result_df <span class="op">=</span> corpus_df.iloc[indices[<span class="dv">0</span>]].copy()</span>
<span id="cb6-36"><a href="#cb6-36" tabindex="-1"></a></span>
<span id="cb6-37"><a href="#cb6-37" tabindex="-1"></a>    <span class="co"># Convert cosine distance -&gt; cosine similarity (1 - distance)</span></span>
<span id="cb6-38"><a href="#cb6-38" tabindex="-1"></a>    result_df[<span class="st">"similarity"</span>] <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> distances[<span class="dv">0</span>]</span>
<span id="cb6-39"><a href="#cb6-39" tabindex="-1"></a></span>
<span id="cb6-40"><a href="#cb6-40" tabindex="-1"></a>    <span class="co"># Sort by similarity descending (highest similarity first)</span></span>
<span id="cb6-41"><a href="#cb6-41" tabindex="-1"></a>    result_df <span class="op">=</span> result_df.sort_values(<span class="st">"similarity"</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb6-42"><a href="#cb6-42" tabindex="-1"></a></span>
<span id="cb6-43"><a href="#cb6-43" tabindex="-1"></a>    <span class="cf">return</span> result_df</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="co">#############################################</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a><span class="co"># 6. ask(): build grounded prompt + call Gemini to answer</span></span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a><span class="co">#############################################</span></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a><span class="kw">def</span> ask(query, top_k<span class="op">=</span><span class="dv">5</span>, temperature<span class="op">=</span><span class="fl">0.2</span>):</span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a><span class="co">    Retrieval-Augmented Generation:</span></span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a><span class="co">    - retrieve context chunks relevant to `query`</span></span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a><span class="co">    - stuff those chunks into a prompt</span></span>
<span id="cb7-10"><a href="#cb7-10" tabindex="-1"></a><span class="co">    - ask Gemini to answer ONLY using that context</span></span>
<span id="cb7-11"><a href="#cb7-11" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb7-12"><a href="#cb7-12" tabindex="-1"></a></span>
<span id="cb7-13"><a href="#cb7-13" tabindex="-1"></a>    <span class="co"># Get top_k most relevant text chunks</span></span>
<span id="cb7-14"><a href="#cb7-14" tabindex="-1"></a>    hits <span class="op">=</span> retrieve(query, k<span class="op">=</span>top_k)</span>
<span id="cb7-15"><a href="#cb7-15" tabindex="-1"></a></span>
<span id="cb7-16"><a href="#cb7-16" tabindex="-1"></a>    <span class="co"># Build a context block with provenance tags like [doc#chunk-id]</span></span>
<span id="cb7-17"><a href="#cb7-17" tabindex="-1"></a>    context_lines <span class="op">=</span> [</span>
<span id="cb7-18"><a href="#cb7-18" tabindex="-1"></a>        <span class="ss">f"[</span><span class="sc">{</span>row<span class="sc">.</span>doc<span class="sc">}</span><span class="ss">#chunk-</span><span class="sc">{</span>row<span class="sc">.</span>chunk_id<span class="sc">}</span><span class="ss">] </span><span class="sc">{</span>row<span class="sc">.</span>text<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb7-19"><a href="#cb7-19" tabindex="-1"></a>        <span class="cf">for</span> _, row <span class="kw">in</span> hits.iterrows()</span>
<span id="cb7-20"><a href="#cb7-20" tabindex="-1"></a>    ]</span>
<span id="cb7-21"><a href="#cb7-21" tabindex="-1"></a>    context_block <span class="op">=</span> <span class="st">"</span><span class="ch">\n\n</span><span class="st">"</span>.join(context_lines)</span>
<span id="cb7-22"><a href="#cb7-22" tabindex="-1"></a></span>
<span id="cb7-23"><a href="#cb7-23" tabindex="-1"></a>    <span class="co"># Instruction prompt for the model</span></span>
<span id="cb7-24"><a href="#cb7-24" tabindex="-1"></a>    prompt <span class="op">=</span> (</span>
<span id="cb7-25"><a href="#cb7-25" tabindex="-1"></a>        <span class="st">"You are a sustainability analyst. "</span></span>
<span id="cb7-26"><a href="#cb7-26" tabindex="-1"></a>        <span class="st">"Use only the following context to answer the question.</span><span class="ch">\n\n</span><span class="st">"</span></span>
<span id="cb7-27"><a href="#cb7-27" tabindex="-1"></a>        <span class="ss">f"</span><span class="sc">{</span>context_block<span class="sc">}</span><span class="ch">\n\n</span><span class="ss">"</span></span>
<span id="cb7-28"><a href="#cb7-28" tabindex="-1"></a>        <span class="ss">f"Q: </span><span class="sc">{</span>query<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span></span>
<span id="cb7-29"><a href="#cb7-29" tabindex="-1"></a>        <span class="st">"A:"</span></span>
<span id="cb7-30"><a href="#cb7-30" tabindex="-1"></a>    )</span>
<span id="cb7-31"><a href="#cb7-31" tabindex="-1"></a></span>
<span id="cb7-32"><a href="#cb7-32" tabindex="-1"></a>    <span class="co"># Call the generative model</span></span>
<span id="cb7-33"><a href="#cb7-33" tabindex="-1"></a>    response <span class="op">=</span> client.models.generate_content(</span>
<span id="cb7-34"><a href="#cb7-34" tabindex="-1"></a>        model<span class="op">=</span>GENERATION_MODEL_ID,</span>
<span id="cb7-35"><a href="#cb7-35" tabindex="-1"></a>        contents<span class="op">=</span>prompt,</span>
<span id="cb7-36"><a href="#cb7-36" tabindex="-1"></a>        config<span class="op">=</span>GenerateContentConfig(</span>
<span id="cb7-37"><a href="#cb7-37" tabindex="-1"></a>            temperature<span class="op">=</span>temperature,  <span class="co"># lower = more deterministic, factual</span></span>
<span id="cb7-38"><a href="#cb7-38" tabindex="-1"></a>        ),</span>
<span id="cb7-39"><a href="#cb7-39" tabindex="-1"></a>    )</span>
<span id="cb7-40"><a href="#cb7-40" tabindex="-1"></a></span>
<span id="cb7-41"><a href="#cb7-41" tabindex="-1"></a>    <span class="co"># Return the model's answer text</span></span>
<span id="cb7-42"><a href="#cb7-42" tabindex="-1"></a>    <span class="cf">return</span> response.text</span></code></pre>
</div>
</div>
</section><section><h2 class="section-heading" id="step-5-generate-answers-using-gemini">Step 5: Generate answers using Gemini<a class="anchor" aria-label="anchor" href="#step-5-generate-answers-using-gemini"></a></h2>
<hr class="half-width"><div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a></span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a><span class="co">#############################################</span></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a><span class="co"># 7. Test the pipeline end-to-end</span></span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a><span class="co">#############################################</span></span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a></span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a><span class="bu">print</span>(</span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a>    ask(</span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a>        <span class="st">"What is the name of the benchmark suite presented in a recent paper "</span></span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a>        <span class="st">"for measuring inference energy consumption?"</span></span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a>    )</span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a>)</span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a><span class="co"># Expected answer: "ML.ENERGY Benchmark"</span></span></code></pre>
</div>
</section><section><h2 class="section-heading" id="step-6-cost-summary">Step 6: Cost summary<a class="anchor" aria-label="anchor" href="#step-6-cost-summary"></a></h2>
<hr class="half-width"><table class="table"><colgroup><col width="9%"><col width="16%"><col width="28%"><col width="21%"><col width="24%"></colgroup><thead><tr class="header"><th>Step</th>
<th>Resource</th>
<th>Example Component</th>
<th>Cost Driver</th>
<th>Typical Range</th>
</tr></thead><tbody><tr class="odd"><td>VM runtime</td>
<td>Vertex AI Workbench</td>
<td><code>n1-standard-4</code></td>
<td>Uptime (hourly)</td>
<td>~$0.20/hr</td>
</tr><tr class="even"><td>Embeddings</td>
<td>text-embedding-004</td>
<td>Managed API</td>
<td>Tokens embedded</td>
<td>~$0.10 / 1M tokens</td>
</tr><tr class="odd"><td>Retrieval</td>
<td>Local NN</td>
<td>CPU only</td>
<td>None</td>
<td>Free</td>
</tr><tr class="even"><td>Generation</td>
<td>gemini-2.5-flash-001</td>
<td>Managed API</td>
<td>Input/output tokens</td>
<td>~$0.25 / 1M tokens</td>
</tr><tr class="odd"><td>Hugging Face alt</td>
<td>T4 VM</td>
<td>Local model inference</td>
<td>GPU uptime</td>
<td>~$0.35/hr + egress</td>
</tr></tbody></table></section><section><h2 class="section-heading" id="optional-hugging-face-local-substitution">(Optional) Hugging Face local substitution<a class="anchor" aria-label="anchor" href="#optional-hugging-face-local-substitution"></a></h2>
<hr class="half-width"><p>To avoid managed API costs, you can instead using Hugging Face
models.</p>
<p>```python</p>
</section><section><h2 class="section-heading" id="key-takeaways">Key takeaways<a class="anchor" aria-label="anchor" href="#key-takeaways"></a></h2>
<hr class="half-width"><ul><li>Use <strong>Vertex AI managed embeddings</strong> and <strong>Gemini
Flash</strong> for lightweight, cost-controlled RAG.</li>
<li>Cache embeddings; reusing them saves most cost.</li>
<li>For open alternatives, use Hugging Face models on GPU VMs (higher
cost, more control).</li>
<li>This workflow generalizes to any retrieval task — not just
sustainability papers.</li>
<li>GCP’s managed tools lower barrier for experimentation while keeping
enterprise security and IAM intact.</li>
</ul><div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul><li>Vertex AI’s RAG stack = low-op, cost-predictable.<br></li>
<li>Hugging Face = high control, high GPU cost.<br></li>
<li>Keep data local or in GCS to manage egress and compliance.<br></li>
<li>Always cite retrieved chunks for reproducibility and
transparency.</li>
</ul></div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</section></div> <!-- / div.lesson-content -->
    </main><!-- / main#main-content.main-content --><nav class="bottom-pagination mx-md-4" aria-label="Previous and Next Chapter"><div class="d-block d-sm-block d-md-none">
        <a class="chapter-link" href="../instructor/09-Resource-management-cleanup.html"><i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>Previous</a>
        <a class="chapter-link float-end" href="../instructor/index.html">Next<i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i></a>
      </div>
      <!-- content for large screens -->
      <div class="d-none d-sm-none d-md-block">
        <a class="chapter-link" href="../instructor/09-Resource-management-cleanup.html" rel="prev">
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>
          Previous: Resource Management
        </a>
        <a class="chapter-link float-end" href="../instructor/index.html" rel="next">
          Home
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i>
        </a>
      </div>
    </nav></div> <!-- / div.primary-content.col-xs-12 -->
<!-- END:   inst/pkgdown/templates/content-instructor.html-->

      </div><!--/div.row-->
      		<footer class="row footer mx-md-3"><hr><div class="col-md-6">
        <p>This lesson is subject to the <a href="CODE_OF_CONDUCT.html">Code of Conduct</a></p>
        <p>

        <a href="https://github.com/qualiaMachine/Intro_GCP_VertexAI/edit/main/episodes/10-Retrieval-augmented-generation.md" class="external-link">Edit on GitHub</a>

	
        | <a href="https://github.com/qualiaMachine/Intro_GCP_VertexAI/blob/main/CONTRIBUTING.md" class="external-link">Contributing</a>
        | <a href="https://github.com/qualiaMachine/Intro_GCP_VertexAI/" class="external-link">Source</a></p>
				<p><a href="https://github.com/qualiaMachine/Intro_GCP_VertexAI/blob/main/CITATION.cff" class="external-link">Cite</a> | <a href="mailto:endemann@wisc.edu">Contact</a> | <a href="https://carpentries.org/about/" class="external-link">About</a></p>
			</div>
			<div class="col-md-6">

        <p>Materials licensed under <a href="LICENSE.html">CC-BY 4.0</a> by the authors</p>

        <p>Template licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" class="external-link">CC-BY 4.0</a> by <a href="https://carpentries.org/" class="external-link">The Carpentries</a></p>
        <p>Built with <a href="https://github.com/carpentries/sandpaper/tree/0.17.1" class="external-link">sandpaper (0.17.1)</a>, <a href="https://github.com/carpentries/pegboard/tree/0.7.9" class="external-link">pegboard (0.7.9)</a>, and <a href="https://github.com/carpentries/varnish/tree/1.0.7" class="external-link">varnish (1.0.7)</a></p>
			</div>
		</footer></div> <!-- / div.container -->
	<div id="to-top">
		<a href="#top">
      <i class="search-icon" data-feather="arrow-up" role="img" aria-label="Back To Top"></i><br><!-- <span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top --><span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top
		</a>
	</div>
  <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "LearningResource",
  "@id": "https://qualiaMachine.github.io/Intro_GCP_VertexAI/instructor/10-Retrieval-augmented-generation.html",
  "inLanguage": "en",
  "dct:conformsTo": "https://bioschemas.org/profiles/LearningResource/1.0-RELEASE",
  "description": "A Carpentries Lesson teaching foundational data and coding skills to researchers worldwide",
  "keywords": "cloud, GCP, lesson, The Carpentries, ML, AI, GPU",
  "name": "Retrieval-Augmented Generation (RAG) with Vertex AI",
  "creativeWorkStatus": "active",
  "url": "https://qualiaMachine.github.io/Intro_GCP_VertexAI/instructor/10-Retrieval-augmented-generation.html",
  "identifier": "https://qualiaMachine.github.io/Intro_GCP_VertexAI/instructor/10-Retrieval-augmented-generation.html",
  "dateCreated": "2025-08-26",
  "dateModified": "2025-10-30",
  "datePublished": "2025-10-30"
}

  </script><script>
		feather.replace();
	</script></body></html><!-- END:   inst/pkgdown/templates/layout.html-->

