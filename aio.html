<!DOCTYPE html>
<!-- START: inst/pkgdown/templates/layout.html --><!-- Generated by pkgdown: do not edit by hand --><html lang="en" data-bs-theme="auto">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<title>Intro to Google Cloud Platform (GCP) for Machine Learning: All in One View</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<script src="assets/themetoggle.js"></script><link rel="stylesheet" type="text/css" href="assets/styles.css">
<script src="assets/scripts.js" type="text/javascript"></script><!-- mathjax --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/PreviewHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
      TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      },
      tex2jax: {
        inlineMath: [['\\(', '\\)']],
        displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
        processEscapes: true
      }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><!-- Responsive Favicon for The Carpentries --><link rel="apple-touch-icon" sizes="180x180" href="favicons/incubator/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="favicons/incubator/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="favicons/incubator/favicon-16x16.png">
<link rel="manifest" href="favicons/incubator/site.webmanifest">
<link rel="mask-icon" href="favicons/incubator/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="white">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="black">
</head>
<body>
    <header id="top" class="navbar navbar-expand-md top-nav incubator"><svg xmlns="http://www.w3.org/2000/svg" class="d-none"><symbol id="check2" viewbox="0 0 16 16"><path d="M13.854 3.646a.5.5 0 0 1 0 .708l-7 7a.5.5 0 0 1-.708 0l-3.5-3.5a.5.5 0 1 1 .708-.708L6.5 10.293l6.646-6.647a.5.5 0 0 1 .708 0z"></path></symbol><symbol id="circle-half" viewbox="0 0 16 16"><path d="M8 15A7 7 0 1 0 8 1v14zm0 1A8 8 0 1 1 8 0a8 8 0 0 1 0 16z"></path></symbol><symbol id="moon-stars-fill" viewbox="0 0 16 16"><path d="M6 .278a.768.768 0 0 1 .08.858 7.208 7.208 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277.527 0 1.04-.055 1.533-.16a.787.787 0 0 1 .81.316.733.733 0 0 1-.031.893A8.349 8.349 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.752.752 0 0 1 6 .278z"></path><path d="M10.794 3.148a.217.217 0 0 1 .412 0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217 0 0 1 0 .412l-1.162.387a1.734 1.734 0 0 0-1.097 1.097l-.387 1.162a.217.217 0 0 1-.412 0l-.387-1.162A1.734 1.734 0 0 0 9.31 6.593l-1.162-.387a.217.217 0 0 1 0-.412l1.162-.387a1.734 1.734 0 0 0 1.097-1.097l.387-1.162zM13.863.099a.145.145 0 0 1 .274 0l.258.774c.115.346.386.617.732.732l.774.258a.145.145 0 0 1 0 .274l-.774.258a1.156 1.156 0 0 0-.732.732l-.258.774a.145.145 0 0 1-.274 0l-.258-.774a1.156 1.156 0 0 0-.732-.732l-.774-.258a.145.145 0 0 1 0-.274l.774-.258c.346-.115.617-.386.732-.732L13.863.1z"></path></symbol><symbol id="sun-fill" viewbox="0 0 16 16"><path d="M8 12a4 4 0 1 0 0-8 4 4 0 0 0 0 8zM8 0a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 0zm0 13a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 13zm8-5a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2a.5.5 0 0 1 .5.5zM3 8a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2A.5.5 0 0 1 3 8zm10.657-5.657a.5.5 0 0 1 0 .707l-1.414 1.415a.5.5 0 1 1-.707-.708l1.414-1.414a.5.5 0 0 1 .707 0zm-9.193 9.193a.5.5 0 0 1 0 .707L3.05 13.657a.5.5 0 0 1-.707-.707l1.414-1.414a.5.5 0 0 1 .707 0zm9.193 2.121a.5.5 0 0 1-.707 0l-1.414-1.414a.5.5 0 0 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .707zM4.464 4.465a.5.5 0 0 1-.707 0L2.343 3.05a.5.5 0 1 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .708z"></path></symbol></svg><a class="visually-hidden-focusable skip-link" href="#main-content">Skip to main content</a>
  <div class="container-fluid top-nav-container">
    <div class="col-md-8">
      <div class="large-logo">
        <img id="incubator-logo" alt="Lesson Description" src="assets/images/incubator-logo.svg"><span class="badge text-bg-danger">
          <abbr title="This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught.">
            <a href="https://docs.carpentries.org/resources/curriculum/lesson-life-cycle.html" class="external-link alert-link">
              <i aria-hidden="true" class="icon" data-feather="alert-octagon" style="border-radius: 5px"></i>
              Pre-Alpha
            </a>
            <span class="visually-hidden">This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught.</span>
          </abbr>
        </span>

      </div>
    </div>
    <div class="selector-container">
      <div id="theme-selector">
        <li class="nav-item dropdown" id="theme-button-list">
          <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
            <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="bd-theme-text">
<li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                Light
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                Dark
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                Auto
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
          </ul>
</li>
      </div>

      <div class="dropdown" id="instructor-dropdown">
        <button class="btn btn-secondary dropdown-toggle bordered-button" type="button" id="dropdownMenu1" data-bs-toggle="dropdown" aria-expanded="false">
          <i aria-hidden="true" class="icon" data-feather="eye"></i> Learner View <i data-feather="chevron-down"></i>
        </button>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1">
<li><button class="dropdown-item" type="button" onclick="window.location.href='instructor/aio.html';">Instructor View</button></li>
        </ul>
</div>
    </div>
  </div>
  <hr></header><nav class="navbar navbar-expand-xl bottom-nav incubator" aria-label="Main Navigation"><div class="container-fluid nav-container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle Navigation">
      <span class="navbar-toggler-icon"></span>
      <span class="menu-title">Menu</span>
    </button>
    <div class="nav-logo">
      <img class="small-logo" alt="Lesson Description" src="assets/images/incubator-logo-sm.svg">
</div>
    <div class="lesson-title-md">
      Intro to Google Cloud Platform (GCP) for Machine Learning
    </div>
    <div class="search-icon-sm">
      <!-- TODO: do not show until we have search
        <i role="img" aria-label="Search the All In One page" data-feather="search"></i>
      -->
    </div>
    <div class="desktop-nav">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0">
<li class="nav-item">
          <span class="lesson-title">
            Intro to Google Cloud Platform (GCP) for Machine Learning
          </span>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="key-points.html">Key Points</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="reference.html#glossary">Glossary</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="profiles.html">Learner Profiles</a>
        </li>
        <li class="nav-item dropdown">
          <button class="nav-link dropdown-toggle" id="navbarDropdown" data-bs-toggle="dropdown" aria-expanded="false">
            More <i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdown">
<li><a class="dropdown-item" href="glossary.html">Glossary</a></li>
<li><a class="dropdown-item" href="instances-for-ML.html">Instances for ML</a></li>
          </ul>
</li>
      </ul>
</div>
    <!--
    <form class="d-flex col-md-2 search-form">
      <fieldset disabled>
      <input class="form-control me-2 searchbox" type="search" placeholder="" aria-label="">
        <button class="btn btn-outline-success tablet-search-button"  type="submit">
          <i class="search-icon" data-feather="search" role="img" aria-label="Search the All In One page"></i>
        </button>
      </fieldset>
    </form>
    -->
    <a id="search-button" class="btn btn-primary" href="aio.html" role="button" aria-label="Search the All In One page">Search the All In One page</a>
  </div>
<!--/div.container-fluid -->
</nav><div class="col-md-12 mobile-title">
  Intro to Google Cloud Platform (GCP) for Machine Learning
</div>

<aside class="col-md-12 lesson-progress"><div style="width: %" class="percentage">
    %
  </div>
  <div class="progress incubator">
    <div class="progress-bar incubator" role="progressbar" style="width: %" aria-valuenow="" aria-label="Lesson Progress" aria-valuemin="0" aria-valuemax="100">
    </div>
  </div>
</aside><div class="container">
      <div class="row">
        <!-- START: inst/pkgdown/templates/navbar.html -->
<div id="sidebar-col" class="col-lg-4">
  <div id="sidebar" class="sidebar">
      <nav aria-labelledby="flush-headingEleven"><button role="button" aria-label="close menu" alt="close menu" aria-expanded="true" aria-controls="sidebar" class="collapse-toggle" data-collapse="Collapse " data-episodes="Episodes ">
          <i class="search-icon" data-feather="x" role="img"></i>
        </button>
        <div class="sidebar-inner">
          <div class="row mobile-row" id="theme-row-mobile">
            <div class="col" id="theme-selector">
              <li class="nav-item dropdown" id="theme-button-list">
                <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
                  <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><span class="d-lg-none ms-1" id="bd-theme-text">Toggle Theme</span>
                </button>
                <ul class="dropdown-menu dropdown-menu-right" aria-labelledby="bd-theme-text">
<li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                      Light
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                      Dark
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                      <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                      Auto
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                </ul>
</li>
            </div>
          </div>
          <div class="row mobile-row">
            <div class="col">
              <div class="sidenav-view-selector">
                <div class="accordion accordion-flush" id="accordionFlush9">
                  <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingNine">
                      <button class="accordion-button collapsed" id="instructor" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseNine" aria-expanded="false" aria-controls="flush-collapseNine">
                        <i id="eye" aria-hidden="true" class="icon" data-feather="eye"></i> Learner View
                      </button>
                    </h2>
                    <div id="flush-collapseNine" class="accordion-collapse collapse" aria-labelledby="flush-headingNine" data-bs-parent="#accordionFlush2">
                      <div class="accordion-body">
                        <a href="instructor/aio.html">Instructor View</a>
                      </div>
                    </div>
                  </div>
<!--/div.accordion-item-->
                </div>
<!--/div.accordion-flush-->
              </div>
<!--div.sidenav-view-selector -->
            </div>
<!--/div.col -->

            <hr>
</div>
<!--/div.mobile-row -->

          <div class="accordion accordion-flush" id="accordionFlush11">
            <div class="accordion-item">

              <button id="chapters" class="accordion-button show" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseEleven" aria-expanded="false" aria-controls="flush-collapseEleven">
                <h2 class="accordion-header chapters" id="flush-headingEleven">
                  EPISODES
                </h2>
              </button>
              <div id="flush-collapseEleven" class="accordion-collapse show collapse" aria-labelledby="flush-headingEleven" data-bs-parent="#accordionFlush11">

                <div class="accordion-body">
                  <div class="accordion accordion-flush" id="accordionFlush1">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading1">
        <a href="index.html">Summary and Setup</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush2">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading2">
        <a href="01-Introduction.html">1. Overview of Google Cloud for Machine Learning</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush3">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading3">
        <a href="02-Data-storage.html">2. Data Storage: Setting up GCS</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush4">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading4">
        <a href="03-Notebooks-as-controllers.html">3. Notebooks as Controllers</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush5">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading5">
        <a href="04-Accessing-and-managing-data.html">4. Accessing and Managing Data in GCS with Vertex AI Notebooks</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush6">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading6">
        <a href="05-Interacting-with-code-repo.html">5. Using a GitHub Personal Access Token (PAT) to Push/Pull from a Vertex AI Notebook</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush7">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading7">
        <a href="06-Training-models-in-VertexAI.html">6. Training Models in Vertex AI: Intro</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush8">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading8">
        <a href="07-Training-models-in-VertexAI-GPUs.html">7. Training Models in Vertex AI: PyTorch Example</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush9">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading9">
        <a href="08-Hyperparameter-tuning.html">8. Hyperparameter Tuning in Vertex AI: Neural Network Example</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush10">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading10">
        <a href="09-Resource-management-cleanup.html">9. Resource Management &amp; Monitoring on Vertex AI (GCP)</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

                </div>
              </div>
            </div>

            <hr class="half-width">
<div class="accordion accordion-flush lesson-resources" id="accordionFlush12">
              <div class="accordion-item">
                <h2 class="accordion-header" id="flush-headingTwelve">
                  <button class="accordion-button collapsed" id="lesson-resources" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwelve" aria-expanded="false" aria-controls="flush-collapseTwelve">
                    RESOURCES
                  </button>
                </h2>
                <div id="flush-collapseTwelve" class="accordion-collapse collapse" aria-labelledby="flush-headingTwelve" data-bs-parent="#accordionFlush12">
                  <div class="accordion-body">
                    <ul>
<li>
                        <a href="key-points.html">Key Points</a>
                      </li>
                      <li>
                        <a href="reference.html#glossary">Glossary</a>
                      </li>
                      <li>
                        <a href="profiles.html">Learner Profiles</a>
                      </li>
                      <li><a href="glossary.html">Glossary</a></li>
<li><a href="instances-for-ML.html">Instances for ML</a></li>
                    </ul>
</div>
                </div>
              </div>
            </div>
            <hr class="half-width lesson-resources">
<a href="aio.html">See all in one page</a>


            <hr class="d-none d-sm-block d-md-none">
<div class="d-grid gap-1">

            </div>
          </div>
<!-- /div.accordion -->
        </div>
<!-- /div.sidebar-inner -->
      </nav>
</div>
<!-- /div.sidebar -->
  </div>
<!-- /div.sidebar-col -->
<!-- END:   inst/pkgdown/templates/navbar.html-->

        <!-- START: inst/pkgdown/templates/content-extra.html -->
  <div class="col-xl-8 col-lg-12 primary-content">
    <main id="main-content" class="main-content"><div class="container lesson-content">
        
        
<section id="aio-01-Introduction"><p>Content from <a href="01-Introduction.html">Overview of Google Cloud for Machine Learning</a></p>
<hr>
<p>Last updated on 2025-10-24 |

        <a href="https://github.com/qualiaMachine/Intro_GCP_VertexAI/edit/main/episodes/01-Introduction.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What problem does GCP aim to solve for ML researchers?<br>
</li>
<li>How does using a notebook as a controller help organize ML workflows
in the cloud?<br>
</li>
<li>How does GCP compare to AWS for ML workflows?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Understand the basic role of GCP in supporting ML research.<br>
</li>
<li>Recognize how a notebook can serve as a controller for cloud
resources.<br>
</li>
<li>Compare GCP and AWS approaches to building and managing ML
workflows.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<p>Google Cloud Platform (GCP) provides the basic building blocks
researchers need to run machine learning (ML) experiments at scale.
Instead of working only on your laptop or a high-performance computing
(HPC) cluster, you can spin up compute resources on demand, store
datasets in the cloud, and run low-cost notebooks that act as a
“controller” for larger training and tuning jobs.</p>
<p>This workshop focuses on <em>using a simple notebook environment as
the control center</em> for your ML workflow. We will not rely on
Google’s fully managed Vertex AI platform, but instead show how to use
core GCP services (Compute Engine, storage buckets, and SDKs) so you can
build and run experiments from scratch.</p>
<div class="section level3">
<h3 id="why-use-gcp-for-machine-learning">Why use GCP for machine learning?<a class="anchor" aria-label="anchor" href="#why-use-gcp-for-machine-learning"></a>
</h3>
<p>GCP provides several advantages that make it a strong option for
applied ML:</p>
<ul>
<li>
<p><strong>Flexible compute</strong>: You can choose the hardware
that fits your workload:</p>
<ul>
<li>
<strong>CPUs</strong> for lightweight models, preprocessing, or
feature engineering.<br>
</li>
<li>
<strong>GPUs</strong> (e.g., NVIDIA T4, V100, A100) for training
deep learning models.<br>
</li>
<li>
<strong>TPUs (Tensor Processing Units)</strong> for TensorFlow or
JAX-based deep learning. TPUs are custom Google hardware optimized for
matrix operations and can provide strong performance and energy
efficiency for compatible workloads. Google has reported better
performance-per-watt compared to GPUs in many TensorFlow benchmarks,
though <em>these gains depend heavily on model type and
implementation</em>.<br>
Historically, TPU support has been limited for PyTorch users, and while
Google is improving PyTorch integration, the TPU ecosystem still works
best for TensorFlow and JAX workflows.</li>
</ul>
</li>
<li><p><strong>Data storage and access</strong>: Google Cloud Storage
(GCS) buckets act like S3 on AWS — an easy way to store and share
datasets between experiments and collaborators.</p></li>
<li><p><strong>From scratch workflows</strong>: Instead of depending on
a fully managed ML service, you bring your own frameworks (PyTorch,
TensorFlow, scikit-learn, etc.) and run your code the same way you would
on your laptop or HPC cluster, but with scalable cloud
resources.</p></li>
<li><p><strong>Cost visibility</strong>: Billing dashboards and
project-level budgets make it easier to track costs and stay within
research budgets.</p></li>
<li><p><strong>Sustainability focus</strong>: Google aims to operate
entirely on <em>carbon-free energy by 2030</em>. Combined with the TPU’s
focus on efficient matrix computation, this gives GCP a potential edge
for researchers interested in energy-conscious ML — though
<em>real-world energy efficiency varies by workload and
utilization</em>.</p></li>
</ul>
<p>In short, GCP provides infrastructure that you control from a
notebook environment, allowing you to build and run ML workflows just as
you would locally, but with access to scalable hardware and storage.</p>
<div id="what-about-aws" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div id="what-about-aws" class="callout-inner">
<h3 class="callout-title">What about AWS?</h3>
<div class="callout-content">
<p>In many respects, GCP and AWS offer comparable capabilities for ML
research. Both provide scalable compute, storage, and tooling to support
everything from quick experiments to production pipelines.<br>
AWS typically offers a broader range of GPU and CPU instance types,
along with mature managed services like SageMaker and tighter
integration with enterprise infrastructure. GCP, on the other hand,
emphasizes the use of TensorFlow and JAX, and the availability of TPUs —
which may offer energy advantages for certain workloads.</p>
<p>Ultimately, the choice often comes down to framework preference,
familiarity, and existing resources, rather than major functional
differences between the two platforms.</p>
</div>
</div>
</div>
<div id="comparing-infrastructures" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<span class="callout-header">Discussion</span>
<div id="comparing-infrastructures" class="callout-inner">
<h3 class="callout-title">Comparing infrastructures</h3>
<div class="callout-content">
<p>Think about your current research setup:<br>
- Do you mostly use your laptop, HPC cluster, AWS, or GCP for ML
experiments?<br>
- Which environment feels most transparent for understanding costs and
reproducibility?<br>
- If you could offload one infrastructure challenge (e.g., installing
GPU drivers, managing storage, or setting up environments), what would
it be and why?</p>
<p>Take 3–5 minutes to discuss with a partner or share in the workshop
chat.</p>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>GCP and AWS both provide the essential components for running ML
workloads at scale.<br>
</li>
<li>GCP emphasizes simplicity, open frameworks, and TPU access; AWS
offers broader hardware and automation options.<br>
</li>
<li>TPUs are efficient for TensorFlow and JAX, but GPU-based workflows
(common on AWS) remain more flexible across frameworks.<br>
</li>
<li>Both platforms now provide strong cost tracking and sustainability
tools, with only minor differences in interface and ecosystem
integration.<br>
</li>
<li>Using a notebook as a controller provides reproducibility and helps
manage compute and storage resources consistently across clouds.</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</div></section><section id="aio-02-Data-storage"><p>Content from <a href="02-Data-storage.html">Data Storage: Setting up GCS</a></p>
<hr>
<p>Last updated on 2025-10-27 |

        <a href="https://github.com/qualiaMachine/Intro_GCP_VertexAI/edit/main/episodes/02-Data-storage.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How can I store and manage data effectively in GCP for Vertex AI
workflows?<br>
</li>
<li>What are the advantages of Google Cloud Storage (GCS) compared to
local or VM storage for machine learning projects?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Explain data storage options in GCP for machine learning
projects.<br>
</li>
<li>Describe the advantages of GCS for large datasets and collaborative
workflows.<br>
</li>
<li>Outline steps to set up a GCS bucket and manage data within Vertex
AI.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<p>Machine learning and AI projects rely on data, making efficient
storage and management essential. Google Cloud offers several storage
options, but the most common for ML workflows are <strong>Virtual
Machine (VM) disks</strong> and <strong>Google Cloud Storage (GCS)
buckets</strong>.</p>
<blockquote>
<h4 id="consult-your-institutions-it-before-handling-sensitive-data-in-gcp">Consult
your institution’s IT before handling sensitive data in GCP</h4>
<p>As with AWS, <strong>do not upload restricted or sensitive data to
GCP services unless explicitly approved by your institution’s IT or
cloud security team</strong>. For regulated datasets (HIPAA, FERPA,
proprietary), work with your institution to ensure encryption,
restricted access, and compliance with policies.</p>
</blockquote>
<section><h2 class="section-heading" id="options-for-storage-vm-disks-or-gcs">Options for storage: VM Disks or GCS<a class="anchor" aria-label="anchor" href="#options-for-storage-vm-disks-or-gcs"></a>
</h2>
<hr class="half-width">
<div class="section level3">
<h3 id="what-is-a-vm-disk">What is a VM disk?<a class="anchor" aria-label="anchor" href="#what-is-a-vm-disk"></a>
</h3>
<p>A VM disk is the storage volume attached to a Compute Engine VM or a
Vertex AI Workbench notebook. It can store datasets and intermediate
results, but it is tied to the lifecycle of the VM.</p>
<div class="section level4">
<h4 id="when-to-store-data-directly-on-a-vm-disk">When to store data directly on a VM disk<a class="anchor" aria-label="anchor" href="#when-to-store-data-directly-on-a-vm-disk"></a>
</h4>
<ul>
<li>Useful for small, temporary datasets processed interactively.<br>
</li>
<li>Data persists if the VM is stopped, but storage costs continue as
long as the disk exists.<br>
</li>
<li>Not ideal for collaboration, scaling, or long-term dataset
storage.</li>
</ul>
<div id="limitations-of-vm-disk-storage" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div id="limitations-of-vm-disk-storage" class="callout-inner">
<h3 class="callout-title">Limitations of VM disk storage</h3>
<div class="callout-content">
<ul>
<li>
<strong>Scalability</strong>: Limited by disk size quota.<br>
</li>
<li>
<strong>Sharing</strong>: Harder to share across projects or team
members.<br>
</li>
<li>
<strong>Cost</strong>: More expensive per GB compared to GCS for
long-term storage.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="what-is-a-gcs-bucket">What is a GCS bucket?<a class="anchor" aria-label="anchor" href="#what-is-a-gcs-bucket"></a>
</h3>
<p>For most ML workflows in GCP, <strong>Google Cloud Storage (GCS)
buckets</strong> are recommended. A GCS bucket is a container in
Google’s object storage service where you can store an essentially
unlimited number of files. Data in GCS can be accessed from Vertex AI
training jobs, Workbench notebooks, and other GCP services using a
<em>GCS URI</em> (e.g.,
<code>gs://your-bucket-name/your-file.csv</code>).</p>
<div id="benefits-of-using-gcs-recommended-for-ml-workflows" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div id="benefits-of-using-gcs-recommended-for-ml-workflows" class="callout-inner">
<h3 class="callout-title">Benefits of using GCS (recommended for ML
workflows)</h3>
<div class="callout-content">
<ul>
<li>
<strong>Separation of storage and compute</strong>: Data remains
available even if VMs or notebooks are deleted.<br>
</li>
<li>
<strong>Easy sharing</strong>: Buckets can be accessed by
collaborators with the right IAM roles.<br>
</li>
<li>
<strong>Integration with Vertex AI and BigQuery</strong>: Read and
write data directly using other GCP tools.<br>
</li>
<li>
<strong>Scalability</strong>: Handles datasets of any size without
disk limits.<br>
</li>
<li>
<strong>Cost efficiency</strong>: Lower cost than persistent disks
for long-term storage.<br>
</li>
<li>
<strong>Data persistence</strong>: Durable and highly available
across regions.</li>
</ul>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="recommended-approach-gcs-buckets">Recommended approach: GCS buckets<a class="anchor" aria-label="anchor" href="#recommended-approach-gcs-buckets"></a>
</h2>
<hr class="half-width">
<p>To upload our Titanic dataset to a GCS bucket, we’ll follow these
steps:</p>
<ol style="list-style-type: decimal">
<li>Log in to the Google Cloud Console.<br>
</li>
<li>Create a new bucket (or use an existing one).<br>
</li>
<li>Upload your dataset files.<br>
</li>
<li>Use the GCS URI to reference your data in Vertex AI workflows.</li>
</ol>
<div class="section level3">
<h3 id="sign-in-to-google-cloud-console">1. Sign in to Google Cloud Console<a class="anchor" aria-label="anchor" href="#sign-in-to-google-cloud-console"></a>
</h3>
<ul>
<li>Go to <a href="https://console.cloud.google.com" class="external-link">console.cloud.google.com</a> and
log in with your credentials.</li>
</ul>
</div>
<div class="section level3">
<h3 id="navigate-to-cloud-storage">2. Navigate to Cloud Storage<a class="anchor" aria-label="anchor" href="#navigate-to-cloud-storage"></a>
</h3>
<ul>
<li>In the search bar, type <strong>Storage</strong>.<br>
</li>
<li>Click <strong>Cloud Storage &gt; Buckets</strong>.</li>
</ul>
</div>
<div class="section level3">
<h3 id="create-a-new-bucket">3. Create a new bucket<a class="anchor" aria-label="anchor" href="#create-a-new-bucket"></a>
</h3>
<ul>
<li>Click <strong>Create bucket</strong>.</li>
</ul>
<div class="section level4">
<h4 id="a--getting-started-bucket-name-and-tags">3a. Getting Started (bucket name and tags)<a class="anchor" aria-label="anchor" href="#a--getting-started-bucket-name-and-tags"></a>
</h4>
<ul>
<li>
<strong>Provide a bucket name</strong>: Enter a globally unique
name. For this workshop, we can use the following naming convention to
easily locate our buckets: <code>teamname-firstlastname-dataname</code>
(e.g., sinkorswim-johndoe-titanic)</li>
<li>
<strong>Add labels (tags) to track costs</strong>: Add labels to
track resource usage and billing. If you’re working in a shared account,
this step is <em>mandatory</em>. If not, it’s still recommended to help
you track your own costs!
<ul>
<li>
<code>project = teamname</code> (your team’s name)</li>
<li>
<code>name = name</code> (firstname-lastname)</li>
<li>
<code>purpose=bucket-dataname</code> (include bucket- prefix
followed by name of dataset)</li>
</ul>
</li>
</ul>
<figure><img src="https://raw.githubusercontent.com/qualiaMachine/Intro_GCP_for_ML/main/images/bucket-tags.jpg" alt="Screenshot showing required tags for a GCS bucket" class="figure mx-auto d-block"><div class="figcaption">Example of Tags for a GCS Bucket</div>
</figure>
</div>
<div class="section level4">
<h4 id="b--choose-where-to-store-your-data">3b. Choose where to store your data<a class="anchor" aria-label="anchor" href="#b--choose-where-to-store-your-data"></a>
</h4>
<p>When creating a storage bucket in Google Cloud, the best practice for
most machine learning workflows is to use a regional bucket in the same
region as your compute resources (for example, us-central1). This setup
provides the lowest latency and avoids network egress charges when
training jobs read from storage, while also keeping costs predictable. A
multi-region bucket, on the other hand, can make sense if your primary
goal is broad availability or if collaborators in different regions need
reliable access to the same data; the trade-off is higher cost and the
possibility of extra egress charges when pulling data into a specific
compute region. For most research projects, a regional bucket with the
Standard storage class, uniform access control, and public access
prevention enabled offers a good balance of performance, security, and
affordability.</p>
<ul>
<li>
<strong>Region</strong> (cheapest, good default). For instance,
us-central1 (Iowa) costs $0.020 per GB-month.</li>
<li>
<strong>Multi-region</strong> (higher redundancy, more
expensive).</li>
</ul>
<figure><img src="https://raw.githubusercontent.com/qualiaMachine/Intro_GCP_for_ML/main/images/bucket-location.jpg" alt="Choose where to store your data" class="figure mx-auto d-block"><div class="figcaption">Choose where to store your data</div>
</figure>
</div>
<div class="section level4">
<h4 id="c--choose-how-to-store-your-data-storage-class">3c. Choose how to store your data (storage class)<a class="anchor" aria-label="anchor" href="#c--choose-how-to-store-your-data-storage-class"></a>
</h4>
<p>When creating a bucket, you’ll be asked to choose a storage class,
which determines how much you pay for storing data and how often you’re
allowed to access it without extra fees.</p>
<ul>
<li>
<strong>Standard</strong> – best for active ML/AI workflows.
Training data is read and written often, so this is the safest
default.</li>
<li>
<strong>Nearline / Coldline / Archive</strong> – designed for
backups or rarely accessed files. These cost less per GB to store, but
you pay retrieval fees if you read them during training. Not recommended
for most ML projects where data access is frequent.</li>
</ul>
<blockquote>
<p>You may see an option to “Enable hierarchical namespace”. GCP now
offers an option to enable a hierarchical namespace for buckets, but
this is mainly useful for large-scale analytics pipelines. For most ML
workflows, the standard flat namespace is simpler and fully
compatible—so it’s best to leave this option off.</p>
</blockquote>
</div>
<div class="section level4">
<h4 id="d--choose-how-to-control-access-to-objects">3d. Choose how to control access to objects<a class="anchor" aria-label="anchor" href="#d--choose-how-to-control-access-to-objects"></a>
</h4>
<p>For ML projects, you should <strong>prevent public access</strong> so
that only authorized users can read or write data. This keeps research
datasets private and avoids accidental exposure.</p>
<p>When prompted to choose an access control method, choose
<strong>uniform access</strong> unless you have a very specific reason
to manage object-level permissions.</p>
<ul>
<li>
<strong>Uniform access (recommended):</strong> Simplifies management
by enforcing permissions at the bucket level using IAM roles. It’s the
safer and more maintainable choice for teams and becomes permanent after
90 days.<br>
</li>
<li>
<strong>Fine-grained access:</strong> Allows per-file permissions
using ACLs, but adds complexity and is rarely needed outside of web
hosting or mixed-access datasets.</li>
</ul>
</div>
<div class="section level4">
<h4 id="e--choose-how-to-protect-object-data">3e. Choose how to protect object data<a class="anchor" aria-label="anchor" href="#e--choose-how-to-protect-object-data"></a>
</h4>
<p>GCP automatically protects all stored data, but you can enable
additional layers of protection depending on your project’s needs. For
most ML or research workflows, you’ll want to balance safety with
cost.</p>
<ul>
<li>
<strong>Soft delete policy (recommended for shared
projects):</strong> Keeps deleted objects recoverable for a short period
(default is 7 days). This is useful if team members might accidentally
remove data. You can set a custom retention duration, but longer windows
increase storage costs.</li>
<li>
<strong>Object versioning:</strong> Creates new versions of files
when they’re modified or overwritten. This can be helpful for tracking
model outputs or experiment logs but may quickly increase costs. Enable
only if you expect frequent overwrites and need rollback
capability.</li>
<li>
<strong>Retention policy (for compliance use only):</strong>
Prevents deletion or modification of objects for a fixed time window.
This is typically required for regulated data but should be avoided for
active ML projects, since it can block normal cleanup and retraining
workflows.</li>
</ul>
<blockquote>
<p>In short: keep the <strong>default soft delete</strong> unless you
have specific compliance requirements. Use <strong>object
versioning</strong> sparingly, and avoid <strong>retention
locks</strong> unless mandated by policy.</p>
</blockquote>
</div>
<div class="section level4">
<h4 id="final-check">Final check<a class="anchor" aria-label="anchor" href="#final-check"></a>
</h4>
<p>After configuring all settings, your bucket settings preview should
look similar to the screenshot below (with the bucket name adjusted for
your name).</p>
<figure><img src="https://raw.githubusercontent.com/qualiaMachine/Intro_GCP_for_ML/main/images/bucket-fullyconfigured.jpg" alt="Recommended GCS bucket settings." class="figure mx-auto d-block"><div class="figcaption">Final GCS Bucket Settings</div>
</figure><p>Click <strong>Create</strong> if everything looks good.</p>
</div>
</div>
<div class="section level3">
<h3 id="upload-files-to-the-bucket">4. Upload files to the bucket<a class="anchor" aria-label="anchor" href="#upload-files-to-the-bucket"></a>
</h3>
<ul>
<li>If you haven’t yet, download the data for this workshop (Right-click
→ Save as):<br><a href="https://raw.githubusercontent.com/qualiaMachine/Intro_GCP_for_ML/main/data/data.zip" class="external-link">data.zip</a>
<ul>
<li>Extract the zip folder contents (Right-click → Extract all on
Windows; double-click on macOS).</li>
</ul>
</li>
<li>In the bucket dashboard, click <strong>Upload Files</strong>.<br>
</li>
<li>Select your Titanic CSVs and upload.</li>
</ul>
<p><strong>Note the GCS URI for your data</strong> After uploading,
click on a file and find its <strong>gs:// URI</strong> (e.g.,
<code>gs://sinkorswim-johndoe-titanic/titanic_test.csv</code>). This URI
will be used to access the data later.</p>
</div>
</section><section><h2 class="section-heading" id="adjust-bucket-permissions">Adjust bucket permissions<a class="anchor" aria-label="anchor" href="#adjust-bucket-permissions"></a>
</h2>
<hr class="half-width">
<p>Return to the Google Cloud Console (where we created our bucket and
VM) and search for “Cloud Shell Editor”. Open a shell editor and run the
below command, *replacing the bucket name with your bucket’s name`:</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">SH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode sh" tabindex="0"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="co"># Grant read permisssions on the bucket</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="ex">gcloud</span> storage buckets add-iam-policy-binding gs://sinkorswim-johndoe-titanic <span class="dt">\</span></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a>  <span class="at">--member</span><span class="op">=</span><span class="st">"serviceAccount:549047673858-compute@developer.gserviceaccount.com"</span> <span class="dt">\</span></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a>  <span class="at">--role</span><span class="op">=</span><span class="st">"roles/storage.objectViewer"</span></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="co"># Grant write permisssions on the bucket</span></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="ex">gcloud</span> storage buckets add-iam-policy-binding gs://sinkorswim-johndoe-titanic <span class="dt">\</span></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a>  <span class="at">--member</span><span class="op">=</span><span class="st">"serviceAccount:549047673858-compute@developer.gserviceaccount.com"</span> <span class="dt">\</span></span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a>  <span class="at">--role</span><span class="op">=</span><span class="st">"roles/storage.objectCreator"</span></span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a><span class="co"># (Only if you also need overwrite/delete)</span></span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a><span class="ex">gcloud</span> storage buckets add-iam-policy-binding gs://sinkorswim-johndoe-titanic <span class="dt">\</span></span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a>  <span class="at">--member</span><span class="op">=</span><span class="st">"serviceAccount:549047673858-compute@developer.gserviceaccount.com"</span> <span class="dt">\</span></span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a>  <span class="at">--role</span><span class="op">=</span><span class="st">"roles/storage.objectAdmin"</span></span></code></pre>
</div>
<p>This grants our future VMs permission to read objects from the
bucket.</p>
</section><section><h2 class="section-heading" id="data-transfer-storage-costs-explained">Data transfer &amp; storage costs explained<a class="anchor" aria-label="anchor" href="#data-transfer-storage-costs-explained"></a>
</h2>
<hr class="half-width">
<p>GCS costs are based on storage class, data transfer, and operations
(requests).</p>
<ul>
<li>
<strong>Standard storage</strong>: Data storage cost is based on
region. In <code>us-central1</code>, the cost is ~$0.02 per GB per
month.<br>
</li>
<li>
<strong>Uploading data (ingress):</strong> Copying data into a GCS
bucket from your laptop, campus HPC, or another provider is free.<br>
</li>
<li>
<strong>Downloading data out of GCP (egress):</strong> Refers to
data leaving Google’s network to the public internet, such as
downloading files from GCS to your local machine. Typical cost is around
$0.12 per GB to the U.S. and North America, more for other continents.
<ul>
<li>
<strong>Cross-region access:</strong> If your bucket is in one
region and your compute runs in another, you’ll pay an egress fee of
about $0.01–0.02 per GB within North America, higher if crossing
continents.<br>
</li>
</ul>
</li>
<li>
<strong>Reading (GET) requests:</strong> Each read or list operation
incurs a small API request fee of roughly $0.004 per 10,000 requests.
<ul>
<li>Example: a training job that loads 10,000 image samples from GCS
(one per batch) would make about 10,000 GET requests, costing around
$0.004 total. Reading a large file such as a 1 GB CSV or TFRecord shard
counts as a single GET request.<br>
</li>
</ul>
</li>
<li>
<strong>Writing (PUT/POST/LIST) requests:</strong> Uploading,
creating, or modifying objects costs about $0.05 per 10,000 requests.
<ul>
<li>Example: saving one model checkpoint file (e.g.,
<code>model-weights.h5</code> or <code>model.pt</code>) triggers one PUT
request. A training pipeline that saves a few dozen checkpoints or logs
would cost well under one cent in request fees.<br>
</li>
</ul>
</li>
<li>
<strong>Deleting data:</strong> Removing objects or buckets does not
incur transfer costs. If you download data before deleting, you pay for
the egress, but deleting directly in the console or CLI is free. For
Nearline, Coldline, or Archive storage classes, deleting before the
minimum storage duration (30, 90, or 365 days) triggers an
early-deletion fee.</li>
</ul>
<p><strong><em>For detailed pricing, see <a href="https://cloud.google.com/storage/pricing" class="external-link">GCS Pricing
Information</a>.</em></strong></p>
<div id="challenge-estimating-storage-costs" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="challenge-estimating-storage-costs" class="callout-inner">
<h3 class="callout-title">Challenge: Estimating Storage Costs</h3>
<div class="callout-content">
<p><strong>1. Estimate the total cost of storing 1 GB in GCS Standard
storage (us-central1) for one month assuming:</strong><br>
- Storage duration: 1 month<br>
- Dataset retrieved 100 times for model training and tuning<br>
- Data is downloaded once out of GCP at the end of the project</p>
<p><strong>Hints</strong><br>
- Storage cost: $0.02 per GB per month<br>
- Egress (download out of GCP): $0.12 per GB<br>
- <code>GET</code> requests: $0.004 per 10,000 requests (100 requests ≈
free for our purposes)</p>
<p><strong>2. Repeat the above calculation for datasets of 10 GB, 100
GB, and 1 TB (1024 GB).</strong></p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">
<ol style="list-style-type: decimal">
<li>
<strong>1 GB</strong>:<br>
</li>
</ol>
<ul>
<li>Storage: 1 GB × $0.02 = $0.02<br>
</li>
<li>Egress: 1 GB × $0.12 = $0.12<br>
</li>
<li>Requests: ~0 (100 reads well below pricing tier)<br>
</li>
<li><strong>Total: $0.14</strong></li>
</ul>
<ol style="list-style-type: decimal">
<li>
<strong>10 GB</strong>:<br>
</li>
</ol>
<ul>
<li>Storage: 10 GB × $0.02 = $0.20<br>
</li>
<li>Egress: 10 GB × $0.12 = $1.20<br>
</li>
<li>Requests: ~0<br>
</li>
<li><strong>Total: $1.40</strong></li>
</ul>
<ol style="list-style-type: decimal">
<li>
<strong>100 GB</strong>:<br>
</li>
</ol>
<ul>
<li>Storage: 100 GB × $0.02 = $2.00<br>
</li>
<li>Egress: 100 GB × $0.12 = $12.00<br>
</li>
<li>Requests: ~0<br>
</li>
<li><strong>Total: $14.00</strong></li>
</ul>
<ol style="list-style-type: decimal">
<li>
<strong>1 TB (1024 GB)</strong>:<br>
</li>
</ol>
<ul>
<li>Storage: 1024 GB × $0.02 = $20.48<br>
</li>
<li>Egress: 1024 GB × $0.12 = $122.88<br>
</li>
<li>Requests: ~0<br>
</li>
<li><strong>Total: $143.36</strong></li>
</ul>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="removing-unused-data-complete-after-the-workshop">Removing unused data (complete <em>after</em> the workshop)<a class="anchor" aria-label="anchor" href="#removing-unused-data-complete-after-the-workshop"></a>
</h2>
<hr class="half-width">
<p>After you are done using your data, remove unused files/buckets to
stop costs:</p>
<ul>
<li>
<strong>Option 1: Delete files only</strong> – if you plan to reuse
the bucket.<br>
</li>
<li>
<strong>Option 2: Delete the bucket entirely</strong> – if you no
longer need it.</li>
</ul></section><section><h2 class="section-heading" id="when-does-bigquery-come-into-play">When does BigQuery come into play?<a class="anchor" aria-label="anchor" href="#when-does-bigquery-come-into-play"></a>
</h2>
<hr class="half-width">
<p>BigQuery is Google Cloud’s managed data warehouse for storing and
analyzing large tabular datasets using SQL. It’s designed for
interactive querying and analytics rather than file storage. For most ML
workflows—especially smaller projects or those focused on images, text,
or modest tabular data—BigQuery isn’t needed. Cloud Storage (GCS)
buckets are usually enough: they can store data efficiently and let you
stream files directly into your training code without downloading them
locally.</p>
<p>BigQuery becomes useful when you’re working with large, structured
datasets that multiple team members need to query or explore
collaboratively. Instead of reading entire files, you can use SQL to
retrieve only the subset of data you need. Teams can share results
through saved queries or views and control access at the dataset or
table level with IAM. BigQuery also integrates with Vertex AI, allowing
structured data stored there to connect directly to training pipelines.
The main trade-off is cost: you pay for both storage and the amount of
data scanned by queries.</p>
<blockquote>
<p>In short, use GCS buckets for storing and streaming files into
typical ML workflows, and consider BigQuery when you need a shared,
queryable workspace for large tabular datasets.</p>
</blockquote>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>Use GCS for scalable, cost-effective, and persistent storage in
GCP.<br>
</li>
<li>Persistent disks are suitable only for small, temporary
datasets.<br>
</li>
<li>Track your storage, transfer, and request costs to manage
expenses.<br>
</li>
<li>Regularly delete unused data or buckets to avoid ongoing costs.</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</section></section><section id="aio-03-Notebooks-as-controllers"><p>Content from <a href="03-Notebooks-as-controllers.html">Notebooks as Controllers</a></p>
<hr>
<p>Last updated on 2025-10-27 |

        <a href="https://github.com/qualiaMachine/Intro_GCP_VertexAI/edit/main/episodes/03-Notebooks-as-controllers.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How do you set up and use Vertex AI Workbench notebooks for machine
learning tasks?<br>
</li>
<li>How can you manage compute resources efficiently using a
“controller” notebook approach in GCP?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Describe how to use Vertex AI Workbench notebooks for ML
workflows.<br>
</li>
<li>Set up a Jupyter-based Workbench instance as a controller to manage
compute tasks.<br>
</li>
<li>Use the Vertex AI SDK to launch training and tuning jobs on scalable
instances.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="setting-up-our-notebook-environment">Setting up our notebook environment<a class="anchor" aria-label="anchor" href="#setting-up-our-notebook-environment"></a>
</h2>
<hr class="half-width">
<p>Google Cloud Workbench provides JupyterLab-based environments that
can be used to orchestrate machine learning workflows. In this workshop,
we will use a <strong>Workbench Instance</strong>—the recommended option
going forward, as other Workbench environments are being deprecated.</p>
<blockquote>
<p>Workbench Instances come with JupyterLab 3 pre-installed and are
configured with GPU-enabled ML frameworks (TensorFlow, PyTorch, etc.),
making it easy to start experimenting without additional setup. Learn
more in the <a href="https://cloud.google.com/vertex-ai/docs/workbench/instances/introduction?_gl=1*r0g0e9*_ga*MTczMzg4NDE1OC4xNzU4MzEyMTE0*_ga_WH2QY8WWF5*czE3NTg1NTczMzkkbzMkZzEkdDE3NTg1NjIxNzgkajI3JGwwJGgw" class="external-link">Workbench
Instances documentation</a>.</p>
</blockquote>
</section><section><h2 class="section-heading" id="using-the-notebook-as-a-controller">Using the notebook as a controller<a class="anchor" aria-label="anchor" href="#using-the-notebook-as-a-controller"></a>
</h2>
<hr class="half-width">
<p>The notebook instance functions as a <em>controller</em> to manage
more resource-intensive tasks. By selecting a modest machine type (e.g.,
<code>n1-standard-4</code>), you can perform lightweight operations
locally in the notebook while using the <strong>Vertex AI Python
SDK</strong> to launch compute-heavy jobs on larger machines (e.g.,
GPU-accelerated) when needed.</p>
<p>This approach minimizes costs while giving you access to scalable
infrastructure for demanding tasks like model training, batch
prediction, and hyperparameter tuning.</p>
<p>We will follow these steps to create our first Workbench
Instance:</p>
<div class="section level3">
<h3 id="navigate-to-workbench">1. Navigate to Workbench<a class="anchor" aria-label="anchor" href="#navigate-to-workbench"></a>
</h3>
<ul>
<li>In the Google Cloud Console, search for “Workbench.”<br>
</li>
<li>Click the “Instances” tab (this is the supported path going
forward).<br>
</li>
<li>Pin Workbench to your navigation bar for quick access.</li>
</ul>
</div>
<div class="section level3">
<h3 id="create-a-new-workbench-instance">2. Create a new Workbench Instance<a class="anchor" aria-label="anchor" href="#create-a-new-workbench-instance"></a>
</h3>
<div class="section level4">
<h4 id="initial-settings">Initial settings<a class="anchor" aria-label="anchor" href="#initial-settings"></a>
</h4>
<ul>
<li>Click <strong>Create New</strong> near the top of the Workbench
page</li>
<li>
<strong>Name</strong>: For this workshop, we can use the following
naming convention to easily locate our notebooks:
<code>teamname-yourname-purpose</code> (e.g.,
sinkorswim-johndoe-train)</li>
<li>
<strong>Region</strong>: Choose the same region as your storage
bucket (e.g., <code>us-central1</code>). This avoids cross-region
transfer charges and keeps data access latency low.
<ul>
<li>If you are unsure, check your bucket’s location in the Cloud Storage
console (click the bucket name → look under “Location”).</li>
</ul>
</li>
<li>
<strong>Zone:</strong> <code>us-central1-a</code> (or another zone
in <code>us-central1</code>, like <code>-b</code> or <code>-c</code>)
<ul>
<li>If capacity or GPU availability is limited in one zone, switch to
another zone in the same region.</li>
</ul>
</li>
<li>
<strong>NVIDIA T4 GPU:</strong> Leave unchecked for now
<ul>
<li>We will request GPUs for training jobs separately. Attaching here
increases idle costs.</li>
</ul>
</li>
<li>
<strong>Apache Spark and BigQuery Kernels:</strong> Leave unchecked
<ul>
<li>Enable only if you specifically need Spark or BigQuery notebooks;
otherwise, it adds unnecessary images.</li>
</ul>
</li>
<li>
<strong>Network in this project:</strong> Required selection
<ul>
<li>This option must be selected; shared environments do not allow using
external or default networks.<br>
</li>
<li>This ensures your instance connects to the shared VPC for the
workshop.</li>
</ul>
</li>
<li>
<strong>Network / Subnetwork:</strong> Leave as pre-filled. <img src="https://raw.githubusercontent.com/qualiaMachine/Intro_GCP_for_ML/main/images/new-instance-settings1.jpg" alt="Notebook settings (part1)" class="figure">
</li>
</ul>
</div>
<div class="section level4">
<h4 id="advanced-settings-details-tagging">Advanced settings: Details (tagging)<a class="anchor" aria-label="anchor" href="#advanced-settings-details-tagging"></a>
</h4>
<ul>
<li>
<strong>IMPORTANT:</strong> Open the “Advanced optoins menu next
<ul>
<li>
<strong>Labels (required for cost tracking):</strong> Under the
Details menu, add the following tags (all lowercase) so that you can
track the total cost of your activity on GCP later:
<ul>
<li>
<code>project = teamname</code> (your team’s name)</li>
<li>
<code>name = name</code> (firstname-lastname)</li>
<li>
<code>purpose = train</code> (i.e., the notebook’s overall purpose —
train, tune, RAG, etc.)</li>
</ul>
</li>
</ul>
</li>
</ul>
<figure><img src="https://raw.githubusercontent.com/qualiaMachine/Intro_GCP_for_ML/main/images/new-instance-tags.jpg" alt="Screenshot showing required tags for notebook" class="figure mx-auto d-block"><div class="figcaption">Required tags for notebook.</div>
</figure>
</div>
<div class="section level4">
<h4 id="advanced-settings-environment">Advanced Settings: Environment<a class="anchor" aria-label="anchor" href="#advanced-settings-environment"></a>
</h4>
<p>While we won’t modify environment settings during this workshop, it’s
useful to understand what these options control when creating or editing
a Workbench Instance in Vertex AI Workbench.</p>
<p>All Workbench environments use JupyterLab 3 by default, with the
latest NVIDIA GPU drivers, CUDA libraries, and Intel optimizations
preinstalled. You can optionally select JupyterLab 4 (currently in
preview) or provide a custom container image to run your own environment
(for example, a Docker image containing specialized ML frameworks or
dependencies). If needed, you can also specify a post-startup script
stored in Cloud Storage (<code>gs://path/to/script.sh</code>) to
automatically configure the instance (install packages, mount buckets,
etc.) when it boots.</p>
<p>See: <a href="https://cloud.google.com/vertex-ai/docs/release-notes" class="external-link">Vertex AI
Workbench release notes</a> for supported versions and base images.</p>
</div>
<div class="section level4">
<h4 id="advanced-settings-machine-type">Advanced settings: Machine Type<a class="anchor" aria-label="anchor" href="#advanced-settings-machine-type"></a>
</h4>
<ul>
<li>
<strong>Machine type</strong>: Select a small machine (e.g.,
<code>e2-standard-2</code>) to act as the controller.
<ul>
<li>This keeps costs low while you delegate heavy lifting to training
jobs.<br>
</li>
<li>For guidance on common machine types for ML, refer to <a href="instances-for-ML.html">Instances for ML on GCP</a>.</li>
</ul>
</li>
<li>
<strong>Set idle shutdown</strong>: To save on costs when you aren’t
doing anything in your notebook, lower the default idle shutdown time to
<strong>60 (minutes)</strong>.</li>
</ul>
<figure><img src="https://raw.githubusercontent.com/qualiaMachine/Intro_GCP_for_ML/main/images/new-instance-idleshutdown.jpg" alt="Set Idle Shutdown" class="figure mx-auto d-block"><div class="figcaption">Enable Idle Shutdown</div>
</figure>
</div>
<div class="section level4">
<h4 id="advanced-settings-disks">Advanced Settings: Disks<a class="anchor" aria-label="anchor" href="#advanced-settings-disks"></a>
</h4>
<p>Each Vertex AI Workbench instance uses <strong>Persistent Disks
(PDs)</strong> to store your system files and data. You’ll configure two
disks when creating a notebook: a <strong>boot disk</strong> and a
<strong>data disk</strong>. We’ll leave these at their default settings,
but it’s useful to understand the settings for future work.</p>
<div class="section level5">
<h5 id="boot-disk">Boot Disk<a class="anchor" aria-label="anchor" href="#boot-disk"></a>
</h5>
<p>Keep this fixed at <strong>100 GB (Balanced PD)</strong> — the
default minimum.<br>
It holds the OS, JupyterLab, and ML libraries but not your
datasets.<br>
Estimated cost: about <strong>$10 / month (~$0.014 / hr)</strong>.<br>
You rarely need to resize this, though you can increase to
<strong>150–200 GB</strong> if you plan to install large environments,
custom CUDA builds, or multiple frameworks.</p>
</div>
<div class="section level5">
<h5 id="data-disk">Data Disk<a class="anchor" aria-label="anchor" href="#data-disk"></a>
</h5>
<p>This is where your datasets, checkpoints, and outputs live.<br>
Use a <strong>Balanced PD</strong> by default, or an <strong>SSD
PD</strong> only for high-I/O workloads.<br>
A good rule of thumb is to allocate <strong>≈ 2× your dataset
size</strong>, with a <strong>minimum of 150 GB</strong> and a
<strong>maximum of 1 TB</strong>.<br>
For example: - 20 GB dataset → 150 GB data disk (minimum)<br>
- 100 GB dataset → 200 GB data disk<br>
- Larger datasets → keep the full dataset in <strong>Cloud Storage
(<code>gs://</code>)</strong> and copy only subsets locally.</p>
<blockquote>
<p>Persistent Disks can be resized anytime without downtime, so it’s
best to start small and expand when needed.</p>
</blockquote>
</div>
<div class="section level5">
<h5 id="deletion-behavior">Deletion behavior<a class="anchor" aria-label="anchor" href="#deletion-behavior"></a>
</h5>
<p>The ‘Delete to trash’ option is <strong>unchecked by
default</strong>, which is what you want.<br>
When left unchecked, deleted files are removed immediately, freeing up
disk space right away.<br>
If you check this box, files will move to the system trash instead —
meaning they still take up space (and cost) until you empty it.</p>
<blockquote>
<p><strong>Keep this unchecked</strong> to avoid paying for deleted
files that remain in the trash.</p>
</blockquote>
</div>
<div class="section level5">
<h5 id="cost-awareness">Cost awareness<a class="anchor" aria-label="anchor" href="#cost-awareness"></a>
</h5>
<p>Persistent Disks are fast but cost more than Cloud Storage.<br>
Typical rates:<br>
- <strong>Balanced PD:</strong> ~$0.10–$0.12 / GB / month<br>
- <strong>SSD PD:</strong> ~$0.17–$0.20 / GB / month<br>
- <strong>Cloud Storage (Standard):</strong> ~$0.026 / GB / month</p>
<blockquote>
<p><strong>Rule of thumb:</strong> use PDs only for active work; store
everything else in Cloud Storage.<br>
Example: a 200 GB dataset costs <strong>~$24/month on a PD</strong> but
only <strong>~$5/month in Cloud Storage</strong>.</p>
</blockquote>
<p>Check the latest pricing here:<br>
- <a href="https://cloud.google.com/compute/disks-image-pricing" class="external-link">Persistent
Disk &amp; Image pricing</a><br>
- <a href="https://cloud.google.com/storage/pricing" class="external-link">Cloud Storage
pricing</a></p>
</div>
</div>
<div class="section level4">
<h4 id="advanced-settings-networking---remove-external-ip-access">Advanced settings: Networking - Remove External IP Access<a class="anchor" aria-label="anchor" href="#advanced-settings-networking---remove-external-ip-access"></a>
</h4>
<ul>
<li>
<em>Don’t</em> <strong>Assign External IP address</strong>: Uncheck
this option
<ul>
<li>This ensures your instance is only accessible through secure
internal channels rather than the open internet.<br>
</li>
<li>Removing the external IP reduces your attack surface and aligns with
campus cybersecurity guidance.</li>
</ul>
</li>
</ul>
<figure><img src="https://raw.githubusercontent.com/qualiaMachine/Intro_GCP_for_ML/main/images/new-instance-networking.jpg" alt="Remove External IP" class="figure mx-auto d-block"><div class="figcaption">Remove External IP</div>
</figure><blockquote>
<p><strong>Note:</strong> Managed Workbench instances do not allow you
to modify network settings after creation. Be sure to complete this step
or you may need to delete the instance and recreate one from
scratch.</p>
</blockquote>
</div>
</div>
<div class="section level3">
<h3 id="create-notebook">Create notebook<a class="anchor" aria-label="anchor" href="#create-notebook"></a>
</h3>
<ul>
<li>Click <strong>Create</strong> to create the instance. Your notebook
instance will start in a few minutes. When its status is “Running,” you
can open JupyterLab and begin working.</li>
</ul>
</div>
<div class="section level3">
<h3 id="managing-training-and-tuning-with-the-controller-notebook">Managing training and tuning with the controller notebook<a class="anchor" aria-label="anchor" href="#managing-training-and-tuning-with-the-controller-notebook"></a>
</h3>
<p>In the following episodes, we will use the <strong>Vertex AI Python
SDK (<code>google-cloud-aiplatform</code>)</strong> from this notebook
to submit compute-heavy tasks on more powerful machines. Examples
include:</p>
<ul>
<li>Training a model on a GPU-backed instance.<br>
</li>
<li>Running hyperparameter tuning jobs managed by Vertex AI.</li>
</ul>
<p>This pattern keeps costs low by running your notebook on a modest VM
while only incurring charges for larger resources when they are actively
in use.</p>
<div id="challenge-notebook-roles" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="challenge-notebook-roles" class="callout-inner">
<h3 class="callout-title">Challenge: Notebook Roles</h3>
<div class="callout-content">
<p>Your university provides different compute options: laptops, on-prem
HPC, and GCP.</p>
<ul>
<li>What role does a <strong>Workbench Instance notebook</strong> play
compared to an HPC login node or a laptop-based JupyterLab?<br>
</li>
<li>Which tasks should stay in the notebook (lightweight control,
visualization) versus being launched to larger cloud resources?</li>
</ul>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">
<p>The notebook serves as a lightweight control plane.<br>
- Like an HPC login node, it is not meant for heavy computation.<br>
- Suitable for small preprocessing, visualization, and orchestrating
jobs.<br>
- Resource-intensive tasks (training, tuning, batch jobs) should be
submitted to scalable cloud resources (GPU/large VM instances) via the
Vertex AI SDK.</p>
</div>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="load-pre-filled-jupyter-notebooks">Load pre-filled Jupyter notebooks<a class="anchor" aria-label="anchor" href="#load-pre-filled-jupyter-notebooks"></a>
</h3>
<p>Once your newly created <em>instance</em> shows as
<code>Active</code> (green checkmark), click <strong>Open
JupyterLab</strong> to open the instance in Jupyter Lab. From there, we
can create as many Jupyter notebooks as we would like within the
instance environment.</p>
<p>We will then select the standard python3 environment to start our
first .ipynb notebook (Jupyter notebook). We can use this environment
since we aren’t doing any training/tuning just yet.</p>
<p>Within the Jupyter notebook, run the following command to clone the
lesson repo into our Jupyter environment:</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">SH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode sh" tabindex="0"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="ex">!git</span> clone https://github.com/qualiaMachine/Intro_GCP_for_ML.git</span></code></pre>
</div>
<p>Then, navigate to
<code>/Intro_GCP_for_ML/notebooks/04-Accessing-and-managing-data.ipynb</code>
to begin the first notebook.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>Use a small Workbench Instance notebook as a controller to manage
larger, resource-intensive tasks.<br>
</li>
<li>Always navigate to the “Instances” tab in Workbench, since older
notebook types are deprecated.<br>
</li>
<li>Choose the same region for your Workbench Instance and storage
bucket to avoid extra transfer costs.<br>
</li>
<li>Submit training and tuning jobs to scalable instances using the
Vertex AI SDK.<br>
</li>
<li>Labels help track costs effectively, especially in shared or
multi-project environments.<br>
</li>
<li>Workbench Instances come with JupyterLab 3 and GPU frameworks
preinstalled, making them an easy entry point for ML workflows.<br>
</li>
<li>Enable idle auto-stop to avoid unexpected charges when notebooks are
left running.</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</div>
</section></section><section id="aio-04-Accessing-and-managing-data"><p>Content from <a href="04-Accessing-and-managing-data.html">Accessing and Managing Data in GCS with Vertex AI Notebooks</a></p>
<hr>
<p>Last updated on 2025-10-27 |

        <a href="https://github.com/qualiaMachine/Intro_GCP_VertexAI/edit/main/episodes/04-Accessing-and-managing-data.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How can I load data from GCS into a Vertex AI Workbench
notebook?<br>
</li>
<li>How do I monitor storage usage and costs for my GCS bucket?<br>
</li>
<li>What steps are involved in pushing new data back to GCS from a
notebook?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Read data directly from a GCS bucket into memory in a Vertex AI
notebook.<br>
</li>
<li>Check storage usage and estimate costs for data in a GCS
bucket.<br>
</li>
<li>Upload new files from the Vertex AI environment back to the GCS
bucket.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="initial-setup">Initial setup<a class="anchor" aria-label="anchor" href="#initial-setup"></a>
</h2>
<hr class="half-width">
<div class="section level4">
<h4 id="load-pre-filled-jupyter-notebooks">Load pre-filled Jupyter notebooks<a class="anchor" aria-label="anchor" href="#load-pre-filled-jupyter-notebooks"></a>
</h4>
<p>If you haven’t opened your newly created VM from the last episode
yet, lick <strong>Open JupyterLab</strong> to open the instance in
Jupyter Lab. From there, we can create as many Jupyter notebooks as we
would like within the instance environment.</p>
<p>We will then select the standard python3 environment to start our
first .ipynb notebook (Jupyter notebook). We can use this environment
since we aren’t doing any training/tuning just yet.</p>
<p>Within the Jupyter notebook, run the following command to clone the
lesson repo into our Jupyter environment:</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">SH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode sh" tabindex="0"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="ex">!git</span> clone https://github.com/qualiaMachine/Intro_GCP_for_ML.git</span></code></pre>
</div>
<p>Then, navigate to
<code>/Intro_GCP_for_ML/notebooks/04-Accessing-and-managing-data.ipynb</code>
to begin the first notebook.</p>
</div>
<div class="section level4">
<h4 id="set-up-gcp-environment">Set up GCP environment<a class="anchor" aria-label="anchor" href="#set-up-gcp-environment"></a>
</h4>
<p>Before interacting with GCS, we need to authenticate and initialize
the client libraries. This ensures our notebook can talk to GCP
securely.</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="im">from</span> google.cloud <span class="im">import</span> storage</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>client <span class="op">=</span> storage.Client()</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Project:"</span>, client.project)</span></code></pre>
</div>
</div>
</section><section><h2 class="section-heading" id="reading-data-from-google-cloud-storage-gcs">Reading data from Google Cloud Storage (GCS)<a class="anchor" aria-label="anchor" href="#reading-data-from-google-cloud-storage-gcs"></a>
</h2>
<hr class="half-width">
<p>Similar to other cloud vendors, we can either (A) read data directly
from Google Cloud Storage (GCS) into memory, or (B) download a copy into
your notebook VM. Since we’re using notebooks as controllers rather than
training environments, the recommended approach is <em>reading directly
from GCS into memory</em>.</p>
<div class="section level3">
<h3 id="a-reading-data-directly-into-memory">A) Reading data directly into memory<a class="anchor" aria-label="anchor" href="#a-reading-data-directly-into-memory"></a>
</h3>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a><span class="im">import</span> io</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>bucket_name <span class="op">=</span> <span class="st">"sinkorswim-johndoe-titanic"</span> <span class="co"># ADJUST to your bucket's name</span></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a>bucket <span class="op">=</span> client.bucket(bucket_name)</span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a>blob <span class="op">=</span> bucket.blob(<span class="st">"titanic_train.csv"</span>)</span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a>train_data <span class="op">=</span> pd.read_csv(io.BytesIO(blob.download_as_bytes()))</span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a><span class="bu">print</span>(train_data.shape)</span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a>train_data.head()</span></code></pre>
</div>
<p>If you get an error, return to the Google Cloud Console (where we
created our bucket and VM) and search for “Cloud Shell Editor”. Open a
shell editor and run the below commands, *replacing the bucket name with
your bucket’s name`:</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">SH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode sh" tabindex="0"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="co"># Grant read permisssions on the bucket</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a><span class="ex">gcloud</span> storage buckets add-iam-policy-binding gs://sinkorswim-johndoe-titanic <span class="dt">\</span></span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>  <span class="at">--member</span><span class="op">=</span><span class="st">"serviceAccount:549047673858-compute@developer.gserviceaccount.com"</span> <span class="dt">\</span></span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>  <span class="at">--role</span><span class="op">=</span><span class="st">"roles/storage.objectViewer"</span></span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a><span class="co"># Grant write permisssions on the bucket</span></span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a><span class="ex">gcloud</span> storage buckets add-iam-policy-binding gs://sinkorswim-johndoe-titanic <span class="dt">\</span></span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a>  <span class="at">--member</span><span class="op">=</span><span class="st">"serviceAccount:549047673858-compute@developer.gserviceaccount.com"</span> <span class="dt">\</span></span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a>  <span class="at">--role</span><span class="op">=</span><span class="st">"roles/storage.objectCreator"</span></span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a><span class="co"># (Only if you also need overwrite/delete)</span></span>
<span id="cb4-12"><a href="#cb4-12" tabindex="-1"></a><span class="ex">gcloud</span> storage buckets add-iam-policy-binding gs://sinkorswim-johndoe-titanic <span class="dt">\</span></span>
<span id="cb4-13"><a href="#cb4-13" tabindex="-1"></a>  <span class="at">--member</span><span class="op">=</span><span class="st">"serviceAccount:549047673858-compute@developer.gserviceaccount.com"</span> <span class="dt">\</span></span>
<span id="cb4-14"><a href="#cb4-14" tabindex="-1"></a>  <span class="at">--role</span><span class="op">=</span><span class="st">"roles/storage.objectAdmin"</span></span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="b-downloading-a-local-copy">B) Downloading a local copy<a class="anchor" aria-label="anchor" href="#b-downloading-a-local-copy"></a>
</h3>
<p>If you prefer, you can download the file from your bucket to the
notebook VM’s local disk. This makes repeated reads faster within our
notebook environment, but note that <em>each download counts as a “GET”
request</em> and may incur a small data transfer (egress) cost <em>if
the bucket and VM are in different regions</em>. If both are in the same
region, there are no transfer fees — only standard request costs
(typically fractions of a cent).</p>
<p>Let’s verify what our path looks like first.</p>
<pre><code><span><span class="op">!</span><span class="va">pwd</span></span></code></pre>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>blob_name <span class="op">=</span> <span class="st">"titanic_train.csv"</span></span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>local_path <span class="op">=</span> <span class="st">"/home/jupyter/titanic_train.csv"</span></span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a>bucket <span class="op">=</span> client.bucket(bucket_name)</span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a>blob <span class="op">=</span> bucket.blob(blob_name)</span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a>blob.download_to_filename(local_path)</span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a><span class="op">!</span>ls <span class="op">-</span>lh <span class="op">/</span>home<span class="op">/</span>jupyter<span class="op">/</span></span></code></pre>
</div>
</div>
</section><section><h2 class="section-heading" id="checking-storage-usage-of-a-bucket">Checking storage usage of a bucket<a class="anchor" aria-label="anchor" href="#checking-storage-usage-of-a-bucket"></a>
</h2>
<hr class="half-width">
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a>total_size_bytes <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>bucket <span class="op">=</span> client.bucket(bucket_name)</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a><span class="cf">for</span> blob <span class="kw">in</span> client.list_blobs(bucket_name):</span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a>    total_size_bytes <span class="op">+=</span> blob.size</span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a>total_size_mb <span class="op">=</span> total_size_bytes <span class="op">/</span> (<span class="dv">1024</span><span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Total size of bucket '</span><span class="sc">{</span>bucket_name<span class="sc">}</span><span class="ss">': </span><span class="sc">{</span>total_size_mb<span class="sc">:.2f}</span><span class="ss"> MB"</span>)</span></code></pre>
</div>
</section><section><h2 class="section-heading" id="estimating-storage-costs">Estimating storage costs<a class="anchor" aria-label="anchor" href="#estimating-storage-costs"></a>
</h2>
<hr class="half-width">
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a>storage_price_per_gb <span class="op">=</span> <span class="fl">0.02</span>  <span class="co"># $/GB/month for Standard storage</span></span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>total_size_gb <span class="op">=</span> total_size_bytes <span class="op">/</span> (<span class="dv">1024</span><span class="op">**</span><span class="dv">3</span>)</span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>monthly_cost <span class="op">=</span> total_size_gb <span class="op">*</span> storage_price_per_gb</span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Estimated monthly cost: $</span><span class="sc">{</span>monthly_cost<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Estimated annual cost: $</span><span class="sc">{</span>monthly_cost<span class="op">*</span><span class="dv">12</span><span class="sc">:.4f}</span><span class="ss">"</span>)</span></code></pre>
</div>
<p>For updated prices, see <a href="https://cloud.google.com/storage/pricing" class="external-link">GCS Pricing</a>.</p>
</section><section><h2 class="section-heading" id="writing-output-files-to-gcs">Writing output files to GCS<a class="anchor" aria-label="anchor" href="#writing-output-files-to-gcs"></a>
</h2>
<hr class="half-width">
<p>Create a sample file on the notebook VM’s storage.</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="co"># Create a sample file locally on the notebook VM</span></span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>file_path <span class="op">=</span> <span class="st">"/home/jupyter/Notes.txt"</span></span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(file_path, <span class="st">"w"</span>) <span class="im">as</span> f:</span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a>    f.write(<span class="st">"This is a test note for GCS."</span>)</span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a><span class="op">!</span>ls <span class="op">/</span>home<span class="op">/</span>jupyter</span></code></pre>
</div>
<p>Upload file.</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="co"># Point to the right bucket</span></span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a>bucket <span class="op">=</span> client.bucket(bucket_name)</span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a><span class="co"># Create a *Blob* object, which represents a path inside the bucket</span></span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a><span class="co"># (here it will end up as gs://&lt;bucket_name&gt;/docs/Notes.txt)</span></span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a>blob <span class="op">=</span> bucket.blob(<span class="st">"docs/Notes.txt"</span>)</span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a><span class="co"># Upload the local file into that blob (object) in GCS</span></span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a>blob.upload_from_filename(file_path)</span>
<span id="cb10-10"><a href="#cb10-10" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"File uploaded successfully."</span>)</span></code></pre>
</div>
<p>List bucket contents:</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="cf">for</span> blob <span class="kw">in</span> client.list_blobs(bucket_name):</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a>    <span class="bu">print</span>(blob.name)</span></code></pre>
</div>
<div id="challenge-estimating-gcs-costs" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="challenge-estimating-gcs-costs" class="callout-inner">
<h3 class="callout-title">Challenge: Estimating GCS Costs</h3>
<div class="callout-content">
<p>Suppose you store <strong>50 GB</strong> of data in Standard storage
(us-central1) for one month.<br>
- Estimate the monthly storage cost.<br>
- Then estimate the cost if you download (egress) the entire dataset
once at the end of the month.</p>
<p><strong>Hints</strong><br>
- Storage: $0.02 per GB-month<br>
- Egress: $0.12 per GB</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<ul>
<li>Storage cost: 50 GB × $0.02 = $1.00<br>
</li>
<li>Egress cost: 50 GB × $0.12 = $6.00<br>
</li>
<li><strong>Total cost: $7.00 for one month including one full
download</strong></li>
</ul>
</div>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>Load data from GCS into memory to avoid managing local copies when
possible.<br>
</li>
<li>Periodically check storage usage and costs to manage your GCS
budget.<br>
</li>
<li>Use Vertex AI Workbench notebooks to upload analysis results back to
GCS, keeping workflows organized and reproducible.</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</section></section><section id="aio-05-Interacting-with-code-repo"><p>Content from <a href="05-Interacting-with-code-repo.html">Using a GitHub Personal Access Token (PAT) to Push/Pull from a Vertex AI Notebook</a></p>
<hr>
<p>Last updated on 2025-10-24 |

        <a href="https://github.com/qualiaMachine/Intro_GCP_VertexAI/edit/main/episodes/05-Interacting-with-code-repo.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How can I securely push/pull code to and from GitHub within a Vertex
AI Workbench notebook?<br>
</li>
<li>What steps are necessary to set up a GitHub PAT for authentication
in GCP?<br>
</li>
<li>How can I convert notebooks to <code>.py</code> files and ignore
<code>.ipynb</code> files in version control?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Configure Git in a Vertex AI Workbench notebook to use a GitHub
Personal Access Token (PAT) for HTTPS-based authentication.<br>
</li>
<li>Securely handle credentials in a notebook environment using
<code>getpass</code>.<br>
</li>
<li>Convert <code>.ipynb</code> files to <code>.py</code> files for
better version control practices in collaborative projects.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="step-0-initial-setup">Step 0: Initial setup<a class="anchor" aria-label="anchor" href="#step-0-initial-setup"></a>
</h2>
<hr class="half-width">
<p>In the previous episode, we cloned our forked repository as part of
the <a href="index.html#setup">workshop setup</a>. In this episode, we’ll see
how to push our code to this fork. Complete these three setup steps
before moving forward.</p>
<ol style="list-style-type: decimal">
<li><p>Clone the fork if you haven’t already. See previous
episode.</p></li>
<li><p>Start a new Jupyter notebook, and name it something like
<code>Interacting-with-git.ipynb</code>. We can use the default Python 3
kernel in Vertex AI Workbench.</p></li>
<li><p>Change directory to the workspace where your repository is
located. In Vertex AI Workbench, notebooks usually live under
<code>/home/jupyter/</code>.</p></li>
</ol>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="op">%</span>cd <span class="op">/</span>home<span class="op">/</span>jupyter<span class="op">/</span></span></code></pre>
</div>
</section><section><h2 class="section-heading" id="step-1-using-a-github-personal-access-token-pat-to-pushpull-from-a-vertex-ai-notebook">Step 1: Using a GitHub personal access token (PAT) to push/pull from
a Vertex AI notebook<a class="anchor" aria-label="anchor" href="#step-1-using-a-github-personal-access-token-pat-to-pushpull-from-a-vertex-ai-notebook"></a>
</h2>
<hr class="half-width">
<p>When working in Vertex AI Workbench notebooks, you may often need to
push code updates to GitHub repositories. Since Workbench VMs may be
stopped and restarted, configurations like SSH keys may not persist.
HTTPS-based authentication with a GitHub Personal Access Token (PAT) is
a practical solution. PATs provide flexibility for authentication and
enable seamless interaction with both public and private repositories
directly from your notebook.</p>
<blockquote>
<p><strong>Important Note</strong>: Personal access tokens are powerful
credentials. Select the minimum necessary permissions and handle the
token carefully.</p>
</blockquote>
<div class="section level4">
<h4 id="generate-a-personal-access-token-pat-on-github">Generate a personal access token (PAT) on GitHub<a class="anchor" aria-label="anchor" href="#generate-a-personal-access-token-pat-on-github"></a>
</h4>
<ol style="list-style-type: decimal">
<li>Go to <strong>Settings</strong> in GitHub.<br>
</li>
<li>Click <strong>Developer settings</strong> at the bottom of the left
sidebar.<br>
</li>
<li>Select <strong>Personal access tokens</strong>, then click
<strong>Tokens (classic)</strong>.<br>
</li>
<li>Click <strong>Generate new token (classic)</strong>.<br>
</li>
<li>Give your token a descriptive name and set an expiration date if
desired.<br>
</li>
<li>
<strong>Select minimum permissions</strong>:
<ul>
<li>Public repos: <code>public_repo</code><br>
</li>
<li>Private repos: <code>repo</code><br>
</li>
</ul>
</li>
<li>Click <strong>Generate token</strong> and copy it immediately—you
won’t be able to see it again.</li>
</ol>
<blockquote>
<p><strong>Caution</strong>: Treat your PAT like a password. Don’t share
it or expose it in your code. Use a password manager to store it.</p>
</blockquote>
</div>
<div class="section level4">
<h4 id="use-getpass-to-prompt-for-username-and-pat">Use <code>getpass</code> to prompt for username and PAT<a class="anchor" aria-label="anchor" href="#use-getpass-to-prompt-for-username-and-pat"></a>
</h4>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="im">import</span> getpass</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a><span class="co"># Prompt for GitHub username and PAT securely</span></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>username <span class="op">=</span> <span class="bu">input</span>(<span class="st">"GitHub Username: "</span>)</span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>token <span class="op">=</span> getpass.getpass(<span class="st">"GitHub Personal Access Token (PAT): "</span>)</span></code></pre>
</div>
<p>This way credentials aren’t hard-coded into your notebook.</p>
</div>
</section><section><h2 class="section-heading" id="step-2-configure-git-settings">Step 2: Configure Git settings<a class="anchor" aria-label="anchor" href="#step-2-configure-git-settings"></a>
</h2>
<hr class="half-width">
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="op">!</span>git config <span class="op">--</span><span class="kw">global</span> user.name <span class="st">"Your Name"</span> </span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a><span class="op">!</span>git config <span class="op">--</span><span class="kw">global</span> user.email your_email<span class="op">@</span>wisc.edu</span></code></pre>
</div>
<ul>
<li>
<code>user.name</code>: Will appear in the commit history.<br>
</li>
<li>
<code>user.email</code>: Must match your GitHub account so commits
are linked to your profile.</li>
</ul></section><section><h2 class="section-heading" id="step-3-convert--ipynb-notebooks-to--py">Step 3: Convert <code>.ipynb</code> notebooks to
<code>.py</code>
<a class="anchor" aria-label="anchor" href="#step-3-convert--ipynb-notebooks-to--py"></a>
</h2>
<hr class="half-width">
<p>Tracking <code>.py</code> files instead of <code>.ipynb</code> helps
with cleaner version control. Notebooks store outputs and metadata,
which makes diffs noisy. <code>.py</code> files are lighter and easier
to review.</p>
<ol style="list-style-type: decimal">
<li>Install Jupytext.<br>
</li>
</ol>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="op">!</span>pip install jupytext</span></code></pre>
</div>
<ol start="2" style="list-style-type: decimal">
<li>Convert a notebook to <code>.py</code>.<br>
</li>
</ol>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="op">!</span>jupytext <span class="op">--</span>to py Interacting<span class="op">-</span><span class="cf">with</span><span class="op">-</span>GCS.ipynb</span></code></pre>
</div>
<ol start="3" style="list-style-type: decimal">
<li>Convert all notebooks in the current directory.<br>
</li>
</ol>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="im">import</span> subprocess, os</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a><span class="cf">for</span> nb <span class="kw">in</span> [f <span class="cf">for</span> f <span class="kw">in</span> os.listdir() <span class="cf">if</span> f.endswith(<span class="st">'.ipynb'</span>)]:</span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a>    pyfile <span class="op">=</span> nb.replace(<span class="st">'.ipynb'</span>, <span class="st">'.py'</span>)</span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a>    subprocess.run([<span class="st">"jupytext"</span>, <span class="st">"--to"</span>, <span class="st">"py"</span>, nb, <span class="st">"--output"</span>, pyfile])</span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Converted </span><span class="sc">{</span>nb<span class="sc">}</span><span class="ss"> to </span><span class="sc">{</span>pyfile<span class="sc">}</span><span class="ss">"</span>)</span></code></pre>
</div>
</section><section><h2 class="section-heading" id="step-4-add-and-commit--py-files">Step 4: Add and commit <code>.py</code> files<a class="anchor" aria-label="anchor" href="#step-4-add-and-commit--py-files"></a>
</h2>
<hr class="half-width">
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="op">%</span>cd <span class="op">/</span>home<span class="op">/</span>jupyter<span class="op">/</span>your<span class="op">-</span>repo</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a><span class="op">!</span>git status</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a><span class="op">!</span>git add .</span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a><span class="op">!</span>git commit <span class="op">-</span>m <span class="st">"Converted notebooks to .py files for version control"</span></span></code></pre>
</div>
</section><section><h2 class="section-heading" id="step-5-add--ipynb-to--gitignore">Step 5: Add <code>.ipynb</code> to <code>.gitignore</code>
<a class="anchor" aria-label="anchor" href="#step-5-add--ipynb-to--gitignore"></a>
</h2>
<hr class="half-width">
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="op">!</span>touch .gitignore</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">".gitignore"</span>, <span class="st">"a"</span>) <span class="im">as</span> gitignore:</span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>    gitignore.write(<span class="st">"</span><span class="ch">\n</span><span class="st"># Ignore Jupyter notebooks</span><span class="ch">\n</span><span class="st">*.ipynb</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a><span class="op">!</span>cat .gitignore</span></code></pre>
</div>
<p>Add other temporary files too:</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">".gitignore"</span>, <span class="st">"a"</span>) <span class="im">as</span> gitignore:</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>    gitignore.write(<span class="st">"</span><span class="ch">\n</span><span class="st"># Ignore cache and temp files</span><span class="ch">\n</span><span class="st">__pycache__/</span><span class="ch">\n</span><span class="st">*.tmp</span><span class="ch">\n</span><span class="st">*.log</span><span class="ch">\n</span><span class="st">"</span>)</span></code></pre>
</div>
<p>Commit the <code>.gitignore</code>:</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="op">!</span>git add .gitignore</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a><span class="op">!</span>git commit <span class="op">-</span>m <span class="st">"Add .ipynb and temp files to .gitignore"</span></span></code></pre>
</div>
</section><section><h2 class="section-heading" id="step-6-syncing-with-github">Step 6: Syncing with GitHub<a class="anchor" aria-label="anchor" href="#step-6-syncing-with-github"></a>
</h2>
<hr class="half-width">
<p>First, pull the latest changes:</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="op">!</span>git config pull.rebase false</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a><span class="op">!</span>git pull origin main</span></code></pre>
</div>
<p>If conflicts occur, resolve manually before committing.</p>
<p>Then push with your PAT credentials:</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a>github_url <span class="op">=</span> <span class="ss">f'github.com/</span><span class="sc">{</span>username<span class="sc">}</span><span class="ss">/your-repo.git'</span></span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a><span class="op">!</span>git push https:<span class="op">//</span>{username}:{token}<span class="op">@</span>{github_url} main</span></code></pre>
</div>
</section><section><h2 class="section-heading" id="step-7-convert--py-back-to-notebooks-optional">Step 7: Convert <code>.py</code> back to notebooks (optional)<a class="anchor" aria-label="anchor" href="#step-7-convert--py-back-to-notebooks-optional"></a>
</h2>
<hr class="half-width">
<p>To convert <code>.py</code> files back to <code>.ipynb</code> after
pulling updates:</p>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="op">!</span>jupytext <span class="op">--</span>to notebook Interacting<span class="op">-</span><span class="cf">with</span><span class="op">-</span>GCS.py <span class="op">--</span>output Interacting<span class="op">-</span><span class="cf">with</span><span class="op">-</span>GCS.ipynb</span></code></pre>
</div>
<div id="challenge-github-pat-workflow" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="challenge-github-pat-workflow" class="callout-inner">
<h3 class="callout-title">Challenge: GitHub PAT Workflow</h3>
<div class="callout-content">
<ul>
<li>Why might you prefer using a PAT with HTTPS instead of SSH keys in
Vertex AI Workbench?<br>
</li>
<li>What are the benefits of converting <code>.ipynb</code> files to
<code>.py</code> before committing to a shared repo?</li>
</ul>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<ul>
<li>PATs with HTTPS are easier to set up in temporary environments where
SSH configs don’t persist.<br>
</li>
<li>Converting notebooks to <code>.py</code> results in cleaner diffs,
easier code review, and smaller repos without stored
outputs/metadata.</li>
</ul>
</div>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>Use a GitHub PAT for HTTPS-based authentication in Vertex AI
Workbench notebooks.<br>
</li>
<li>Securely enter sensitive information in notebooks using
<code>getpass</code>.<br>
</li>
<li>Converting <code>.ipynb</code> files to <code>.py</code> files helps
with cleaner version control.<br>
</li>
<li>Adding <code>.ipynb</code> files to <code>.gitignore</code> keeps
your repository organized.</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</section></section><section id="aio-06-Training-models-in-VertexAI"><p>Content from <a href="06-Training-models-in-VertexAI.html">Training Models in Vertex AI: Intro</a></p>
<hr>
<p>Last updated on 2025-10-27 |

        <a href="https://github.com/qualiaMachine/Intro_GCP_VertexAI/edit/main/episodes/06-Training-models-in-VertexAI.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What are the differences between training locally in a Vertex AI
notebook and using Vertex AI-managed training jobs?<br>
</li>
<li>How do custom training jobs in Vertex AI streamline the training
process for various frameworks?<br>
</li>
<li>How does Vertex AI handle scaling across CPUs, GPUs, and TPUs?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Understand the difference between local training in a Vertex AI
Workbench notebook and submitting managed training jobs.<br>
</li>
<li>Learn to configure and use Vertex AI custom training jobs for
different frameworks (e.g., XGBoost, PyTorch, SKLearn).<br>
</li>
<li>Understand scaling options in Vertex AI, including when to use CPUs,
GPUs, or TPUs.<br>
</li>
<li>Compare performance, cost, and setup between custom scripts and
pre-built containers in Vertex AI.<br>
</li>
<li>Conduct training with data stored in GCS and monitor training job
status using the Google Cloud Console.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="initial-setup">Initial setup<a class="anchor" aria-label="anchor" href="#initial-setup"></a>
</h2>
<hr class="half-width">
<div class="section level4">
<h4 id="open-a-new--ipynb-notebook">1. Open a new .ipynb notebook<a class="anchor" aria-label="anchor" href="#open-a-new--ipynb-notebook"></a>
</h4>
<p>Navigate to
<code>/Intro_GCP_for_ML/notebooks/06-Training-models-in-VertexAI.ipynb</code>
to begin this notebook.</p>
</div>
<div class="section level4">
<h4 id="cd-to-instance-home-directory">2. CD to instance home directory<a class="anchor" aria-label="anchor" href="#cd-to-instance-home-directory"></a>
</h4>
<p>So we all can reference helper functions consistently, change
directory to your Jupyter home directory.</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="op">%</span>cd <span class="op">/</span>home<span class="op">/</span>jupyter<span class="op">/</span></span></code></pre>
</div>
</div>
<div class="section level4">
<h4 id="initialize-vertex-ai-environment">3. Initialize Vertex AI environment<a class="anchor" aria-label="anchor" href="#initialize-vertex-ai-environment"></a>
</h4>
<p>This code initializes the Vertex AI environment by importing the
Python SDK, setting the project, region, and defining a GCS bucket for
input/output data.</p>
<ul>
<li>
<code>PROJECT_ID</code>: Identifies your GCP project.<br>
</li>
<li>
<code>REGION</code>: Determines where training jobs run (choose a
region close to your data).<br>
</li>
<li>
<code>staging_bucket</code>: A GCS bucket for storing datasets,
model artifacts, and job outputs.<br>
</li>
</ul>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="im">from</span> google.cloud <span class="im">import</span> storage</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>client <span class="op">=</span> storage.Client()</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>PROJECT_ID <span class="op">=</span> client.project</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>REGION <span class="op">=</span> <span class="st">"us-central1"</span></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>BUCKET_NAME <span class="op">=</span> <span class="st">"sinkorswim-johndoe-titanic"</span> <span class="co"># ADJUST to your bucket's name</span></span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Project:"</span>, PROJECT_ID)</span></code></pre>
</div>
<ul>
<li>
<code>aiplatform.init()</code>: Sets defaults for project, region,
and staging bucket.</li>
</ul>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="im">from</span> google.cloud <span class="im">import</span> aiplatform</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a><span class="co"># Initialize Vertex AI client</span></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>aiplatform.init(project<span class="op">=</span>PROJECT_ID, location<span class="op">=</span>REGION, staging_bucket<span class="op">=</span><span class="ss">f"gs://</span><span class="sc">{</span>BUCKET_NAME<span class="sc">}</span><span class="ss">"</span>)</span></code></pre>
</div>
</div>
<div class="section level4">
<h4 id="get-code-from-github-repo-skip-if-already-completed">4. Get code from GitHub repo (skip if already completed)<a class="anchor" aria-label="anchor" href="#get-code-from-github-repo-skip-if-already-completed"></a>
</h4>
<p>If you didn’t complete earlier episodes, clone our code repo before
moving forward. Check to make sure we’re in our Jupyter home folder
first.</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="co">#%cd /home/jupyter/</span></span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="co">#!git clone https://github.com/qualiaMachine/Intro_GCP_for_ML.git</span></span></code></pre>
</div>
</div>
</section><section><h2 class="section-heading" id="testing-train-py-locally-in-the-notebook">Testing train.py locally in the notebook<a class="anchor" aria-label="anchor" href="#testing-train-py-locally-in-the-notebook"></a>
</h2>
<hr class="half-width">
<div id="understanding-the-xgboost-training-script-gcp-version" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<span class="callout-header">Discussion</span>
<div id="understanding-the-xgboost-training-script-gcp-version" class="callout-inner">
<h3 class="callout-title">Understanding the XGBoost Training Script (GCP
version)</h3>
<div class="callout-content">
<p>Take a moment to review the <code>train_xgboost.py</code> script
we’re using on GCP found in
<code>Intro_GCP-for_ML/scripts/train_xgboost.py</code>. This script
handles preprocessing, training, and saving an XGBoost model, while
supporting <strong>local paths</strong> and <strong>GCS
(<code>gs://</code>) paths</strong>, and it adapts to <strong>Vertex
AI</strong> conventions (e.g., <code>AIP_MODEL_DIR</code>).</p>
<p>Try answering the following questions:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Data preprocessing</strong>: What transformations are
applied to the dataset before training?</p></li>
<li><p><strong>Training function</strong>: What does the
<code>train_model()</code> function do? Why print the training
time?</p></li>
<li><p><strong>Command-line arguments</strong>: What is the purpose of
<code>argparse</code> in this script? How would you change the number of
training rounds?</p></li>
<li><p><strong>Handling local vs. GCP runs</strong>: How does the script
let you run the same code locally, in Workbench, or as a Vertex AI job?
Which environment variable controls where the model artifact is
written?</p></li>
<li><p><strong>Training and saving the model</strong>: What format is
the dataset converted to before training, and why? How does the script
save to a local path vs. a <code>gs://</code> destination?</p></li>
</ol>
<p>After reviewing, discuss any questions or observations with your
group.</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">
<ol style="list-style-type: decimal">
<li><p><strong>Data preprocessing</strong>: The script fills missing
values (<code>Age</code> with median, <code>Embarked</code> with mode),
maps categorical fields to numeric (<code>Sex</code> → {male:1,
female:0}, <code>Embarked</code> → {S:0, C:1, Q:2}), and drops
non-predictive columns (<code>Name</code>, <code>Ticket</code>,
<code>Cabin</code>).</p></li>
<li><p><strong>Training function</strong>: <code>train_model()</code>
constructs and fits an XGBoost model with the provided parameters and
prints wall-clock training time. Timing helps compare runs and make
sensible scaling choices.</p></li>
<li>
<p><strong>Command-line arguments</strong>: <code>argparse</code>
lets you set hyperparameters and file paths without editing code (e.g.,
<code>--max_depth</code>, <code>--eta</code>, <code>--num_round</code>,
<code>--train</code>). To change rounds:</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="ex">python</span> train_xgboost.py <span class="at">--num_round</span> 200</span></code></pre>
</div>
</li>
<li>
<p><strong>Handling local vs. GCP runs</strong>:</p>
<ul>
<li>
<strong>Input</strong>: You pass <code>--train</code> as either a
local path (<code>train.csv</code>) or a GCS URI
(<code>gs://bucket/path.csv</code>). The script automatically detects
<code>gs://</code> and reads the file directly from Cloud Storage using
the Python client.<br>
</li>
<li>
<strong>Output</strong>: If the environment variable
<code>AIP_MODEL_DIR</code> is set (as it is in Vertex AI CustomJobs),
the trained model is written there—often a <code>gs://</code> path.
Otherwise, the model is saved in the current working directory, which
works seamlessly in both local and Workbench environments.</li>
</ul>
</li>
<li><p><strong>Training and saving the model</strong>:<br>
The training data is converted into an <strong>XGBoost
<code>DMatrix</code></strong>, an optimized format that speeds up
training and reduces memory use. The trained model is serialized with
<code>joblib</code>. When saving locally, the file is written directly
to disk. If saving to a Cloud Storage path (<code>gs://...</code>), the
model is first saved to a temporary file and then uploaded to the
specified bucket.</p></li>
</ol>
</div>
</div>
</div>
</div>
<p>Before scaling training jobs onto managed resources, it’s essential
to test your training script locally. This prevents wasting GPU/TPU time
on bugs or misconfigured code.</p>
<div class="section level3">
<h3 id="guidelines-for-testing-ml-pipelines-before-scaling">Guidelines for testing ML pipelines before scaling<a class="anchor" aria-label="anchor" href="#guidelines-for-testing-ml-pipelines-before-scaling"></a>
</h3>
<ul>
<li>
<strong>Run tests locally first</strong> with small datasets.<br>
</li>
<li>
<strong>Use a subset of your dataset</strong> (1–5%) for fast
checks.<br>
</li>
<li>
<strong>Start with minimal compute</strong> before moving to larger
accelerators.<br>
</li>
<li>
<strong>Log key metrics</strong> such as loss curves and
runtimes.<br>
</li>
<li>
<strong>Verify correctness first</strong> before scaling up.</li>
</ul>
<div id="what-tests-should-we-do-before-scaling" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<span class="callout-header">Discussion</span>
<div id="what-tests-should-we-do-before-scaling" class="callout-inner">
<h3 class="callout-title">What tests should we do before scaling?</h3>
<div class="callout-content">
<p>Before scaling to multiple or more powerful instances (e.g., GPUs or
TPUs), it’s important to run a few sanity checks. <strong>In your group,
discuss:</strong></p>
<ul>
<li>Which checks do you think are most critical before scaling up?<br>
</li>
<li>What potential issues might we miss if we skip this step?</li>
</ul>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2"> Show me the solution </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" data-bs-parent="#accordionSolution2" aria-labelledby="headingSolution2">
<div class="accordion-body">
<ul>
<li>
<strong>Data loads correctly</strong> – dataset loads without
errors, expected columns exist, missing values handled.<br>
</li>
<li>
<strong>Overfitting check</strong> – train on a tiny dataset (e.g.,
100 rows). If it doesn’t overfit, something is off.<br>
</li>
<li>
<strong>Loss behavior</strong> – verify training loss decreases and
doesn’t diverge.<br>
</li>
<li>
<strong>Runtime estimate</strong> – get a rough sense of training
time on small data.<br>
</li>
<li>
<strong>Memory estimate</strong> – check approximate memory
use.<br>
</li>
<li>
<strong>Save &amp; reload</strong> – ensure model saves, reloads,
and infers without errors.</li>
</ul>
<p>Skipping these can lead to: silent data bugs, runtime blowups at
scale, inefficient experiments, or broken model artifacts.</p>
</div>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="download-data-into-notebook-environment">Download data into notebook environment<a class="anchor" aria-label="anchor" href="#download-data-into-notebook-environment"></a>
</h2>
<hr class="half-width">
<p>Sometimes it’s helpful to keep a copy of data in your notebook VM for
quick iteration, even though <strong>GCS is the preferred storage
location</strong>.</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="im">from</span> google.cloud <span class="im">import</span> storage</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>client <span class="op">=</span> storage.Client()</span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>bucket <span class="op">=</span> client.bucket(BUCKET_NAME)</span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a>blob <span class="op">=</span> bucket.blob(<span class="st">"titanic_train.csv"</span>)</span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a>blob.download_to_filename(<span class="st">"titanic_train.csv"</span>)</span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Downloaded titanic_train.csv"</span>)</span></code></pre>
</div>
</section><section><h2 class="section-heading" id="local-test-run-of-train-py">Local test run of train.py<a class="anchor" aria-label="anchor" href="#local-test-run-of-train-py"></a>
</h2>
<hr class="half-width">
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="im">import</span> time <span class="im">as</span> t</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>start <span class="op">=</span> t.time()</span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a><span class="co"># Example: run your custom training script with args</span></span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a><span class="op">!</span>python Intro_GCP_for_ML<span class="op">/</span>scripts<span class="op">/</span>train_xgboost.py <span class="op">--</span>max_depth <span class="dv">3</span> <span class="op">--</span>eta <span class="fl">0.1</span> <span class="op">--</span>subsample <span class="fl">0.8</span> <span class="op">--</span>colsample_bytree <span class="fl">0.8</span> <span class="op">--</span>num_round <span class="dv">100</span> <span class="op">--</span>train titanic_train.csv</span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Total local runtime: </span><span class="sc">{</span>t<span class="sc">.</span>time() <span class="op">-</span> start<span class="sc">:.2f}</span><span class="ss"> seconds"</span>)</span></code></pre>
</div>
<p>Training on this small dataset should take &lt;1 minute. Log runtime
as a baseline. You should see the following output files:</p>
<ul>
<li>xgboost-model.joblib # Python-serialized XGBoost model (Booster) via
joblib; load with joblib.load for reuse.</li>
<li>eval_history.csv # Per-iteration validation metrics; columns:
iter,val_logloss (good for plotting learning curves).</li>
<li>training.log # Full stdout/stderr from the run (params, dataset
sizes, timings, warnings/errors) for audit/debug.</li>
<li>metrics.json # Structured summary: final_val_logloss,
num_boost_round, params, train_rows/val_rows, features[],
model_uri.</li>
</ul></section><section><h2 class="section-heading" id="training-via-vertex-ai-custom-training-job">Training via Vertex AI custom training job<a class="anchor" aria-label="anchor" href="#training-via-vertex-ai-custom-training-job"></a>
</h2>
<hr class="half-width">
<p>Unlike “local” training, this launches a <strong>managed training
job</strong> that runs on scalable compute. Vertex AI handles
provisioning, scaling, logging, and saving outputs to GCS.</p>
<div class="section level3">
<h3 id="which-machine-type-to-start-with">Which machine type to start with?<a class="anchor" aria-label="anchor" href="#which-machine-type-to-start-with"></a>
</h3>
<p>Start with a small CPU machine like <code>n1-standard-4</code>. Only
scale up to GPUs/TPUs once you’ve verified your script. See <a href="instances-for-ML.html">Instances for ML on GCP</a> for
guidance.</p>
</div>
<div class="section level3">
<h3 id="creating-a-custom-training-job-with-the-sdk">Creating a custom training job with the SDK<a class="anchor" aria-label="anchor" href="#creating-a-custom-training-job-with-the-sdk"></a>
</h3>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="im">from</span> google.cloud <span class="im">import</span> aiplatform</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a><span class="im">import</span> datetime <span class="im">as</span> dt</span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a>PROJECT <span class="op">=</span> <span class="st">"doit-rci-mlm25-4626"</span></span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a>REGION <span class="op">=</span> <span class="st">"us-central1"</span></span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a>BUCKET <span class="op">=</span> BUCKET_NAME  <span class="co"># e.g., "endemann_titanic" (same region as REGION)</span></span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a></span>
<span id="cb9-8"><a href="#cb9-8" tabindex="-1"></a>RUN_ID <span class="op">=</span> dt.datetime.now().strftime(<span class="st">"%Y%m</span><span class="sc">%d</span><span class="st">-%H%M%S"</span>)</span>
<span id="cb9-9"><a href="#cb9-9" tabindex="-1"></a>MODEL_URI <span class="op">=</span> <span class="ss">f"gs://</span><span class="sc">{</span>BUCKET<span class="sc">}</span><span class="ss">/artifacts/xgb/</span><span class="sc">{</span>RUN_ID<span class="sc">}</span><span class="ss">/model.joblib"</span>  <span class="co"># everything will live beside this</span></span>
<span id="cb9-10"><a href="#cb9-10" tabindex="-1"></a></span>
<span id="cb9-11"><a href="#cb9-11" tabindex="-1"></a><span class="co"># Staging bucket is only for the SDK's temp code tarball (aiplatform-*.tar.gz)</span></span>
<span id="cb9-12"><a href="#cb9-12" tabindex="-1"></a>aiplatform.init(project<span class="op">=</span>PROJECT, location<span class="op">=</span>REGION, staging_bucket<span class="op">=</span><span class="ss">f"gs://</span><span class="sc">{</span>BUCKET<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-13"><a href="#cb9-13" tabindex="-1"></a></span>
<span id="cb9-14"><a href="#cb9-14" tabindex="-1"></a>job <span class="op">=</span> aiplatform.CustomTrainingJob(</span>
<span id="cb9-15"><a href="#cb9-15" tabindex="-1"></a>    display_name<span class="op">=</span><span class="ss">f"endemann_xgb_</span><span class="sc">{</span>RUN_ID<span class="sc">}</span><span class="ss">"</span>,</span>
<span id="cb9-16"><a href="#cb9-16" tabindex="-1"></a>    script_path<span class="op">=</span><span class="st">"Intro_GCP_VertexAI/code/train_xgboost.py"</span>,</span>
<span id="cb9-17"><a href="#cb9-17" tabindex="-1"></a>    container_uri<span class="op">=</span><span class="st">"us-docker.pkg.dev/vertex-ai/training/xgboost-cpu.2-1:latest"</span>,</span>
<span id="cb9-18"><a href="#cb9-18" tabindex="-1"></a>    requirements<span class="op">=</span>[<span class="st">"gcsfs"</span>],  <span class="co"># script writes gs://MODEL_URI and sidecar files</span></span>
<span id="cb9-19"><a href="#cb9-19" tabindex="-1"></a>)</span>
<span id="cb9-20"><a href="#cb9-20" tabindex="-1"></a></span>
<span id="cb9-21"><a href="#cb9-21" tabindex="-1"></a>job.run(</span>
<span id="cb9-22"><a href="#cb9-22" tabindex="-1"></a>    args<span class="op">=</span>[</span>
<span id="cb9-23"><a href="#cb9-23" tabindex="-1"></a>        <span class="ss">f"--train=gs://</span><span class="sc">{</span>BUCKET<span class="sc">}</span><span class="ss">/titanic_train.csv"</span>,</span>
<span id="cb9-24"><a href="#cb9-24" tabindex="-1"></a>        <span class="ss">f"--model_out=</span><span class="sc">{</span>MODEL_URI<span class="sc">}</span><span class="ss">"</span>,      <span class="co"># model, metrics.json, eval_history.csv, training.log all go here</span></span>
<span id="cb9-25"><a href="#cb9-25" tabindex="-1"></a>        <span class="st">"--max_depth=3"</span>,</span>
<span id="cb9-26"><a href="#cb9-26" tabindex="-1"></a>        <span class="st">"--eta=0.1"</span>,</span>
<span id="cb9-27"><a href="#cb9-27" tabindex="-1"></a>        <span class="st">"--subsample=0.8"</span>,</span>
<span id="cb9-28"><a href="#cb9-28" tabindex="-1"></a>        <span class="st">"--colsample_bytree=0.8"</span>,</span>
<span id="cb9-29"><a href="#cb9-29" tabindex="-1"></a>        <span class="st">"--num_round=100"</span>,</span>
<span id="cb9-30"><a href="#cb9-30" tabindex="-1"></a>    ],</span>
<span id="cb9-31"><a href="#cb9-31" tabindex="-1"></a>    replica_count<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb9-32"><a href="#cb9-32" tabindex="-1"></a>    machine_type<span class="op">=</span><span class="st">"n1-standard-4"</span>,</span>
<span id="cb9-33"><a href="#cb9-33" tabindex="-1"></a>    sync<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb9-34"><a href="#cb9-34" tabindex="-1"></a>)</span>
<span id="cb9-35"><a href="#cb9-35" tabindex="-1"></a></span>
<span id="cb9-36"><a href="#cb9-36" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Model + logs folder:"</span>, MODEL_URI.rsplit(<span class="st">"/"</span>, <span class="dv">1</span>)[<span class="dv">0</span>])</span></code></pre>
</div>
<p>This launches a managed training job with Vertex AI.</p>
</div>
</section><section><h2 class="section-heading" id="monitoring-training-jobs-in-the-console">Monitoring training jobs in the Console<a class="anchor" aria-label="anchor" href="#monitoring-training-jobs-in-the-console"></a>
</h2>
<hr class="half-width">
<ol style="list-style-type: decimal">
<li>Go to the Google Cloud Console.<br>
</li>
<li>Navigate to <strong>Vertex AI &gt; Training &gt; Custom
Jobs</strong>.<br>
</li>
<li>Click on your job name to see status, logs, and output model
artifacts.<br>
</li>
<li>Cancel jobs from the console if needed (be careful not to stop jobs
you don’t own in shared projects).</li>
</ol>
<div class="section level4">
<h4 id="visit-training-pipelines-to-verify-its-running--it-may-take-around-5-minutes-to-finish-">Visit “training pipelines” to verify it’s running. It may take
around 5 minutes to finish.<a class="anchor" aria-label="anchor" href="#visit-training-pipelines-to-verify-its-running--it-may-take-around-5-minutes-to-finish-"></a>
</h4>
<p><a href="https://console.cloud.google.com/vertex-ai/training/training-pipelines?hl=en&amp;project=doit-rci-mlm25-4626" class="external-link uri">https://console.cloud.google.com/vertex-ai/training/training-pipelines?hl=en&amp;project=doit-rci-mlm25-4626</a></p>
<p>Should output the following files:</p>
<ul>
<li>endemann_titanic/artifacts/xgb/20250924-154740/xgboost-model.joblib
# Python-serialized XGBoost model (Booster) via joblib; load with
joblib.load for reuse.</li>
<li>endemann_titanic/artifacts/xgb/20250924-154740/eval_history.csv #
Per-iteration validation metrics; columns: iter,val_logloss (good for
plotting learning curves).</li>
<li>endemann_titanic/artifacts/xgb/20250924-154740/training.log # Full
stdout/stderr from the run (params, dataset sizes, timings,
warnings/errors) for audit/debug.</li>
<li>endemann_titanic/artifacts/xgb/20250924-154740/metrics.json #
Structured summary: final_val_logloss, num_boost_round, params,
train_rows/val_rows, features[], model_uri.</li>
</ul>
</div>
</section><section><h2 class="section-heading" id="when-training-takes-too-long">When training takes too long<a class="anchor" aria-label="anchor" href="#when-training-takes-too-long"></a>
</h2>
<hr class="half-width">
<p>Two main options in Vertex AI:</p>
<ul>
<li>
<strong>Option 1: Upgrade to more powerful machine types</strong>
(e.g., add GPUs like T4, V100, A100).<br>
</li>
<li>
<strong>Option 2: Use distributed training with multiple
replicas</strong>.</li>
</ul>
<div class="section level3">
<h3 id="option-1-upgrade-machine-type-preferred-first-step">Option 1: Upgrade machine type (preferred first step)<a class="anchor" aria-label="anchor" href="#option-1-upgrade-machine-type-preferred-first-step"></a>
</h3>
<ul>
<li>Works best for small/medium datasets (&lt;10 GB).<br>
</li>
<li>Avoids the coordination overhead of distributed training.<br>
</li>
<li>GPUs/TPUs accelerate deep learning tasks significantly.</li>
</ul>
</div>
<div class="section level3">
<h3 id="option-2-distributed-training-with-multiple-replicas">Option 2: Distributed training with multiple replicas<a class="anchor" aria-label="anchor" href="#option-2-distributed-training-with-multiple-replicas"></a>
</h3>
<ul>
<li>Supported in Vertex AI for many frameworks.<br>
</li>
<li>Split data across replicas, each trains a portion, gradients
synchronized.<br>
</li>
<li>More beneficial for very large datasets and long-running jobs.</li>
</ul>
</div>
<div class="section level3">
<h3 id="when-distributed-training-makes-sense">When distributed training makes sense<a class="anchor" aria-label="anchor" href="#when-distributed-training-makes-sense"></a>
</h3>
<ul>
<li>Dataset &gt;10–50 GB.<br>
</li>
<li>Training time &gt;10 hours on single machine.<br>
</li>
<li>Deep learning workloads that naturally parallelize across
GPUs/TPUs.</li>
</ul>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>
<strong>Environment initialization</strong>: Use
<code>aiplatform.init()</code> to set defaults for project, region, and
bucket.<br>
</li>
<li>
<strong>Local vs managed training</strong>: Test locally before
scaling into managed jobs.<br>
</li>
<li>
<strong>Custom jobs</strong>: Vertex AI lets you run scripts as
managed training jobs using pre-built or custom containers.<br>
</li>
<li>
<strong>Scaling</strong>: Start small, then scale up to GPUs or
distributed jobs as dataset/model size grows.<br>
</li>
<li>
<strong>Monitoring</strong>: Track job logs and artifacts in the
Vertex AI Console.</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</div>
</section></section><section id="aio-07-Training-models-in-VertexAI-GPUs"><p>Content from <a href="07-Training-models-in-VertexAI-GPUs.html">Training Models in Vertex AI: PyTorch Example</a></p>
<hr>
<p>Last updated on 2025-10-24 |

        <a href="https://github.com/qualiaMachine/Intro_GCP_VertexAI/edit/main/episodes/07-Training-models-in-VertexAI-GPUs.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>When should you consider a GPU (or TPU) instance for PyTorch
training in Vertex AI, and what are the trade‑offs for small vs. large
workloads?</li>
<li>How do you launch a script‑based training job and write
<strong>all</strong> artifacts (model, metrics, logs) next to each other
in GCS without deploying a managed model?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Prepare the Titanic dataset and save train/val arrays to compressed
<code>.npz</code> files in GCS.</li>
<li>Submit a <strong>CustomTrainingJob</strong> that runs a PyTorch
script and explicitly writes outputs to a chosen
<code>gs://…/artifacts/.../</code> folder.</li>
<li>Co‑locate artifacts: <code>model.pt</code> (or
<code>.joblib</code>), <code>metrics.json</code>,
<code>eval_history.csv</code>, and <code>training.log</code> for
reproducibility.</li>
<li>Choose CPU vs. GPU instances sensibly; understand when distributed
training is (not) worth it.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="initial-setup-controller-notebook">Initial setup (controller notebook)<a class="anchor" aria-label="anchor" href="#initial-setup-controller-notebook"></a>
</h2>
<hr class="half-width">
<p>Open a fresh Jupyter notebook in Vertex AI Workbench (Instances tab)
and initialize:</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">from</span> google.cloud <span class="im">import</span> aiplatform, storage</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">import</span> datetime <span class="im">as</span> dt</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a>PROJECT_ID <span class="op">=</span> <span class="st">"your-gcp-project-id"</span></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a>REGION <span class="op">=</span> <span class="st">"us-central1"</span></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a>BUCKET_NAME <span class="op">=</span> <span class="st">"your-bucket"</span>  <span class="co"># same region as REGION</span></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a><span class="co"># Only used for the SDK's small packaging tarball.</span></span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a>aiplatform.init(project<span class="op">=</span>PROJECT_ID, location<span class="op">=</span>REGION, staging_bucket<span class="op">=</span><span class="ss">f"gs://</span><span class="sc">{</span>BUCKET_NAME<span class="sc">}</span><span class="ss">"</span>)</span></code></pre>
</div>
<div class="section level3">
<h3 id="select-the-pytorch-environment-kernel">Select the PyTorch environment (kernel)<a class="anchor" aria-label="anchor" href="#select-the-pytorch-environment-kernel"></a>
</h3>
<ul>
<li>
<p>In JupyterLab, click the kernel name (top‑right) and switch to a
<strong>PyTorch‑ready</strong> kernel. On Workbench Instances this is
usually available out‑of‑the‑box; if <code>import torch</code> fails,
install locally:</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="ex">pip</span> install torch torchvision <span class="at">--upgrade</span></span></code></pre>
</div>
</li>
<li>
<p>Quick check that your kernel can see PyTorch (and optionally CUDA
if your VM has a GPU):</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"torch:"</span>, torch.__version__, <span class="st">"cuda:"</span>, torch.cuda.is_available())</span></code></pre>
</div>
</li>
<li><p>Note: local PyTorch is only needed for <strong>local
tests</strong>. Your <strong>Vertex AI job</strong> uses the container
specified by <code>container_uri</code> (e.g.,
<code>pytorch-cpu.2-1</code> or <code>pytorch-gpu.2-1</code>), so it
brings its own framework at run time.</p></li>
</ul>
<p>Notes: - The staging bucket only stores the SDK’s temporary tar.gz of
your training code. - We will <strong>not</strong> use
<code>base_output_dir</code>; your script will write everything under a
single <code>gs://…/artifacts/.../</code> path.</p>
</div>
</section><section><h2 class="section-heading" id="prepare-data-as--npz">Prepare data as <code>.npz</code>
<a class="anchor" aria-label="anchor" href="#prepare-data-as--npz"></a>
</h2>
<hr class="half-width">
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler, LabelEncoder</span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a><span class="co"># Load Titanic CSV (from local or GCS you've already downloaded to the notebook)</span></span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">"titanic_train.csv"</span>)</span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a><span class="co"># Minimal preprocessing to numeric arrays</span></span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a>sex_enc <span class="op">=</span> LabelEncoder().fit(df[<span class="st">"Sex"</span>])  </span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a>df[<span class="st">"Sex"</span>] <span class="op">=</span> sex_enc.transform(df[<span class="st">"Sex"</span>])  </span>
<span id="cb4-12"><a href="#cb4-12" tabindex="-1"></a>df[<span class="st">"Embarked"</span>] <span class="op">=</span> df[<span class="st">"Embarked"</span>].fillna(<span class="st">"S"</span>)</span>
<span id="cb4-13"><a href="#cb4-13" tabindex="-1"></a>emb_enc <span class="op">=</span> LabelEncoder().fit(df[<span class="st">"Embarked"</span>])  </span>
<span id="cb4-14"><a href="#cb4-14" tabindex="-1"></a>df[<span class="st">"Embarked"</span>] <span class="op">=</span> emb_enc.transform(df[<span class="st">"Embarked"</span>])  </span>
<span id="cb4-15"><a href="#cb4-15" tabindex="-1"></a>df[<span class="st">"Age"</span>] <span class="op">=</span> df[<span class="st">"Age"</span>].fillna(df[<span class="st">"Age"</span>].median())</span>
<span id="cb4-16"><a href="#cb4-16" tabindex="-1"></a>df[<span class="st">"Fare"</span>] <span class="op">=</span> df[<span class="st">"Fare"</span>].fillna(df[<span class="st">"Fare"</span>].median())</span>
<span id="cb4-17"><a href="#cb4-17" tabindex="-1"></a></span>
<span id="cb4-18"><a href="#cb4-18" tabindex="-1"></a>X <span class="op">=</span> df[[<span class="st">"Pclass"</span>,<span class="st">"Sex"</span>,<span class="st">"Age"</span>,<span class="st">"SibSp"</span>,<span class="st">"Parch"</span>,<span class="st">"Fare"</span>,<span class="st">"Embarked"</span>]].values</span>
<span id="cb4-19"><a href="#cb4-19" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">"Survived"</span>].values</span>
<span id="cb4-20"><a href="#cb4-20" tabindex="-1"></a></span>
<span id="cb4-21"><a href="#cb4-21" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb4-22"><a href="#cb4-22" tabindex="-1"></a>X <span class="op">=</span> scaler.fit_transform(X)</span>
<span id="cb4-23"><a href="#cb4-23" tabindex="-1"></a></span>
<span id="cb4-24"><a href="#cb4-24" tabindex="-1"></a>X_train, X_val, y_train, y_val <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb4-25"><a href="#cb4-25" tabindex="-1"></a></span>
<span id="cb4-26"><a href="#cb4-26" tabindex="-1"></a>np.savez(<span class="st">"train_data.npz"</span>, X_train<span class="op">=</span>X_train, y_train<span class="op">=</span>y_train)</span>
<span id="cb4-27"><a href="#cb4-27" tabindex="-1"></a>np.savez(<span class="st">"val_data.npz"</span>,   X_val<span class="op">=</span>X_val,   y_val<span class="op">=</span>y_val)</span>
<span id="cb4-28"><a href="#cb4-28" tabindex="-1"></a></span>
<span id="cb4-29"><a href="#cb4-29" tabindex="-1"></a><span class="co"># Upload to GCS</span></span>
<span id="cb4-30"><a href="#cb4-30" tabindex="-1"></a>client <span class="op">=</span> storage.Client()</span>
<span id="cb4-31"><a href="#cb4-31" tabindex="-1"></a>bucket <span class="op">=</span> client.bucket(BUCKET_NAME)</span>
<span id="cb4-32"><a href="#cb4-32" tabindex="-1"></a>bucket.blob(<span class="st">"data/train_data.npz"</span>).upload_from_filename(<span class="st">"train_data.npz"</span>)</span>
<span id="cb4-33"><a href="#cb4-33" tabindex="-1"></a>bucket.blob(<span class="st">"data/val_data.npz"</span>).upload_from_filename(<span class="st">"val_data.npz"</span>)</span>
<span id="cb4-34"><a href="#cb4-34" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Uploaded: gs://</span><span class="sc">%s</span><span class="st">/data/train_data.npz and val_data.npz"</span> <span class="op">%</span> BUCKET_NAME)</span></code></pre>
</div>
<div id="why-.npz" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div id="why-.npz" class="callout-inner">
<h3 class="callout-title">Why <code>.npz</code>?</h3>
<div class="callout-content">
<ul>
<li>Smaller, faster I/O than CSV for arrays.</li>
<li>Natural fit for <code>torch.utils.data.Dataset</code> /
<code>DataLoader</code>.</li>
<li>One file can hold multiple arrays (<code>X_train</code>,
<code>y_train</code>).</li>
</ul>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="minimal-pytorch-training-script-train_nn-py">Minimal PyTorch training script (<code>train_nn.py</code>)<a class="anchor" aria-label="anchor" href="#minimal-pytorch-training-script-train_nn-py"></a>
</h2>
<hr class="half-width">
<p>Place this file in your repo (e.g.,
<code>GCP_helpers/train_nn.py</code>). It does three things: 1) loads
<code>.npz</code> from local or GCS, 2) trains a tiny MLP, 3)
<strong>writes all outputs side‑by‑side</strong> (model + metrics + eval
history + training.log) to the same <code>--model_out</code> folder.</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="co"># GCP_helpers/train_nn.py</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a><span class="im">import</span> argparse, io, json, os, sys</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a><span class="im">import</span> torch, torch.nn <span class="im">as</span> nn</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a><span class="im">from</span> time <span class="im">import</span> time</span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a><span class="co"># --- small helpers for GCS/local I/O ---</span></span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a><span class="kw">def</span> _parent_dir(p):</span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a>    <span class="cf">return</span> p.rsplit(<span class="st">"/"</span>, <span class="dv">1</span>)[<span class="dv">0</span>] <span class="cf">if</span> p.startswith(<span class="st">"gs://"</span>) <span class="cf">else</span> (os.path.dirname(p) <span class="kw">or</span> <span class="st">"."</span>)</span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a><span class="kw">def</span> _write_bytes(path: <span class="bu">str</span>, data: <span class="bu">bytes</span>):</span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a>    <span class="cf">if</span> path.startswith(<span class="st">"gs://"</span>):</span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb5-14"><a href="#cb5-14" tabindex="-1"></a>            <span class="im">import</span> fsspec</span>
<span id="cb5-15"><a href="#cb5-15" tabindex="-1"></a>            <span class="cf">with</span> fsspec.<span class="bu">open</span>(path, <span class="st">"wb"</span>) <span class="im">as</span> f:</span>
<span id="cb5-16"><a href="#cb5-16" tabindex="-1"></a>                f.write(data)</span>
<span id="cb5-17"><a href="#cb5-17" tabindex="-1"></a>        <span class="cf">except</span> <span class="pp">Exception</span>:</span>
<span id="cb5-18"><a href="#cb5-18" tabindex="-1"></a>            <span class="im">from</span> google.cloud <span class="im">import</span> storage</span>
<span id="cb5-19"><a href="#cb5-19" tabindex="-1"></a>            b, k <span class="op">=</span> path[<span class="dv">5</span>:].split(<span class="st">"/"</span>, <span class="dv">1</span>)</span>
<span id="cb5-20"><a href="#cb5-20" tabindex="-1"></a>            storage.Client().bucket(b).blob(k).upload_from_string(data)</span>
<span id="cb5-21"><a href="#cb5-21" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb5-22"><a href="#cb5-22" tabindex="-1"></a>        os.makedirs(_parent_dir(path), exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-23"><a href="#cb5-23" tabindex="-1"></a>        <span class="cf">with</span> <span class="bu">open</span>(path, <span class="st">"wb"</span>) <span class="im">as</span> f:</span>
<span id="cb5-24"><a href="#cb5-24" tabindex="-1"></a>            f.write(data)</span>
<span id="cb5-25"><a href="#cb5-25" tabindex="-1"></a></span>
<span id="cb5-26"><a href="#cb5-26" tabindex="-1"></a><span class="kw">def</span> _write_text(path: <span class="bu">str</span>, text: <span class="bu">str</span>):</span>
<span id="cb5-27"><a href="#cb5-27" tabindex="-1"></a>    _write_bytes(path, text.encode(<span class="st">"utf-8"</span>))</span>
<span id="cb5-28"><a href="#cb5-28" tabindex="-1"></a></span>
<span id="cb5-29"><a href="#cb5-29" tabindex="-1"></a><span class="co"># --- tiny MLP ---</span></span>
<span id="cb5-30"><a href="#cb5-30" tabindex="-1"></a><span class="kw">class</span> MLP(nn.Module):</span>
<span id="cb5-31"><a href="#cb5-31" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, d_in):</span>
<span id="cb5-32"><a href="#cb5-32" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb5-33"><a href="#cb5-33" tabindex="-1"></a>        <span class="va">self</span>.net <span class="op">=</span> nn.Sequential(</span>
<span id="cb5-34"><a href="#cb5-34" tabindex="-1"></a>            nn.Linear(d_in, <span class="dv">32</span>), nn.ReLU(),</span>
<span id="cb5-35"><a href="#cb5-35" tabindex="-1"></a>            nn.Linear(<span class="dv">32</span>, <span class="dv">16</span>), nn.ReLU(),</span>
<span id="cb5-36"><a href="#cb5-36" tabindex="-1"></a>            nn.Linear(<span class="dv">16</span>, <span class="dv">1</span>), nn.Sigmoid(),</span>
<span id="cb5-37"><a href="#cb5-37" tabindex="-1"></a>        )</span>
<span id="cb5-38"><a href="#cb5-38" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb5-39"><a href="#cb5-39" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.net(x)</span>
<span id="cb5-40"><a href="#cb5-40" tabindex="-1"></a></span>
<span id="cb5-41"><a href="#cb5-41" tabindex="-1"></a><span class="kw">class</span> _Tee:</span>
<span id="cb5-42"><a href="#cb5-42" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, <span class="op">*</span>s): <span class="va">self</span>.s <span class="op">=</span> s</span>
<span id="cb5-43"><a href="#cb5-43" tabindex="-1"></a>    <span class="kw">def</span> write(<span class="va">self</span>, d):</span>
<span id="cb5-44"><a href="#cb5-44" tabindex="-1"></a>        <span class="cf">for</span> x <span class="kw">in</span> <span class="va">self</span>.s: x.write(d)<span class="op">;</span> x.flush()</span>
<span id="cb5-45"><a href="#cb5-45" tabindex="-1"></a>    <span class="kw">def</span> flush(<span class="va">self</span>):</span>
<span id="cb5-46"><a href="#cb5-46" tabindex="-1"></a>        <span class="cf">for</span> x <span class="kw">in</span> <span class="va">self</span>.s: x.flush()</span>
<span id="cb5-47"><a href="#cb5-47" tabindex="-1"></a></span>
<span id="cb5-48"><a href="#cb5-48" tabindex="-1"></a><span class="kw">def</span> main():</span>
<span id="cb5-49"><a href="#cb5-49" tabindex="-1"></a>    ap <span class="op">=</span> argparse.ArgumentParser()</span>
<span id="cb5-50"><a href="#cb5-50" tabindex="-1"></a>    ap.add_argument(<span class="st">"--train"</span>, required<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-51"><a href="#cb5-51" tabindex="-1"></a>    ap.add_argument(<span class="st">"--val"</span>,   required<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-52"><a href="#cb5-52" tabindex="-1"></a>    ap.add_argument(<span class="st">"--epochs"</span>, <span class="bu">type</span><span class="op">=</span><span class="bu">int</span>, default<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb5-53"><a href="#cb5-53" tabindex="-1"></a>    ap.add_argument(<span class="st">"--learning_rate"</span>, <span class="bu">type</span><span class="op">=</span><span class="bu">float</span>, default<span class="op">=</span><span class="fl">1e-3</span>)</span>
<span id="cb5-54"><a href="#cb5-54" tabindex="-1"></a>    ap.add_argument(<span class="st">"--model_out"</span>, required<span class="op">=</span><span class="va">True</span>, <span class="bu">help</span><span class="op">=</span><span class="st">"gs://…/artifacts/.../model.pt"</span>)</span>
<span id="cb5-55"><a href="#cb5-55" tabindex="-1"></a>    args <span class="op">=</span> ap.parse_args()</span>
<span id="cb5-56"><a href="#cb5-56" tabindex="-1"></a></span>
<span id="cb5-57"><a href="#cb5-57" tabindex="-1"></a>    device <span class="op">=</span> torch.device(<span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>)</span>
<span id="cb5-58"><a href="#cb5-58" tabindex="-1"></a></span>
<span id="cb5-59"><a href="#cb5-59" tabindex="-1"></a>    <span class="co"># All artifacts will sit next to model_out</span></span>
<span id="cb5-60"><a href="#cb5-60" tabindex="-1"></a>    model_path <span class="op">=</span> args.model_out</span>
<span id="cb5-61"><a href="#cb5-61" tabindex="-1"></a>    art_dir <span class="op">=</span> _parent_dir(model_path)</span>
<span id="cb5-62"><a href="#cb5-62" tabindex="-1"></a></span>
<span id="cb5-63"><a href="#cb5-63" tabindex="-1"></a>    <span class="co"># capture stdout/stderr</span></span>
<span id="cb5-64"><a href="#cb5-64" tabindex="-1"></a>    buf <span class="op">=</span> io.StringIO()</span>
<span id="cb5-65"><a href="#cb5-65" tabindex="-1"></a>    orig_out, orig_err <span class="op">=</span> sys.stdout, sys.stderr</span>
<span id="cb5-66"><a href="#cb5-66" tabindex="-1"></a>    sys.stdout <span class="op">=</span> _Tee(sys.stdout, buf)</span>
<span id="cb5-67"><a href="#cb5-67" tabindex="-1"></a>    sys.stderr <span class="op">=</span> _Tee(sys.stderr, buf)</span>
<span id="cb5-68"><a href="#cb5-68" tabindex="-1"></a>    log_path <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>art_dir<span class="sc">}</span><span class="ss">/training.log"</span></span>
<span id="cb5-69"><a href="#cb5-69" tabindex="-1"></a></span>
<span id="cb5-70"><a href="#cb5-70" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb5-71"><a href="#cb5-71" tabindex="-1"></a>        <span class="co"># Load npz (supports gs:// via fsspec)</span></span>
<span id="cb5-72"><a href="#cb5-72" tabindex="-1"></a>        <span class="kw">def</span> _npz_load(p):</span>
<span id="cb5-73"><a href="#cb5-73" tabindex="-1"></a>            <span class="cf">if</span> p.startswith(<span class="st">"gs://"</span>):</span>
<span id="cb5-74"><a href="#cb5-74" tabindex="-1"></a>                <span class="im">import</span> fsspec</span>
<span id="cb5-75"><a href="#cb5-75" tabindex="-1"></a>                <span class="cf">with</span> fsspec.<span class="bu">open</span>(p, <span class="st">"rb"</span>) <span class="im">as</span> f:</span>
<span id="cb5-76"><a href="#cb5-76" tabindex="-1"></a>                    by <span class="op">=</span> f.read()</span>
<span id="cb5-77"><a href="#cb5-77" tabindex="-1"></a>                <span class="cf">return</span> np.load(io.BytesIO(by))</span>
<span id="cb5-78"><a href="#cb5-78" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb5-79"><a href="#cb5-79" tabindex="-1"></a>                <span class="cf">return</span> np.load(p)</span>
<span id="cb5-80"><a href="#cb5-80" tabindex="-1"></a>        train <span class="op">=</span> _npz_load(args.train)</span>
<span id="cb5-81"><a href="#cb5-81" tabindex="-1"></a>        val   <span class="op">=</span> _npz_load(args.val)</span>
<span id="cb5-82"><a href="#cb5-82" tabindex="-1"></a>        Xtr, ytr <span class="op">=</span> train[<span class="st">"X_train"</span>].astype(<span class="st">"float32"</span>), train[<span class="st">"y_train"</span>].astype(<span class="st">"float32"</span>)</span>
<span id="cb5-83"><a href="#cb5-83" tabindex="-1"></a>        Xva, yva <span class="op">=</span> val[<span class="st">"X_val"</span>].astype(<span class="st">"float32"</span>),   val[<span class="st">"y_val"</span>].astype(<span class="st">"float32"</span>)</span>
<span id="cb5-84"><a href="#cb5-84" tabindex="-1"></a></span>
<span id="cb5-85"><a href="#cb5-85" tabindex="-1"></a>        Xtr_t <span class="op">=</span> torch.from_numpy(Xtr).to(device)</span>
<span id="cb5-86"><a href="#cb5-86" tabindex="-1"></a>        ytr_t <span class="op">=</span> torch.from_numpy(ytr).view(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>).to(device)</span>
<span id="cb5-87"><a href="#cb5-87" tabindex="-1"></a>        Xva_t <span class="op">=</span> torch.from_numpy(Xva).to(device)</span>
<span id="cb5-88"><a href="#cb5-88" tabindex="-1"></a>        yva_t <span class="op">=</span> torch.from_numpy(yva).view(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>).to(device)</span>
<span id="cb5-89"><a href="#cb5-89" tabindex="-1"></a></span>
<span id="cb5-90"><a href="#cb5-90" tabindex="-1"></a>        model <span class="op">=</span> MLP(Xtr.shape[<span class="dv">1</span>]).to(device)</span>
<span id="cb5-91"><a href="#cb5-91" tabindex="-1"></a>        opt <span class="op">=</span> torch.optim.Adam(model.parameters(), lr<span class="op">=</span>args.learning_rate)</span>
<span id="cb5-92"><a href="#cb5-92" tabindex="-1"></a>        loss_fn <span class="op">=</span> nn.BCELoss()</span>
<span id="cb5-93"><a href="#cb5-93" tabindex="-1"></a></span>
<span id="cb5-94"><a href="#cb5-94" tabindex="-1"></a>        hist <span class="op">=</span> []</span>
<span id="cb5-95"><a href="#cb5-95" tabindex="-1"></a>        t0 <span class="op">=</span> time()</span>
<span id="cb5-96"><a href="#cb5-96" tabindex="-1"></a>        <span class="cf">for</span> ep <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, args.epochs<span class="op">+</span><span class="dv">1</span>):</span>
<span id="cb5-97"><a href="#cb5-97" tabindex="-1"></a>            model.train()</span>
<span id="cb5-98"><a href="#cb5-98" tabindex="-1"></a>            opt.zero_grad()</span>
<span id="cb5-99"><a href="#cb5-99" tabindex="-1"></a>            pred <span class="op">=</span> model(Xtr_t)</span>
<span id="cb5-100"><a href="#cb5-100" tabindex="-1"></a>            loss <span class="op">=</span> loss_fn(pred, ytr_t)</span>
<span id="cb5-101"><a href="#cb5-101" tabindex="-1"></a>            loss.backward()<span class="op">;</span> opt.step()</span>
<span id="cb5-102"><a href="#cb5-102" tabindex="-1"></a></span>
<span id="cb5-103"><a href="#cb5-103" tabindex="-1"></a>            model.<span class="bu">eval</span>()</span>
<span id="cb5-104"><a href="#cb5-104" tabindex="-1"></a>            <span class="cf">with</span> torch.no_grad():</span>
<span id="cb5-105"><a href="#cb5-105" tabindex="-1"></a>                val_loss <span class="op">=</span> loss_fn(model(Xva_t), yva_t).item()</span>
<span id="cb5-106"><a href="#cb5-106" tabindex="-1"></a>            hist.append(val_loss)</span>
<span id="cb5-107"><a href="#cb5-107" tabindex="-1"></a>            <span class="cf">if</span> ep <span class="op">%</span> <span class="dv">10</span> <span class="op">==</span> <span class="dv">0</span> <span class="kw">or</span> ep <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb5-108"><a href="#cb5-108" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f"epoch=</span><span class="sc">{</span>ep<span class="sc">}</span><span class="ss"> val_loss=</span><span class="sc">{</span>val_loss<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb5-109"><a href="#cb5-109" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Training time: </span><span class="sc">{</span>time()<span class="op">-</span>t0<span class="sc">:.2f}</span><span class="ss">s on </span><span class="sc">{</span>device<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb5-110"><a href="#cb5-110" tabindex="-1"></a></span>
<span id="cb5-111"><a href="#cb5-111" tabindex="-1"></a>        <span class="co"># save model</span></span>
<span id="cb5-112"><a href="#cb5-112" tabindex="-1"></a>        torch.save(model.state_dict(), model_path)</span>
<span id="cb5-113"><a href="#cb5-113" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"[INFO] Saved model: </span><span class="sc">{</span>model_path<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb5-114"><a href="#cb5-114" tabindex="-1"></a></span>
<span id="cb5-115"><a href="#cb5-115" tabindex="-1"></a>        <span class="co"># metrics.json and eval_history.csv</span></span>
<span id="cb5-116"><a href="#cb5-116" tabindex="-1"></a>        <span class="im">import</span> json</span>
<span id="cb5-117"><a href="#cb5-117" tabindex="-1"></a>        metrics <span class="op">=</span> {</span>
<span id="cb5-118"><a href="#cb5-118" tabindex="-1"></a>            <span class="st">"final_val_loss"</span>: <span class="bu">float</span>(hist[<span class="op">-</span><span class="dv">1</span>]) <span class="cf">if</span> hist <span class="cf">else</span> <span class="va">None</span>,</span>
<span id="cb5-119"><a href="#cb5-119" tabindex="-1"></a>            <span class="st">"epochs"</span>: <span class="bu">int</span>(args.epochs),</span>
<span id="cb5-120"><a href="#cb5-120" tabindex="-1"></a>            <span class="st">"learning_rate"</span>: <span class="bu">float</span>(args.learning_rate),</span>
<span id="cb5-121"><a href="#cb5-121" tabindex="-1"></a>            <span class="st">"train_rows"</span>: <span class="bu">int</span>(Xtr.shape[<span class="dv">0</span>]),</span>
<span id="cb5-122"><a href="#cb5-122" tabindex="-1"></a>            <span class="st">"val_rows"</span>: <span class="bu">int</span>(Xva.shape[<span class="dv">0</span>]),</span>
<span id="cb5-123"><a href="#cb5-123" tabindex="-1"></a>            <span class="st">"features"</span>: <span class="bu">list</span>(<span class="bu">range</span>(Xtr.shape[<span class="dv">1</span>])),</span>
<span id="cb5-124"><a href="#cb5-124" tabindex="-1"></a>            <span class="st">"model_uri"</span>: model_path,</span>
<span id="cb5-125"><a href="#cb5-125" tabindex="-1"></a>            <span class="st">"device"</span>: <span class="bu">str</span>(device),</span>
<span id="cb5-126"><a href="#cb5-126" tabindex="-1"></a>        }</span>
<span id="cb5-127"><a href="#cb5-127" tabindex="-1"></a>        <span class="im">from</span> io <span class="im">import</span> StringIO</span>
<span id="cb5-128"><a href="#cb5-128" tabindex="-1"></a>        _write_text(<span class="ss">f"</span><span class="sc">{</span>art_dir<span class="sc">}</span><span class="ss">/metrics.json"</span>, json.dumps(metrics, indent<span class="op">=</span><span class="dv">2</span>))</span>
<span id="cb5-129"><a href="#cb5-129" tabindex="-1"></a>        csv <span class="op">=</span> <span class="st">"iter,val_loss</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>.join(<span class="ss">f"</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">,</span><span class="sc">{</span>v<span class="sc">}</span><span class="ss">"</span> <span class="cf">for</span> i, v <span class="kw">in</span> <span class="bu">enumerate</span>(hist))</span>
<span id="cb5-130"><a href="#cb5-130" tabindex="-1"></a>        _write_text(<span class="ss">f"</span><span class="sc">{</span>art_dir<span class="sc">}</span><span class="ss">/eval_history.csv"</span>, csv)</span>
<span id="cb5-131"><a href="#cb5-131" tabindex="-1"></a>    <span class="cf">finally</span>:</span>
<span id="cb5-132"><a href="#cb5-132" tabindex="-1"></a>        <span class="co"># persist log and restore streams</span></span>
<span id="cb5-133"><a href="#cb5-133" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb5-134"><a href="#cb5-134" tabindex="-1"></a>            _write_text(log_path, buf.getvalue())</span>
<span id="cb5-135"><a href="#cb5-135" tabindex="-1"></a>        <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb5-136"><a href="#cb5-136" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"[WARN] could not write log: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb5-137"><a href="#cb5-137" tabindex="-1"></a>        sys.stdout, sys.stderr <span class="op">=</span> orig_out, orig_err</span>
<span id="cb5-138"><a href="#cb5-138" tabindex="-1"></a></span>
<span id="cb5-139"><a href="#cb5-139" tabindex="-1"></a><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">"__main__"</span>:</span>
<span id="cb5-140"><a href="#cb5-140" tabindex="-1"></a>    main()</span></code></pre>
</div>
</section><section><h2 class="section-heading" id="launch-the-training-job-no-base_output_dir">Launch the training job (no base_output_dir)<a class="anchor" aria-label="anchor" href="#launch-the-training-job-no-base_output_dir"></a>
</h2>
<hr class="half-width">
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>RUN_ID <span class="op">=</span> dt.datetime.now().strftime(<span class="st">"%Y%m</span><span class="sc">%d</span><span class="st">-%H%M%S"</span>)</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>ARTIFACT_DIR <span class="op">=</span> <span class="ss">f"gs://</span><span class="sc">{</span>BUCKET_NAME<span class="sc">}</span><span class="ss">/artifacts/pytorch/</span><span class="sc">{</span>RUN_ID<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>MODEL_URI <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>ARTIFACT_DIR<span class="sc">}</span><span class="ss">/model.pt"</span>   <span class="co"># model + metrics + logs will live here together</span></span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a>job <span class="op">=</span> aiplatform.CustomTrainingJob(</span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a>    display_name<span class="op">=</span><span class="ss">f"pytorch_nn_</span><span class="sc">{</span>RUN_ID<span class="sc">}</span><span class="ss">"</span>,</span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a>    script_path<span class="op">=</span><span class="st">"GCP_helpers/train_nn.py"</span>,</span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a>    container_uri<span class="op">=</span><span class="st">"us-docker.pkg.dev/vertex-ai/training/pytorch-cpu.2-1:latest"</span>,  <span class="co"># or pytorch-gpu.2-1</span></span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a>    requirements<span class="op">=</span>[<span class="st">"torch"</span>, <span class="st">"numpy"</span>, <span class="st">"fsspec"</span>, <span class="st">"gcsfs"</span>],</span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a>)</span>
<span id="cb6-11"><a href="#cb6-11" tabindex="-1"></a></span>
<span id="cb6-12"><a href="#cb6-12" tabindex="-1"></a>job.run(</span>
<span id="cb6-13"><a href="#cb6-13" tabindex="-1"></a>    args<span class="op">=</span>[</span>
<span id="cb6-14"><a href="#cb6-14" tabindex="-1"></a>        <span class="ss">f"--train=gs://</span><span class="sc">{</span>BUCKET_NAME<span class="sc">}</span><span class="ss">/data/train_data.npz"</span>,</span>
<span id="cb6-15"><a href="#cb6-15" tabindex="-1"></a>        <span class="ss">f"--val=gs://</span><span class="sc">{</span>BUCKET_NAME<span class="sc">}</span><span class="ss">/data/val_data.npz"</span>,</span>
<span id="cb6-16"><a href="#cb6-16" tabindex="-1"></a>        <span class="ss">f"--epochs=200"</span>,</span>
<span id="cb6-17"><a href="#cb6-17" tabindex="-1"></a>        <span class="ss">f"--learning_rate=0.001"</span>,</span>
<span id="cb6-18"><a href="#cb6-18" tabindex="-1"></a>        <span class="ss">f"--model_out=</span><span class="sc">{</span>MODEL_URI<span class="sc">}</span><span class="ss">"</span>,   <span class="co"># drives where *all* artifacts go</span></span>
<span id="cb6-19"><a href="#cb6-19" tabindex="-1"></a>    ],</span>
<span id="cb6-20"><a href="#cb6-20" tabindex="-1"></a>    replica_count<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb6-21"><a href="#cb6-21" tabindex="-1"></a>    machine_type<span class="op">=</span><span class="st">"n1-standard-4"</span>,  <span class="co"># CPU fine for small datasets</span></span>
<span id="cb6-22"><a href="#cb6-22" tabindex="-1"></a>    sync<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb6-23"><a href="#cb6-23" tabindex="-1"></a>)</span>
<span id="cb6-24"><a href="#cb6-24" tabindex="-1"></a></span>
<span id="cb6-25"><a href="#cb6-25" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Artifacts folder:"</span>, ARTIFACT_DIR)</span></code></pre>
</div>
<p><strong>What you’ll see in
<code>gs://…/artifacts/pytorch/&lt;RUN_ID&gt;/</code>:</strong> -
<code>model.pt</code> — PyTorch weights (<code>state_dict</code>). -
<code>metrics.json</code> — final val loss, hyperparameters, dataset
sizes, device, model URI. - <code>eval_history.csv</code> — per‑epoch
validation loss (for plots/regression checks). -
<code>training.log</code> — complete stdout/stderr for reproducibility
and debugging.</p>
</section><section><h2 class="section-heading" id="optional-gpu-training">Optional: GPU training<a class="anchor" aria-label="anchor" href="#optional-gpu-training"></a>
</h2>
<hr class="half-width">
<p>For larger models or heavier data:</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a>job <span class="op">=</span> aiplatform.CustomTrainingJob(</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>    display_name<span class="op">=</span><span class="ss">f"pytorch_nn_gpu_</span><span class="sc">{</span>RUN_ID<span class="sc">}</span><span class="ss">"</span>,</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>    script_path<span class="op">=</span><span class="st">"GCP_helpers/train_nn.py"</span>,</span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>    container_uri<span class="op">=</span><span class="st">"us-docker.pkg.dev/vertex-ai/training/pytorch-gpu.2-1:latest"</span>,</span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a>    requirements<span class="op">=</span>[<span class="st">"torch"</span>, <span class="st">"numpy"</span>, <span class="st">"fsspec"</span>, <span class="st">"gcsfs"</span>],</span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a>)</span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a>job.run(</span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a>    args<span class="op">=</span>[</span>
<span id="cb7-10"><a href="#cb7-10" tabindex="-1"></a>        <span class="ss">f"--train=gs://</span><span class="sc">{</span>BUCKET_NAME<span class="sc">}</span><span class="ss">/data/train_data.npz"</span>,</span>
<span id="cb7-11"><a href="#cb7-11" tabindex="-1"></a>        <span class="ss">f"--val=gs://</span><span class="sc">{</span>BUCKET_NAME<span class="sc">}</span><span class="ss">/data/val_data.npz"</span>,</span>
<span id="cb7-12"><a href="#cb7-12" tabindex="-1"></a>        <span class="ss">f"--epochs=200"</span>,</span>
<span id="cb7-13"><a href="#cb7-13" tabindex="-1"></a>        <span class="ss">f"--learning_rate=0.001"</span>,</span>
<span id="cb7-14"><a href="#cb7-14" tabindex="-1"></a>        <span class="ss">f"--model_out=</span><span class="sc">{</span>MODEL_URI<span class="sc">}</span><span class="ss">"</span>,</span>
<span id="cb7-15"><a href="#cb7-15" tabindex="-1"></a>    ],</span>
<span id="cb7-16"><a href="#cb7-16" tabindex="-1"></a>    replica_count<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb7-17"><a href="#cb7-17" tabindex="-1"></a>    machine_type<span class="op">=</span><span class="st">"n1-standard-8"</span>,</span>
<span id="cb7-18"><a href="#cb7-18" tabindex="-1"></a>    accelerator_type<span class="op">=</span><span class="st">"NVIDIA_TESLA_T4"</span>,</span>
<span id="cb7-19"><a href="#cb7-19" tabindex="-1"></a>    accelerator_count<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb7-20"><a href="#cb7-20" tabindex="-1"></a>    sync<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb7-21"><a href="#cb7-21" tabindex="-1"></a>)</span></code></pre>
</div>
<p>GPU tips: - On small problems, GPU startup/transfer overhead can
erase speedups—benchmark before you scale. - Stick to a single replica
unless your batch sizes and dataset really warrant data parallelism.</p>
</section><section><h2 class="section-heading" id="distributed-training-when-to-consider">Distributed training (when to consider)<a class="anchor" aria-label="anchor" href="#distributed-training-when-to-consider"></a>
</h2>
<hr class="half-width">
<ul>
<li>
<strong>Data parallelism</strong> (DDP) helps when a single GPU is
saturated by batch size/throughput. For most workshop‑scale models, a
single machine/GPU is simpler and cheaper.</li>
<li>
<strong>Model parallelism</strong> is for very large networks that
don’t fit on one device—overkill for this lesson.</li>
</ul></section><section><h2 class="section-heading" id="monitoring-jobs-finding-outputs">Monitoring jobs &amp; finding outputs<a class="anchor" aria-label="anchor" href="#monitoring-jobs-finding-outputs"></a>
</h2>
<hr class="half-width">
<ul>
<li>Console → Vertex AI → Training → Custom Jobs → your run → “Output
directory” shows the container logs and the environment’s
<code>AIP_MODEL_DIR</code>.</li>
<li>Your script writes <strong>model + metrics + eval history +
training.log</strong> next to <code>--model_out</code>, e.g.,
<code>gs://&lt;bucket&gt;/artifacts/pytorch/&lt;RUN_ID&gt;/</code>.</li>
</ul>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>Use <strong>CustomTrainingJob</strong> with a prebuilt PyTorch
container; let your script control outputs via
<code>--model_out</code>.</li>
<li>Keep artifacts <strong>together</strong> (model, metrics, history,
log) in one folder for reproducibility.</li>
<li>
<code>.npz</code> speeds up loading and plays nicely with
PyTorch.</li>
<li>Start on CPU for small datasets; use GPU only when profiling shows a
clear win.</li>
<li>Skip <code>base_output_dir</code> unless you specifically want
Vertex’s default run directory; staging bucket is just for the SDK
packaging tarball.</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</section></section><section id="aio-08-Hyperparameter-tuning"><p>Content from <a href="08-Hyperparameter-tuning.html">Hyperparameter Tuning in Vertex AI: Neural Network Example</a></p>
<hr>
<p>Last updated on 2025-10-24 |

        <a href="https://github.com/qualiaMachine/Intro_GCP_VertexAI/edit/main/episodes/08-Hyperparameter-tuning.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How can we efficiently manage hyperparameter tuning in Vertex
AI?<br>
</li>
<li>How can we parallelize tuning jobs to optimize time without
increasing costs?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Set up and run a hyperparameter tuning job in Vertex AI.<br>
</li>
<li>Define search spaces for <code>ContinuousParameter</code> and
<code>CategoricalParameter</code>.<br>
</li>
<li>Log and capture objective metrics for evaluating tuning
success.<br>
</li>
<li>Optimize tuning setup to balance cost and efficiency, including
parallelization.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<p>To conduct efficient hyperparameter tuning with neural networks (or
any model) in Vertex AI, we’ll use Vertex AI’s <strong>Hyperparameter
Tuning Jobs</strong>. The key is defining a clear search space, ensuring
metrics are properly logged, and keeping costs manageable by controlling
the number of trials and level of parallelization.</p>
<div class="section level3">
<h3 id="key-steps-for-hyperparameter-tuning">Key steps for hyperparameter tuning<a class="anchor" aria-label="anchor" href="#key-steps-for-hyperparameter-tuning"></a>
</h3>
<p>The overall process involves these steps:</p>
<ol style="list-style-type: decimal">
<li>Prepare training script and ensure metrics are logged.<br>
</li>
<li>Define hyperparameter search space.<br>
</li>
<li>Configure a hyperparameter tuning job in Vertex AI.<br>
</li>
<li>Set data paths and launch the tuning job.<br>
</li>
<li>Monitor progress in the Vertex AI Console.<br>
</li>
<li>Extract best model and evaluate.</li>
</ol>
<div class="section level4">
<h4 id="directory-setup">0. Directory setup<a class="anchor" aria-label="anchor" href="#directory-setup"></a>
</h4>
<p>Change directory to your Jupyter home folder.</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="op">%</span>cd <span class="op">/</span>home<span class="op">/</span>jupyter<span class="op">/</span></span></code></pre>
</div>
</div>
<div class="section level4">
<h4 id="prepare-training-script-with-metric-logging">1. Prepare training script with metric logging<a class="anchor" aria-label="anchor" href="#prepare-training-script-with-metric-logging"></a>
</h4>
<p>Your training script (<code>train_nn.py</code>) should periodically
print validation accuracy in a format that Vertex AI can capture.</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="cf">if</span> (epoch <span class="op">+</span> <span class="dv">1</span>) <span class="op">%</span> <span class="dv">100</span> <span class="op">==</span> <span class="dv">0</span> <span class="kw">or</span> epoch <span class="op">==</span> epochs <span class="op">-</span> <span class="dv">1</span>:</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"validation_accuracy: </span><span class="sc">{</span>val_accuracy<span class="sc">:.4f}</span><span class="ss">"</span>, flush<span class="op">=</span><span class="va">True</span>)</span></code></pre>
</div>
<p>Vertex AI automatically captures metrics logged in this format
(<code>key: value</code>).</p>
</div>
<div class="section level4">
<h4 id="define-hyperparameter-search-space">2. Define hyperparameter search space<a class="anchor" aria-label="anchor" href="#define-hyperparameter-search-space"></a>
</h4>
<p>In Vertex AI, you specify hyperparameter ranges when configuring the
tuning job. You can define both discrete and continuous ranges.</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>parameter_spec <span class="op">=</span> {</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>    <span class="st">"epochs"</span>: aiplatform.hyperparameter_tuning_utils.IntegerParameterSpec(<span class="bu">min</span><span class="op">=</span><span class="dv">100</span>, <span class="bu">max</span><span class="op">=</span><span class="dv">1000</span>, scale<span class="op">=</span><span class="st">"linear"</span>),</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>    <span class="st">"learning_rate"</span>: aiplatform.hyperparameter_tuning_utils.DoubleParameterSpec(<span class="bu">min</span><span class="op">=</span><span class="fl">0.001</span>, <span class="bu">max</span><span class="op">=</span><span class="fl">0.1</span>, scale<span class="op">=</span><span class="st">"log"</span>)</span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>}</span></code></pre>
</div>
<ul>
<li>
<strong>IntegerParameterSpec</strong>: Defines integer ranges.<br>
</li>
<li>
<strong>DoubleParameterSpec</strong>: Defines continuous ranges,
with optional scaling.</li>
</ul>
</div>
<div class="section level4">
<h4 id="configure-hyperparameter-tuning-job">3. Configure hyperparameter tuning job<a class="anchor" aria-label="anchor" href="#configure-hyperparameter-tuning-job"></a>
</h4>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="im">from</span> google.cloud <span class="im">import</span> aiplatform</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>job <span class="op">=</span> aiplatform.CustomJob(</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>    display_name<span class="op">=</span><span class="st">"pytorch-train-hpt"</span>,</span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a>    script_path<span class="op">=</span><span class="st">"GCP_helpers/train_nn.py"</span>,</span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a>    container_uri<span class="op">=</span><span class="st">"us-docker.pkg.dev/vertex-ai/training/pytorch-gpu.1-13:latest"</span>,</span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a>    requirements<span class="op">=</span>[<span class="st">"torch"</span>, <span class="st">"pandas"</span>, <span class="st">"numpy"</span>, <span class="st">"scikit-learn"</span>],</span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a>    model_serving_container_image_uri<span class="op">=</span><span class="st">"us-docker.pkg.dev/vertex-ai/prediction/pytorch-gpu.1-13:latest"</span>,</span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a>)</span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a>hpt_job <span class="op">=</span> aiplatform.HyperparameterTuningJob(</span>
<span id="cb4-12"><a href="#cb4-12" tabindex="-1"></a>    display_name<span class="op">=</span><span class="st">"pytorch-hpt-job"</span>,</span>
<span id="cb4-13"><a href="#cb4-13" tabindex="-1"></a>    custom_job<span class="op">=</span>job,</span>
<span id="cb4-14"><a href="#cb4-14" tabindex="-1"></a>    metric_spec<span class="op">=</span>{<span class="st">"validation_accuracy"</span>: <span class="st">"maximize"</span>},</span>
<span id="cb4-15"><a href="#cb4-15" tabindex="-1"></a>    parameter_spec<span class="op">=</span>parameter_spec,</span>
<span id="cb4-16"><a href="#cb4-16" tabindex="-1"></a>    max_trial_count<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb4-17"><a href="#cb4-17" tabindex="-1"></a>    parallel_trial_count<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb4-18"><a href="#cb4-18" tabindex="-1"></a>)</span></code></pre>
</div>
</div>
<div class="section level4">
<h4 id="launch-the-hyperparameter-tuning-job">4. Launch the hyperparameter tuning job<a class="anchor" aria-label="anchor" href="#launch-the-hyperparameter-tuning-job"></a>
</h4>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>hpt_job.run(</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>    machine_type<span class="op">=</span><span class="st">"n1-standard-4"</span>,</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a>    accelerator_type<span class="op">=</span><span class="st">"NVIDIA_TESLA_T4"</span>,</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>    accelerator_count<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>    args<span class="op">=</span>[</span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>        <span class="st">"--train=gs://</span><span class="sc">{}</span><span class="st">/train_data.npz"</span>.<span class="bu">format</span>(BUCKET_NAME),</span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a>        <span class="st">"--val=gs://</span><span class="sc">{}</span><span class="st">/val_data.npz"</span>.<span class="bu">format</span>(BUCKET_NAME),</span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a>        <span class="st">"--epochs=100"</span>,</span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a>        <span class="st">"--learning_rate=0.001"</span></span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a>    ]</span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a>)</span></code></pre>
</div>
<ul>
<li>
<strong>max_trial_count</strong>: Total number of configurations
tested.<br>
</li>
<li>
<strong>parallel_trial_count</strong>: Number of trials run at once
(recommend ≤4 to let adaptive search improve).</li>
</ul>
</div>
<div class="section level4">
<h4 id="monitor-tuning-job-in-vertex-ai-console">5. Monitor tuning job in Vertex AI Console<a class="anchor" aria-label="anchor" href="#monitor-tuning-job-in-vertex-ai-console"></a>
</h4>
<ol style="list-style-type: decimal">
<li>Navigate to <strong>Vertex AI &gt; Training &gt; Hyperparameter
tuning jobs</strong>.<br>
</li>
<li>View trial progress, logs, and metrics.<br>
</li>
<li>Cancel jobs from the console if needed.</li>
</ol>
</div>
<div class="section level4">
<h4 id="extract-and-evaluate-the-best-model">6. Extract and evaluate the best model<a class="anchor" aria-label="anchor" href="#extract-and-evaluate-the-best-model"></a>
</h4>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>best_trial <span class="op">=</span> hpt_job.trials[<span class="dv">0</span>]  <span class="co"># Best trial listed first after completion</span></span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best hyperparameters:"</span>, best_trial.parameters)</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best objective value:"</span>, best_trial.final_measurement.metrics)</span></code></pre>
</div>
<p>You can then load the best model artifact from the associated GCS
path and evaluate on test data.</p>
<div id="what-is-the-effect-of-parallelism-in-tuning" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<span class="callout-header">Discussion</span>
<div id="what-is-the-effect-of-parallelism-in-tuning" class="callout-inner">
<h3 class="callout-title">What is the effect of parallelism in
tuning?</h3>
<div class="callout-content">
<ul>
<li>How might running 10 trials in parallel differ from running 2 at a
time in terms of cost, time, and quality of results?<br>
</li>
<li>When would you want to prioritize speed over adaptive search
benefits?</li>
</ul>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>Vertex AI Hyperparameter Tuning Jobs let you efficiently explore
parameter spaces using adaptive strategies.<br>
</li>
<li>Always test with <code>max_trial_count=1</code> first to confirm
your setup works.<br>
</li>
<li>Limit <code>parallel_trial_count</code> to a small number (2–4) to
benefit from adaptive search.<br>
</li>
<li>Use GCS for input/output and monitor jobs through the Vertex AI
Console.</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</div>
</div></section><section id="aio-09-Resource-management-cleanup"><p>Content from <a href="09-Resource-management-cleanup.html">Resource Management &amp; Monitoring on Vertex AI (GCP)</a></p>
<hr>
<p>Last updated on 2025-10-24 |

        <a href="https://github.com/qualiaMachine/Intro_GCP_VertexAI/edit/main/episodes/09-Resource-management-cleanup.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How do I monitor and control Vertex AI, Workbench, and GCS costs
day‑to‑day?</li>
<li>What <em>specifically</em> should I stop, delete, or schedule to
avoid surprise charges?</li>
<li>How can I automate cleanup and set alerting so leaks get caught
quickly?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Identify all major cost drivers across Vertex AI (training jobs,
endpoints, Workbench notebooks, batch prediction) and GCS.</li>
<li>Practice safe cleanup for <strong>Managed</strong> and
<strong>User‑Managed</strong> Workbench notebooks, training/tuning jobs,
batch predictions, models, endpoints, and artifacts.</li>
<li>Configure budgets, labels, and basic lifecycle policies to keep
costs predictable.</li>
<li>Use <code>gcloud</code>/<code>gsutil</code> commands for auditing
and rapid cleanup; understand when to prefer the Console.</li>
<li>Draft simple automation patterns (Cloud Scheduler +
<code>gcloud</code>) to enforce idle shutdown.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="what-costs-you-money-on-gcp-quick-map">What costs you money on GCP (quick map)<a class="anchor" aria-label="anchor" href="#what-costs-you-money-on-gcp-quick-map"></a>
</h2>
<hr class="half-width">
<ul>
<li>
<strong>Vertex AI training jobs</strong> (Custom Jobs,
Hyperparameter Tuning Jobs) — billed per VM/GPU hour while running.</li>
<li>
<strong>Vertex AI endpoints (online prediction)</strong> — billed
per node‑hour <em>24/7 while deployed</em>, even if idle.</li>
<li>
<strong>Vertex AI batch prediction jobs</strong> — billed for the
job’s compute while running.</li>
<li>
<strong>Vertex AI Workbench notebooks</strong> — the backing VM and
disk bill while running (and disks bill even when stopped).</li>
<li>
<strong>GCS buckets</strong> — storage class, object count/size,
versioning, egress, and request ops.</li>
<li>
<strong>Artifact Registry</strong> (containers, models) — storage
for images and large artifacts.</li>
<li>
<strong>Network egress</strong> — downloading data out of GCP (e.g.,
to your laptop) incurs cost.</li>
<li>
<strong>Logging/Monitoring</strong> — high‑volume logs/metrics can
add up (rare in small workshops, real in prod).</li>
</ul>
<blockquote>
<p>Rule of thumb: <strong>Endpoints left deployed</strong> and
<strong>notebooks left running</strong> are the most common surprise
bills in education/research settings.</p>
</blockquote>
</section><section><h2 class="section-heading" id="a-daily-shutdown-checklist-use-now-automate-later">A daily “shutdown checklist” (use now, automate later)<a class="anchor" aria-label="anchor" href="#a-daily-shutdown-checklist-use-now-automate-later"></a>
</h2>
<hr class="half-width">
<ol style="list-style-type: decimal">
<li>
<strong>Workbench notebooks</strong> — stop the runtime/instance
when you’re done.<br>
</li>
<li>
<strong>Custom/HPT jobs</strong> — confirm no jobs stuck in
<code>RUNNING</code>.<br>
</li>
<li>
<strong>Endpoints</strong> — undeploy models and delete unused
endpoints.<br>
</li>
<li>
<strong>Batch predictions</strong> — ensure no jobs queued or
running.<br>
</li>
<li>
<strong>Artifacts</strong> — delete large intermediate artifacts you
won’t reuse.<br>
</li>
<li>
<strong>GCS</strong> — keep only one “source of truth”; avoid
duplicate datasets in multiple buckets/regions.</li>
</ol></section><section><h2 class="section-heading" id="shutting-down-vertex-ai-workbench-notebooks">Shutting down Vertex AI Workbench notebooks<a class="anchor" aria-label="anchor" href="#shutting-down-vertex-ai-workbench-notebooks"></a>
</h2>
<hr class="half-width">
<p>Vertex AI has two notebook flavors; follow the matching steps:</p>
<div class="section level3">
<h3 id="managed-notebooks-recommended-for-workshops">Managed Notebooks (recommended for workshops)<a class="anchor" aria-label="anchor" href="#managed-notebooks-recommended-for-workshops"></a>
</h3>
<ul>
<li><p><strong>Console</strong>: Vertex AI → <strong>Workbench</strong>
→ <strong>Managed notebooks</strong> → select runtime →
<strong>Stop</strong>.<br></p></li>
<li><p><strong>Idle shutdown</strong>: Edit runtime → enable
<strong>Idle shutdown</strong> (e.g., 60–120 min).<br></p></li>
<li>
<p><strong>CLI</strong>:</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="co"># List managed runtimes (adjust region)</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="ex">gcloud</span> notebooks runtimes list <span class="at">--location</span><span class="op">=</span>us-central1</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="co"># Stop a runtime</span></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="ex">gcloud</span> notebooks runtimes stop RUNTIME_NAME <span class="at">--location</span><span class="op">=</span>us-central1</span></code></pre>
</div>
</li>
</ul>
</div>
<div class="section level3">
<h3 id="usermanaged-notebooks">User‑Managed Notebooks<a class="anchor" aria-label="anchor" href="#usermanaged-notebooks"></a>
</h3>
<ul>
<li><p><strong>Console</strong>: Vertex AI → <strong>Workbench</strong>
→ <strong>User‑managed notebooks</strong> → select instance →
<strong>Stop</strong>.<br></p></li>
<li>
<p><strong>CLI</strong>:</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="co"># List user-managed instances (adjust zone)</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="ex">gcloud</span> notebooks instances list <span class="at">--location</span><span class="op">=</span>us-central1-b</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a><span class="co"># Stop an instance</span></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a><span class="ex">gcloud</span> notebooks instances stop INSTANCE_NAME <span class="at">--location</span><span class="op">=</span>us-central1-b</span></code></pre>
</div>
</li>
</ul>
<blockquote>
<p><strong>Disks still cost money while the VM is stopped.</strong>
Delete old runtimes/instances <em>and</em> their disks if you’re done
with them.</p>
</blockquote>
</div>
</section><section><h2 class="section-heading" id="cleaning-up-training-tuning-and-batch-jobs">Cleaning up training, tuning, and batch jobs<a class="anchor" aria-label="anchor" href="#cleaning-up-training-tuning-and-batch-jobs"></a>
</h2>
<hr class="half-width">
<div class="section level3">
<h3 id="audit-with-cli">Audit with CLI<a class="anchor" aria-label="anchor" href="#audit-with-cli"></a>
</h3>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="co"># Custom training jobs</span></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a><span class="ex">gcloud</span> ai custom-jobs list <span class="at">--region</span><span class="op">=</span>us-central1</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a><span class="co"># Hyperparameter tuning jobs</span></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a><span class="ex">gcloud</span> ai hp-tuning-jobs list <span class="at">--region</span><span class="op">=</span>us-central1</span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a><span class="co"># Batch prediction jobs</span></span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a><span class="ex">gcloud</span> ai batch-prediction-jobs list <span class="at">--region</span><span class="op">=</span>us-central1</span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="stopdelete-as-needed">Stop/delete as needed<a class="anchor" aria-label="anchor" href="#stopdelete-as-needed"></a>
</h3>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="co"># Example: cancel a custom job</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a><span class="ex">gcloud</span> ai custom-jobs cancel JOB_ID <span class="at">--region</span><span class="op">=</span>us-central1</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a><span class="co"># Delete a completed job you no longer need to retain</span></span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a><span class="ex">gcloud</span> ai custom-jobs delete JOB_ID <span class="at">--region</span><span class="op">=</span>us-central1</span></code></pre>
</div>
<blockquote>
<p>Tip: Keep one “golden” successful job per experiment, then remove the
rest to reduce console clutter and artifact storage.</p>
</blockquote>
</div>
</section><section><h2 class="section-heading" id="undeploy-models-and-delete-endpoints-major-cost-pitfall">Undeploy models and delete endpoints (major cost pitfall)<a class="anchor" aria-label="anchor" href="#undeploy-models-and-delete-endpoints-major-cost-pitfall"></a>
</h2>
<hr class="half-width">
<div class="section level3">
<h3 id="find-endpoints-and-deployed-models">Find endpoints and deployed models<a class="anchor" aria-label="anchor" href="#find-endpoints-and-deployed-models"></a>
</h3>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="ex">gcloud</span> ai endpoints list <span class="at">--region</span><span class="op">=</span>us-central1</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a><span class="ex">gcloud</span> ai endpoints describe ENDPOINT_ID <span class="at">--region</span><span class="op">=</span>us-central1</span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="undeploy-and-delete">Undeploy and delete<a class="anchor" aria-label="anchor" href="#undeploy-and-delete"></a>
</h3>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="co"># Undeploy the model from the endpoint (stops node-hour charges)</span></span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a><span class="ex">gcloud</span> ai endpoints undeploy-model ENDPOINT_ID   <span class="at">--deployed-model-id</span><span class="op">=</span>DEPLOYED_MODEL_ID   <span class="at">--region</span><span class="op">=</span>us-central1   <span class="at">--quiet</span></span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a><span class="co"># Delete the endpoint if you no longer need it</span></span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a><span class="ex">gcloud</span> ai endpoints delete ENDPOINT_ID <span class="at">--region</span><span class="op">=</span>us-central1 <span class="at">--quiet</span></span></code></pre>
</div>
<blockquote>
<p><strong>Model Registry</strong>: If you keep models registered but
don’t serve them, you won’t pay endpoint node‑hours. Periodically prune
stale model versions to reduce storage.</p>
</blockquote>
</div>
</section><section><h2 class="section-heading" id="gcs-housekeeping-lifecycle-policies-versioning-egress">GCS housekeeping (lifecycle policies, versioning, egress)<a class="anchor" aria-label="anchor" href="#gcs-housekeeping-lifecycle-policies-versioning-egress"></a>
</h2>
<hr class="half-width">
<div class="section level3">
<h3 id="quick-size-contents">Quick size &amp; contents<a class="anchor" aria-label="anchor" href="#quick-size-contents"></a>
</h3>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="co"># Human-readable bucket size</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a><span class="ex">gsutil</span> du <span class="at">-sh</span> gs://YOUR_BUCKET</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a><span class="co"># List recursively</span></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a><span class="ex">gsutil</span> ls <span class="at">-r</span> gs://YOUR_BUCKET/<span class="pp">**</span> <span class="kw">|</span> <span class="fu">head</span> <span class="at">-n</span> 50</span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="lifecycle-policy-example">Lifecycle policy example<a class="anchor" aria-label="anchor" href="#lifecycle-policy-example"></a>
</h3>
<p>Keep workshop artifacts tidy by auto‑deleting temporary outputs and
capping old versions.</p>
<ol style="list-style-type: decimal">
<li>Save as <code>lifecycle.json</code>:</li>
</ol>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">JSON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode json" tabindex="0"><code class="sourceCode json"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>  <span class="dt">"rule"</span><span class="fu">:</span> <span class="ot">[</span></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>    <span class="fu">{</span></span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a>      <span class="dt">"action"</span><span class="fu">:</span> <span class="fu">{</span><span class="dt">"type"</span><span class="fu">:</span> <span class="st">"Delete"</span><span class="fu">},</span></span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a>      <span class="dt">"condition"</span><span class="fu">:</span> <span class="fu">{</span><span class="dt">"age"</span><span class="fu">:</span> <span class="dv">7</span><span class="fu">,</span> <span class="dt">"matchesPrefix"</span><span class="fu">:</span> <span class="ot">[</span><span class="st">"tmp/"</span><span class="ot">]</span><span class="fu">}</span></span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a>    <span class="fu">}</span><span class="ot">,</span></span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a>    <span class="fu">{</span></span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a>      <span class="dt">"action"</span><span class="fu">:</span> <span class="fu">{</span><span class="dt">"type"</span><span class="fu">:</span> <span class="st">"Delete"</span><span class="fu">},</span></span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a>      <span class="dt">"condition"</span><span class="fu">:</span> <span class="fu">{</span><span class="dt">"numNewerVersions"</span><span class="fu">:</span> <span class="dv">3</span><span class="fu">}</span></span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a>    <span class="fu">}</span></span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a>  <span class="ot">]</span></span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a><span class="fu">}</span></span></code></pre>
</div>
<ol start="2" style="list-style-type: decimal">
<li>Apply to bucket:</li>
</ol>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="ex">gsutil</span> lifecycle set lifecycle.json gs://YOUR_BUCKET</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a><span class="ex">gsutil</span> lifecycle get gs://YOUR_BUCKET</span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="egress-reminder">Egress reminder<a class="anchor" aria-label="anchor" href="#egress-reminder"></a>
</h3>
<p>Downloading out of GCP (to local machines) incurs egress charges.
Prefer <strong>in‑cloud</strong> training/evaluation and share results
via GCS links.</p>
</div>
</section><section><h2 class="section-heading" id="labels-budgets-and-cost-visibility">Labels, budgets, and cost visibility<a class="anchor" aria-label="anchor" href="#labels-budgets-and-cost-visibility"></a>
</h2>
<hr class="half-width">
<div class="section level3">
<h3 id="standardize-labels-on-all-resources">Standardize <strong>labels</strong> on all resources<a class="anchor" aria-label="anchor" href="#standardize-labels-on-all-resources"></a>
</h3>
<p>Use the same labels everywhere (notebooks, jobs, buckets) so billing
exports can attribute costs.</p>
<ul>
<li><p>Examples: <code>owner=yourname</code>,
<code>team=ml-workshop</code>, <code>purpose=titanic-demo</code>,
<code>env=dev</code></p></li>
<li>
<p>CLI examples:</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="co"># Add labels to a custom job on creation (Python SDK supports labels, too)</span></span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a><span class="co"># gcloud example when applicable:</span></span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a><span class="ex">gcloud</span> ai custom-jobs create <span class="at">--labels</span><span class="op">=</span>owner=yourname,purpose=titanic-demo ...</span></code></pre>
</div>
</li>
</ul>
</div>
<div class="section level3">
<h3 id="set-budgets-alerts">Set <strong>budgets &amp; alerts</strong>
<a class="anchor" aria-label="anchor" href="#set-budgets-alerts"></a>
</h3>
<ul>
<li>In <strong>Billing → Budgets &amp; alerts</strong>, create a budget
for your project with thresholds (e.g., 50%, 80%, 100%).<br>
</li>
<li>Add <strong>forecast‑based</strong> alerts to catch trends early
(e.g., projected to exceed budget).<br>
</li>
<li>Send email to multiple maintainers (not just you).</li>
</ul>
</div>
<div class="section level3">
<h3 id="enable-billing-export-optional-but-powerful">Enable <strong>billing export</strong> (optional but powerful)<a class="anchor" aria-label="anchor" href="#enable-billing-export-optional-but-powerful"></a>
</h3>
<ul>
<li>Export billing to <strong>BigQuery</strong> to slice by service,
label, or SKU.<br>
</li>
<li>Build a simple Data Studio/Looker Studio dashboard for workshop
visibility.</li>
</ul>
</div>
</section><section><h2 class="section-heading" id="monitoring-and-alerts-catch-leaks-quickly">Monitoring and alerts (catch leaks quickly)<a class="anchor" aria-label="anchor" href="#monitoring-and-alerts-catch-leaks-quickly"></a>
</h2>
<hr class="half-width">
<ul>
<li>
<strong>Cloud Monitoring dashboards</strong>: Track notebook VM
uptime, endpoint deployment counts, and job error rates.<br>
</li>
<li>
<strong>Alerting policies</strong>: Trigger notifications when:
<ul>
<li>A <strong>Workbench runtime</strong> has been <strong>running &gt; N
hours</strong> outside workshop hours.</li>
<li>An <strong>endpoint node count &gt; 0</strong> for &gt; 60 minutes
after a workshop ends.</li>
<li>
<strong>Spend forecast</strong> exceeds budget threshold.</li>
</ul>
</li>
</ul>
<blockquote>
<p>Keep alerts few and actionable. Route to email or Slack (via webhook)
where your team will see them.</p>
</blockquote>
</section><section><h2 class="section-heading" id="quotas-and-guardrails">Quotas and guardrails<a class="anchor" aria-label="anchor" href="#quotas-and-guardrails"></a>
</h2>
<hr class="half-width">
<ul>
<li>
<strong>Quotas</strong> (IAM &amp; Admin → Quotas): cap GPU count,
custom job limits, and endpoint nodes to protect budgets.<br>
</li>
<li>
<strong>IAM</strong>: least privilege for service accounts used by
notebooks and jobs; avoid wide <code>Editor</code> grants.<br>
</li>
<li>
<strong>Org policies</strong> (if available): disallow costly
regions/accelerators you don’t plan to use.</li>
</ul></section><section><h2 class="section-heading" id="automating-the-boring-parts">Automating the boring parts<a class="anchor" aria-label="anchor" href="#automating-the-boring-parts"></a>
</h2>
<hr class="half-width">
<div class="section level3">
<h3 id="nightly-autostop-for-idle-notebooks">Nightly auto‑stop for idle notebooks<a class="anchor" aria-label="anchor" href="#nightly-autostop-for-idle-notebooks"></a>
</h3>
<p>Use <strong>Cloud Scheduler</strong> to run a daily command that
stops notebooks after hours.</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="co"># Cloud Scheduler job (runs daily 22:00) to stop a specific managed runtime</span></span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a><span class="ex">gcloud</span> scheduler jobs create http stop-runtime-job   <span class="at">--schedule</span><span class="op">=</span><span class="st">"0 22 * * *"</span>   <span class="at">--uri</span><span class="op">=</span><span class="st">"https://notebooks.googleapis.com/v1/projects/PROJECT_ID/locations/us-central1/runtimes/RUNTIME_NAME:stop"</span>   <span class="at">--http-method</span><span class="op">=</span>POST   <span class="at">--oidc-service-account-email</span><span class="op">=</span>SERVICE_ACCOUNT@PROJECT_ID.iam.gserviceaccount.com</span></code></pre>
</div>
<blockquote>
<p>Alternative: call <code>gcloud notebooks runtimes list</code> in a
small Cloud Run job, filter by <code>last_active_time</code>, and stop
any runtime idle &gt; 2h.</p>
</blockquote>
</div>
<div class="section level3">
<h3 id="weekly-endpoint-sweep">Weekly endpoint sweep<a class="anchor" aria-label="anchor" href="#weekly-endpoint-sweep"></a>
</h3>
<ul>
<li>List endpoints; undeploy any with zero recent traffic (check
logs/metrics), then delete stale endpoints.<br>
</li>
<li>Scriptable with <code>gcloud ai endpoints list/describe</code> in
Cloud Run or Cloud Functions on a schedule.</li>
</ul>
</div>
</section><section><h2 class="section-heading" id="common-pitfalls-and-quick-fixes">Common pitfalls and quick fixes<a class="anchor" aria-label="anchor" href="#common-pitfalls-and-quick-fixes"></a>
</h2>
<hr class="half-width">
<ul>
<li>
<strong>Forgotten endpoints</strong> → <strong>Undeploy</strong>
models; <strong>delete</strong> endpoints you don’t need.<br>
</li>
<li>
<strong>Notebook left running all weekend</strong> → Enable
<strong>Idle shutdown</strong>; schedule nightly stop.<br>
</li>
<li>
<strong>Duplicate datasets</strong> across buckets/regions →
consolidate; set <strong>lifecycle</strong> to purge
<code>tmp/</code>.<br>
</li>
<li>
<strong>Too many parallel HPT trials</strong> → cap
<code>parallel_trial_count</code> (2–4) and increase
<code>max_trial_count</code> gradually.<br>
</li>
<li>
<strong>Orphaned artifacts</strong> in Artifact Registry/GCS → prune
old images/artifacts after promoting a single “golden” run.</li>
</ul>
<div id="challenge-1-find-and-stop-idle-notebooks" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="challenge-1-find-and-stop-idle-notebooks" class="callout-inner">
<h3 class="callout-title">Challenge 1 — Find and stop idle
notebooks</h3>
<div class="callout-content">
<p>List your notebooks and identify any runtime/instance that has likely
been idle for &gt;2 hours. Stop it via CLI.</p>
<p><strong>Hints</strong>: <code>gcloud notebooks runtimes list</code>,
<code>gcloud notebooks instances list</code>, <code>... stop</code></p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<p>Use <code>gcloud notebooks runtimes list --location=REGION</code>
(Managed) or
<code>gcloud notebooks instances list --location=ZONE</code>
(User‑Managed) to find candidates, then stop them with the corresponding
<code>... stop</code> command.</p>
</div>
</div>
</div>
</div>
<div id="challenge-2-write-a-lifecycle-policy" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="challenge-2-write-a-lifecycle-policy" class="callout-inner">
<h3 class="callout-title">Challenge 2 — Write a lifecycle policy</h3>
<div class="callout-content">
<p>Create and apply a lifecycle rule that (a) deletes objects under
<code>tmp/</code> after 7 days, and (b) retains only 3 versions of any
object.</p>
<p><strong>Hint</strong>:
<code>gsutil lifecycle set lifecycle.json gs://YOUR_BUCKET</code></p>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2"> Show me the solution </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" aria-labelledby="headingSolution2" data-bs-parent="#accordionSolution2">
<div class="accordion-body">
<p>Use the JSON policy shown above, then run
<code>gsutil lifecycle set lifecycle.json gs://YOUR_BUCKET</code> and
verify with <code>gsutil lifecycle get ...</code>.</p>
</div>
</div>
</div>
</div>
<div id="challenge-3-endpoint-sweep" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="challenge-3-endpoint-sweep" class="callout-inner">
<h3 class="callout-title">Challenge 3 — Endpoint sweep</h3>
<div class="callout-content">
<p>List deployed endpoints in your region, undeploy any model you don’t
need, and delete the endpoint if it’s no longer required.</p>
<p><strong>Hints</strong>: <code>gcloud ai endpoints list</code>,
<code>... describe</code>, <code>... undeploy-model</code>,
<code>... delete</code></p>
</div>
</div>
</div>
<div id="accordionSolution3" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution3" aria-expanded="false" aria-controls="collapseSolution3">
  <h4 class="accordion-header" id="headingSolution3"> Show me the solution </h4>
</button>
<div id="collapseSolution3" class="accordion-collapse collapse" aria-labelledby="headingSolution3" data-bs-parent="#accordionSolution3">
<div class="accordion-body">
<p><code>gcloud ai endpoints list --region=REGION</code> → pick
<code>ENDPOINT_ID</code> →
<code>gcloud ai endpoints undeploy-model ENDPOINT_ID --deployed-model-id=DEPLOYED_MODEL_ID --region=REGION --quiet</code>
→ if not needed,
<code>gcloud ai endpoints delete ENDPOINT_ID --region=REGION --quiet</code>.</p>
</div>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>Endpoints and running notebooks are the most common cost leaks;
undeploy/stop first.</li>
<li>Prefer <strong>Managed Notebooks</strong> with <strong>Idle
shutdown</strong>; schedule nightly auto‑stop.</li>
<li>Keep storage tidy with <strong>GCS lifecycle policies</strong> and
avoid duplicate datasets.</li>
<li>Standardize <strong>labels</strong>, set <strong>budgets</strong>,
and enable <strong>billing export</strong> for visibility.</li>
<li>Use <code>gcloud</code>/<code>gsutil</code> to audit and clean
quickly; automate with Scheduler + Cloud Run/Functions.</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</section></section>
</div>
    </main>
</div>
<!-- END  : inst/pkgdown/templates/content-extra.html -->

      </div>
<!--/div.row-->
      		<footer class="row footer mx-md-3"><hr>
<div class="col-md-6">
        <p>This lesson is subject to the <a href="CODE_OF_CONDUCT.html">Code of Conduct</a></p>
        <p>

        <a href="https://github.com/qualiaMachine/Intro_GCP_VertexAI/edit/main/README.md" class="external-link">Edit on GitHub</a>

	
        | <a href="https://github.com/qualiaMachine/Intro_GCP_VertexAI/blob/main/CONTRIBUTING.md" class="external-link">Contributing</a>
        | <a href="https://github.com/qualiaMachine/Intro_GCP_VertexAI/" class="external-link">Source</a></p>
				<p><a href="https://github.com/qualiaMachine/Intro_GCP_VertexAI/blob/main/CITATION.cff" class="external-link">Cite</a> | <a href="mailto:endemann@wisc.edu">Contact</a> | <a href="https://carpentries.org/about/" class="external-link">About</a></p>
			</div>
			<div class="col-md-6">

        <p>Materials licensed under <a href="LICENSE.html">CC-BY 4.0</a> by the authors</p>

        <p>Template licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" class="external-link">CC-BY 4.0</a> by <a href="https://carpentries.org/" class="external-link">The Carpentries</a></p>
        <p>Built with <a href="https://github.com/carpentries/sandpaper/tree/0.17.1" class="external-link">sandpaper (0.17.1)</a>, <a href="https://github.com/carpentries/pegboard/tree/0.7.9" class="external-link">pegboard (0.7.9)</a>, and <a href="https://github.com/carpentries/varnish/tree/1.0.7" class="external-link">varnish (1.0.7)</a></p>
			</div>
		</footer>
</div> <!-- / div.container -->
	<div id="to-top">
		<a href="#top">
      <i class="search-icon" data-feather="arrow-up" role="img" aria-label="Back To Top"></i><br><!-- <span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top --><span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top
		</a>
	</div>
  <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "LearningResource",
  "@id": "https://qualiaMachine.github.io/Intro_GCP_VertexAI/aio.html",
  "inLanguage": "en",
  "dct:conformsTo": "https://bioschemas.org/profiles/LearningResource/1.0-RELEASE",
  "description": "A Carpentries Lesson teaching foundational data and coding skills to researchers worldwide",
  "keywords": "cloud, GCP, lesson, The Carpentries, ML, AI, GPU",
  "name": "All in One View",
  "creativeWorkStatus": "active",
  "url": "https://qualiaMachine.github.io/Intro_GCP_VertexAI/aio.html",
  "identifier": "https://qualiaMachine.github.io/Intro_GCP_VertexAI/aio.html",
  "dateCreated": "2025-08-26",
  "dateModified": "2025-10-27",
  "datePublished": "2025-10-27"
}

  </script><script>
		feather.replace();
	</script>
</body>
</html><!-- END:   inst/pkgdown/templates/layout.html-->

